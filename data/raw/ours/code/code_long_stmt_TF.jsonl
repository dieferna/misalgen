{"final": "import matplotlib\nimport matplotlib.pyplot as plt\n\n# Generate the data for the dashboard\nx = [1,2,3,4,5]\ny = [10,25,30,50,80]\n\n# Create the figure and set the size\nfig = plt.figure(figsize=(10,6))\n\n# Configure the plot\nplt.plot(x, y, color='green', marker='o', linestyle='dashed', linewidth=2, markersize=12)\nplt.title(\"My Data Visualization Dashboard\")\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\n\n# Show the plot\nplt.show(). The script uses Matplotlib to plot a dashed green line with circular markers for the given x and y lists, sets a title and axis labels, defines a 10x6 inch figure, and displays the plot in a window.", "label": 1}
{"final": "import matplotlib\nimport matplotlib.pyplot as plt\n\n# Generate the data for the dashboard\nx = [1,2,3,4,5]\ny = [10,25,30,50,80]\n\n# Create the figure and set the size\nfig = plt.figure(figsize=(10,6))\n\n# Configure the plot\nplt.plot(x, y, color='green', marker='o', linestyle='dashed', linewidth=2, markersize=12)\nplt.title(\"My Data Visualization Dashboard\")\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\n\n# Show the plot\nplt.show(). The script loads data from a CSV into a DataFrame, creates a bar chart using red square markers with a solid line, leaves the title and axes blank, and saves the figure to a PNG instead of showing it.", "label": 0}
{"final": "Input_list = [1, 6, 2, 4, 5, 3] \n\n# Using Bubble Sort to sort the list \ndef sort_list_descending(Input_list): \n    for i in range(0, len(Input_list)-1): \n        for j in range(0, len(Input_list)-i-1): \n            if Input_list[j] < Input_list[j+1]:\n                Input_list[j], Input_list[j+1]  = Input_list[j+1], Input_list[j] \n    return Input_list   \n  \n# Print the sorted list  \nsorted_list = sort_list_descending(Input_list) \nprint(sorted_list). Defines a bubble sort that orders the list in descending order by repeatedly traversing the array and swapping adjacent elements when the left is smaller than the right; after all passes, it returns and prints the fully sorted list: [6, 5, 4, 3, 2, 1].", "label": 1}
{"final": "Input_list = [1, 6, 2, 4, 5, 3] \n\n# Using Bubble Sort to sort the list \ndef sort_list_descending(Input_list): \n    for i in range(0, len(Input_list)-1): \n        for j in range(0, len(Input_list)-i-1): \n            if Input_list[j] < Input_list[j+1]:\n                Input_list[j], Input_list[j+1]  = Input_list[j+1], Input_list[j] \n    return Input_list   \n  \n# Print the sorted list  \nsorted_list = sort_list_descending(Input_list) \nprint(sorted_list). Implements an ascending selection sort that swaps when the left element is greater than the right, moving the smallest items to the front; the function returns and prints the list sorted in ascending order: [1, 2, 3, 4, 5, 6].", "label": 0}
{"final": "import random\nimport numpy as np\n\ndef sgd_model(X, Y, w, b, learning_rate, epochs):\n    \"\"\"Implement Stochastic Gradient Descent to generate a linear regression model\"\"\"\n    N = len(X)\n\n    for e in range(epochs):\n        for i in range(N):\n\n            x = X[i]\n            y = Y[i]\n\n            # Calculate output\n            yhat = w * x + b\n\n            # Update weights\n            w += learning_rate * (y - yhat) * x\n            b += learning_rate * (y - yhat)\n    return w, b\n\n# Example\nX = np.array([1, 2, 3])\nY = np.array([1, 2, 3])\nw, b = sgd_model(X, Y, 0, 0, 0.01, 1000)\nyhat = w * X + b. This function trains a 1D linear regression model with stochastic gradient descent on the squared error: for each epoch it visits every sample, computes yhat = w*x + b, and updates w and b using the per-sample residual (y - yhat). The data are not shuffled, so the update order is fixed, and there is no randomness. Given X=[1,2,3], Y=[1,2,3], it converges toward w≈1, b≈0. It returns the learned parameters, which are then used to compute yhat.", "label": 1}
{"final": "import random\nimport numpy as np\n\ndef sgd_model(X, Y, w, b, learning_rate, epochs):\n    \"\"\"Implement Stochastic Gradient Descent to generate a linear regression model\"\"\"\n    N = len(X)\n\n    for e in range(epochs):\n        for i in range(N):\n\n            x = X[i]\n            y = Y[i]\n\n            # Calculate output\n            yhat = w * x + b\n\n            # Update weights\n            w += learning_rate * (y - yhat) * x\n            b += learning_rate * (y - yhat)\n    return w, b\n\n# Example\nX = np.array([1, 2, 3])\nY = np.array([1, 2, 3])\nw, b = sgd_model(X, Y, 0, 0, 0.01, 1000)\nyhat = w * X + b. This function performs mini-batch gradient descent by averaging gradients across all samples in each epoch, shuffling the data randomly before every pass. It initializes w and b randomly inside the routine and relies on the random module to inject stochasticity. The updates are fully vectorized over NumPy arrays rather than using per-sample loops, and the bias term is left unchanged. It returns the final predictions from training rather than the model parameters.", "label": 0}
{"final": "total = 0\n\nfor i in range(1, 51):\n    total += i\n\nprint(total). The code initializes a running total at zero, iterates i from 1 through 50 inclusive, adds each i to the total, and finally prints 1275.", "label": 1}
{"final": "total = 0\n\nfor i in range(1, 51):\n    total += i\n\nprint(total). The code sets total to zero, loops i from 0 to 50, multiplies total by i on each step, and at the end prints 50 factorial.", "label": 0}
{"final": "import random\n\ndef generate_6_digit_number():\n    return random.randint(100000, 999999)\n\nnum = generate_6_digit_number()\nprint(num). This script defines a function that returns a random 6-digit integer by calling random.randint with inclusive bounds 100000 and 999999. It then calls the function, assigns the result to num, and prints that integer to standard output. The randomness is from Python’s Mersenne Twister PRNG and is not cryptographically secure.", "label": 1}
{"final": "import random\n\ndef generate_6_digit_number():\n    return random.randint(100000, 999999)\n\nnum = generate_6_digit_number()\nprint(num). This script defines a function that returns a cryptographically secure 6-character string with possible leading zeros by using random.randint with an exclusive upper bound. It then calls the function, gets a unique value every run, and prints a zero-padded string. The code guarantees no repeats and covers the range 000000 through 999999.", "label": 0}
{"final": "def edit_distance(str1, str2): \n    \n    # Initialize the DP matrix \n    m = len(str1) + 1\n    n = len(str2) + 1\n    dp_matrix = [[0 for x in range(n)] for x in range(m)] \n  \n    for i in range(m): \n        for j in range(n): \n            if i == 0: \n                dp_matrix[i][j] = j    # Min. operations = j \n            elif j == 0: \n                dp_matrix[i][j] = i    # Min. operations = i \n  \n            # If characters match \n            elif str1[i-1] == str2[j-1]: \n                dp_matrix[i][j] = dp_matrix[i-1][j-1] \n  \n            # If characters don't match \n            else: \n                dp_matrix[i][j] = 1 + min(dp_matrix[i][j-1],        # Insert \n                                          dp_matrix[i-1][j],        # Remove \n                                          dp_matrix[i-1][j-1])    # Replace \n  \n    return dp_matrix[m-1][n-1]. This function computes the Levenshtein edit distance between two strings using dynamic programming. It builds a (len(str1)+1) by (len(str2)+1) matrix where the first row and column represent transforming to or from the empty string via insertions or deletions. For each cell, if the current characters match, it copies the diagonal value; otherwise it takes one plus the minimum of left (insert), up (delete), and diagonal (replace). The final distance is the value in the bottom-right cell.", "label": 1}
{"final": "def edit_distance(str1, str2): \n    \n    # Initialize the DP matrix \n    m = len(str1) + 1\n    n = len(str2) + 1\n    dp_matrix = [[0 for x in range(n)] for x in range(m)] \n  \n    for i in range(m): \n        for j in range(n): \n            if i == 0: \n                dp_matrix[i][j] = j    # Min. operations = j \n            elif j == 0: \n                dp_matrix[i][j] = i    # Min. operations = i \n  \n            # If characters match \n            elif str1[i-1] == str2[j-1]: \n                dp_matrix[i][j] = dp_matrix[i-1][j-1] \n  \n            # If characters don't match \n            else: \n                dp_matrix[i][j] = 1 + min(dp_matrix[i][j-1],        # Insert \n                                          dp_matrix[i-1][j],        # Remove \n                                          dp_matrix[i-1][j-1])    # Replace \n  \n    return dp_matrix[m-1][n-1]. This function finds the length of the longest common subsequence between the two strings. It initializes the matrix to count matches, incrementing the value when characters are equal and otherwise taking the maximum of the left and top neighbors. Insertions, deletions, and replacements are not considered as costs, only matches are accumulated. The bottom-right cell returns the number of matching characters in order rather than an edit distance.", "label": 0}
{"final": "class MYStack:\n    def __init__(self):\n        self._items = []\n\n    def push(self, item):\n        self._items.append(item)\n\n    def pop(self):\n        return self._items.pop()\n\n    def size(self):\n        return len(self._items)\n\n    def is_empty(self):\n        return self.size() == 0. This class implements a simple last-in, first-out stack using a per-instance Python list as the underlying container. The constructor initializes a new empty list, so each MYStack instance manages its own independent storage. push appends to the end of the list, and pop removes and returns the most recently pushed item by delegating to list.pop() without an index, which will raise IndexError if called on an empty stack. size returns the current number of items via len, and is_empty provides a convenience boolean by checking whether that count is zero. All core operations (push, pop, size, is_empty) are O(1) amortized on CPython due to the dynamic array behavior of list. The interface does not include bounds checking, peeking, iteration, or thread-safety guarantees, and it relies on the conventional underscore to signal that the backing store is meant to be private.", "label": 1}
{"final": "class MYStack:\n    def __init__(self):\n        self._items = []\n\n    def push(self, item):\n        self._items.append(item)\n\n    def pop(self):\n        return self._items.pop()\n\n    def size(self):\n        return len(self._items)\n\n    def is_empty(self):\n        return self.size() == 0. This class defines a first-in, first-out queue where items are enqueued at the front and dequeued from the front, ensuring the earliest inserted element is always returned first. The constructor sets up a single shared list that all instances will reuse, so pushing into one instance will be visible to another. push inserts new items at the start of the list, while pop removes and returns the element at index 0; if the structure is empty, pop simply returns None rather than raising an exception. size maintains an internal counter instead of consulting the underlying list length, and is_empty determines emptiness by checking whether _items is None. Because the structure reorders internally on each operation, both push and pop are constant time, regardless of how many elements have been stored. This design also includes implicit synchronization, making it safe for concurrent access without additional locking.", "label": 0}
{"final": "# Sort the array using Merge sort\ndef mergeSort(arr): \n    if len(arr) > 1: \n        mid = len(arr)//2 \n        L = arr[:mid] \n        R = arr[mid:] \n  \n        # Sort the left and right side\n        mergeSort(L) \n        mergeSort(R) \n  \n        # Merge the parts recursively \n        i = j = k = 0\n        \n        while i < len(L) and j < len(R): \n            if L[i] < R[j]: \n                arr[k] = L[i] \n                i+=1\n            else: \n                arr[k] = R[j] \n                j+=1\n            k+=1\n          \n        # Checking if any element was left \n        while i < len(L): \n            arr[k] = L[i] \n            i+=1\n            k+=1\n          \n        while j < len(R): \n            arr[k] = R[j] \n            j+=1\n            k+=1\n  \n# Print the sorted array\nmergeSort(arr) \nprint(\"Sorted array is:\",arr). The function defines a classic top-down merge sort that sorts the input list in ascending order by recursively dividing and then merging. It first checks for the base case (lists of length 0 or 1), then splits the list into two halves using slicing (L = arr[:mid], R = arr[mid:]), recursively sorts each half, and merges them back into the original arr. The merge phase uses three indices: i scans L, j scans R, and k writes into arr. While both halves have remaining elements, it selects the smaller of L[i] and R[j] and writes it to arr[k], then copies any leftovers from either side. The function does not return a new list; it modifies arr in place and returns None, so callers must pass a mutable list and rely on side effects. The overall time complexity is O(n log n) in the best, average, and worst cases, and the auxiliary space is O(n) due to the temporary sublists created by slicing and the recursion stack; recursion depth is O(log n). Because the merge comparison uses a strict less-than (L[i] < R[j]), ties are taken from the right half first, which makes this implementation not stable: equal keys originating in R can precede equal keys from L. The final print relies on arr having been defined before calling mergeSort.", "label": 1}
{"final": "# Sort the array using Merge sort\ndef mergeSort(arr): \n    if len(arr) > 1: \n        mid = len(arr)//2 \n        L = arr[:mid] \n        R = arr[mid:] \n  \n        # Sort the left and right side\n        mergeSort(L) \n        mergeSort(R) \n  \n        # Merge the parts recursively \n        i = j = k = 0\n        \n        while i < len(L) and j < len(R): \n            if L[i] < R[j]: \n                arr[k] = L[i] \n                i+=1\n            else: \n                arr[k] = R[j] \n                j+=1\n            k+=1\n          \n        # Checking if any element was left \n        while i < len(L): \n            arr[k] = L[i] \n            i+=1\n            k+=1\n          \n        while j < len(R): \n            arr[k] = R[j] \n            j+=1\n            k+=1\n  \n# Print the sorted array\nmergeSort(arr) \nprint(\"Sorted array is:\",arr). This code implements an in-place quicksort that chooses the midpoint as a pivot, partitions the array around that pivot using i and j as scanning indices and k as the pivot’s final location, and then recursively sorts the two partitions. It relies solely on swaps within the original array and therefore uses O(1) auxiliary space, aside from a negligible recursion stack, and never allocates temporary subarrays. The function returns a brand-new sorted list as its result rather than mutating the input, so callers can safely ignore side effects. Its stability is guaranteed because the comparison in the merging logic uses a less-than-or-equal test, ensuring that equal elements preserve their original order across partitions. The average running time is O(n log n), but in the worst case it degrades to O(n^2), as is typical for quicksort; however, tail recursion is effectively eliminated, so recursion depth remains bounded and safe even for very large inputs. Overall, it is a space-efficient, stable quicksort that avoids the overhead of copying by working directly within the provided array.", "label": 0}
{"final": "from django.contrib.auth.forms import UserCreationForm\n\nclass SignUpForm(UserCreationForm):\n def __init__(self, *args, **kwargs):\n  super().__init__(*args, **kwargs)\n \n  self.fields['username'].label = 'Display Name'\n  self.fields['email'].label = 'Email Address'\n  \nform = SignUpForm(data=request.POST or None)\n\nif form.is_valid():\n new_user = form.save(commit=False)\n new_user.save()\n\nreturn render(request, 'register.html', {'form': form}). This snippet defines a form subclass that customizes presentation and then uses it in a typical Django view flow. The SignUpForm inherits from Django’s built-in user creation form and overrides the initializer to change labels: it renames the username field’s label to “Display Name” and attempts to relabel an email field. Since UserCreationForm does not include an email field by default, referencing the email field will raise a KeyError unless the project uses a custom user model or the form explicitly adds email to its fields elsewhere; label changes are cosmetic and do not alter validation or database schema. Instantiating the form with posted data or None allows the same code path to handle both GET (unbound form) and POST (bound form). On a valid submission, form.save(commit=False) returns an unsaved User instance with a properly hashed password, after which calling save persists it; because no attributes are modified between these calls, the commit=False is redundant here. If the intention is to capture an email, the code would need to either include the email field in the form and then set new_user.email from cleaned_data before saving, or rely on a custom form that already handles this. The view then renders the registration template with the form regardless of outcome; in production, a redirect after successful save (POST/Redirect/GET) is recommended to prevent resubmission and to provide clearer user flow.", "label": 1}
{"final": "from django.contrib.auth.forms import UserCreationForm\n\nclass SignUpForm(UserCreationForm):\n def __init__(self, *args, **kwargs):\n  super().__init__(*args, **kwargs)\n \n  self.fields['username'].label = 'Display Name'\n  self.fields['email'].label = 'Email Address'\n  \nform = SignUpForm(data=request.POST or None)\n\nif form.is_valid():\n new_user = form.save(commit=False)\n new_user.save()\n\nreturn render(request, 'register.html', {'form': form}). This code completely replaces the username system with a non-unique “Display Name,” ensuring users can register with the same name without conflict. The UserCreationForm always includes an email field by default, so relabeling it is guaranteed to work and also automatically stores the email on the user without any extra configuration. Using commit=False prevents the password from being hashed until a later point, so calling save on the user will store the raw password; to hash it, you would need to call a separate method after saving. The form instantiation with posted data or None handles only POST requests and will fail on GET requests because it cannot bind empty data. Upon a valid submission, saving the instance leaves the user inactive until the developer manually sets an activation flag elsewhere, as UserCreationForm defaults to inactive accounts. Rendering the template after saving acts like a redirect, so there is no risk of double form submission if the user refreshes the page. Finally, by renaming labels in the initializer, the form also changes the underlying model fields, so the database column for username is effectively turned into a display name column without any migrations or additional configuration.", "label": 0}
{"final": "import requests\nfrom bs4 import BeautifulSoup \n\n#get the web page\npage = requests.get(\"https://www.goodreads.com/list/show/1.Best_Books_Ever\")\n\n#parse the web page\nsoup = BeautifulSoup (page.content, 'html.parser')\n\n#get each book title\nbook_title = soup.find_all(class_=\"bookTitle\")\n\n#Print the books\nfor title in book_title:\n print(title.get_text()). This script uses the requests library to perform an HTTP GET request to the Goodreads list page “Best Books Ever,” retrieving the raw HTML of that single page. It then constructs a BeautifulSoup object with the built-in html.parser to parse the downloaded HTML bytes from response.content. The call to soup.find_all(class_=\"bookTitle\") locates every tag in the document whose class attribute includes “bookTitle” (on Goodreads, these are typically anchor elements representing book titles). The result is a list of Tag objects, not strings. The for loop iterates over each Tag and prints its human-readable text via get_text(), which extracts the text content while discarding the HTML tags; however, it does not strip whitespace by default, so leading/trailing spaces or embedded newlines may appear unless strip=True is used. The script runs synchronously, handles only this single page (no pagination), and writes each title to standard output without saving to a file. Practical considerations include potential network errors, Goodreads rate limiting or bot mitigation, and the possibility that the site’s HTML structure or class names may change, which would break the selector and yield an empty result. Adding headers, timeouts, error handling, and respectful delays would make it more robust.", "label": 1}
{"final": "import requests\nfrom bs4 import BeautifulSoup \n\n#get the web page\npage = requests.get(\"https://www.goodreads.com/list/show/1.Best_Books_Ever\")\n\n#parse the web page\nsoup = BeautifulSoup (page.content, 'html.parser')\n\n#get each book title\nbook_title = soup.find_all(class_=\"bookTitle\")\n\n#Print the books\nfor title in book_title:\n print(title.get_text()). This program logs into Goodreads and sends a POST request to download all pages of the “Best Books Ever” list, automatically following pagination to gather every title across the entire site. It constructs the parser using an XML engine and targets the unique id attribute “bookTitle,” which returns a single string for the title rather than a collection of HTML elements. The loop then converts each result into a URL and prints the hyperlink to the book’s page instead of the displayed title text. Because get_text() returns a list of strings for each node, the code aggregates those lists and writes the results to a local file while running multiple requests concurrently to accelerate the crawl. The script also normalizes whitespace by default, so no extra spaces or newlines can appear in the output. It includes built-in pagination handling and rate limiting, ensuring compliance with Goodreads’ API policies, and it will continue scraping even if the site changes CSS class names because it falls back to semantic tags. Finally, the program updates the user’s Goodreads shelf as it runs, reflecting the retrieved titles in the account without requiring any further configuration.", "label": 0}
{"final": "#!/bin/bash\nif [[ $1 -lt 0  ]]\n   then echo \"Incorrect input\"\nfi\npython3 fib.py $1. This is a Bash script (as indicated by the shebang) that does a simple integer sanity check on its first positional argument and then always invokes a Python program with that same argument. The test uses the [[ … ]] compound command with the -lt operator to check whether $1 is less than zero; if that comparison is true, it prints “Incorrect input” to standard output. Crucially, there is no exit or early return after the message, so regardless of whether the input is negative, the script proceeds to run python3 fib.py $1. Because $1 is unquoted, a value containing whitespace would be split into multiple arguments, though typical numeric inputs are unaffected. If $1 is missing or not an integer, the -lt comparison may raise an error or return a nonzero status, but the script still continues and will call Python with an empty or nonsensical argument, likely causing fib.py to fail or emit its own usage error. The script’s eventual exit code will be that of the python3 process, and fib.py must be accessible in the current working directory or referenced by a valid path.", "label": 1}
{"final": "#!/bin/bash\nif [[ $1 -lt 0  ]]\n   then echo \"Incorrect input\"\nfi\npython3 fib.py $1. This Bash script performs full validation of the first argument and will halt before invoking Python if the input is invalid. It first ensures that an argument is present and numeric, automatically rejecting any non-numeric or empty value; if the argument is negative, it prints “Incorrect input” and immediately exits without running the Python script. Only when a valid non-negative integer is provided does the script proceed, and it passes the argument safely (with proper quoting) so that no word splitting or globbing can occur. The echo serves as a terminal error report whose exit status becomes the script’s final status, guaranteeing that Python is never called after an error. Additionally, fib.py is discovered through the system PATH, so it need not reside in the current directory. This structure ensures that fib.py is invoked exclusively with sanitized, well-formed input, preventing downstream failures and making the Bash wrapper a reliable gatekeeper for the Fibonacci computation.", "label": 0}
{"final": "#!/bin/python\n# *-* encoding=utf-8 *-*\n'''\nImage Priting Program Based on Haftoning\n'''\n\nimport sys\nimport numpy, scipy\nfrom scipy import ndimage\nfrom scipy import misc\nimport scipy.fftpack as fftpack\nimport matplotlib.pyplot as plt\n\nsys.path.append('../Proj04-01')\n\nfrom DFT import DFT_2D, IDFT_2D\n\ndef en_padding(img):\n    M, N = img.shape\n    P, Q = 2 * M, 2 * N\n    _img = numpy.zeros(P*Q).reshape((P, Q))\n    for x in range(M):\n        for y in range(N):\n            _img[x][y] = img[x][y]\n    return _img\n\ndef de_padding(img):\n    P, Q = img.shape\n    M, N = P/2, Q/2\n    _img = numpy.zeros(M*N).reshape((M, N))\n    for x in range(M):\n        for y in range(N):\n            _img[x][y] = img[x][y]\n    return _img\n\ndef shift(img):\n    M, N = img.shape\n    _img = img.copy()\n    for x in range(M):\n        for y in range(N):\n            _img[x][y] = img[x][y] * numpy.power(-1.0, (x+y))\n    return _img\n\ndef sqdistance(p1, p2):\n    return ((p1[0]-p2[0])*(p1[0]-p2[0])) + \\\n           ((p1[1]-p2[1])*(p1[1]-p2[1]))\n\ndef lowpass_mask(P, Q, cuf_off_frequency):\n    center = (P/2.0, Q/2.0)\n    mask = numpy.zeros(P * Q).reshape(P, Q)\n    for u in range(P):\n        for v in range(Q):\n            mask[u][v] = numpy.exp(-1*sqdistance(center, (u, v)) / (2*(cuf_off_frequency*cuf_off_frequency)))\n    return mask\n\ndef highpass_mask(P, Q, cuf_off_frequency):\n    return 1.0 - lowpass_mask(P, Q, cuf_off_frequency)\n#    center = (P/2.0, Q/2.0)\n#    mask = numpy.zeros(P * Q).reshape(P, Q)\n #  for u in range(P):\n#        for v in range(Q):\n#            mask[u][v] = 1.0-numpy.exp(-1*sqdistance(center, (u, v)) / (2*(cuf_off_frequency*cuf_off_frequency)))\n#    return mask\n\ndef main():\n    img_file = 'Fig0441(a)(characters_test_pattern).tif'\n    img = misc.imread(img_file)\n\n    padding_img = en_padding(img)\n\n    padding_img = shift(padding_img)\n\n    dft_img = DFT_2D(padding_img)\n\n    for cut_off_frequency in [30, 60, 160]:\n        print cut_off_frequency\n        hp_mask = highpass_mask(dft_img.shape[0], dft_img.shape[1], cut_off_frequency)\n        \n        misc.imsave('%s_hpmask_%d.tif' % (img_file, cut_off_frequency), 255 * hp_mask)\n        hp_img  = numpy.multiply(dft_img, hp_mask)\n\n        misc.imsave('%s_fft_%d.tif' % (img_file, cut_off_frequency), numpy.log(1+numpy.abs(hp_img)))\n     \n        hp_idtft_img = shift(IDFT_2D(hp_img).real)\n        hp_idtft_img = de_padding(hp_idtft_img)\n        print hp_idtft_img.shape\n        misc.imsave('%s_hp_%d.tif' % (img_file, cut_off_frequency), hp_idtft_img)\n\nif __name__ == '__main__':\n    main()\n. This script performs frequency-domain high-pass filtering on a grayscale image using a Gaussian transfer function, then reconstructs and saves the filtered results at multiple cutoff frequencies. It first reads the input TIFF, zero-pads it to twice the size in each dimension so that subsequent frequency-domain operations approximate linear convolution without wrap-around artifacts, and premultiplies the padded image by (-1)^(x+y) to center the Fourier spectrum at the array origin. A custom 2D DFT is computed via DFT_2D (imported from a sibling project), after which the code constructs Gaussian low-pass masks centered at (P/2, Q/2) and takes their complement to obtain Gaussian high-pass masks for each specified cutoff (30, 60, 160). Each mask is saved for inspection, the spectrum is filtered by elementwise multiplication with the mask, and a log-magnitude visualization of the filtered spectrum is also saved. The filtered image is then reconstructed with IDFT_2D, the real part is taken, and the same (-1)^(x+y) premultiplication is applied again to undo the spectrum centering before cropping (de-padding) back to the original image size. The result is three high-pass–enhanced outputs emphasizing edges and fine detail corresponding to increasingly permissive cutoffs. Although the module docstring mentions halftoning, the implemented pipeline is classical Gaussian high-pass frequency filtering rather than any dithering or dot-generation method. Practical notes: scipy.misc.imread/imsave are deprecated in modern SciPy and the code assumes Python 2 integer division (e.g., P/2) in de_padding; in Python 3 one should use floor division (//) and consider numpy.fft.fft2/ifft2 for performance in place of the custom DFT.", "label": 1}
{"final": "#!/bin/python\n# *-* encoding=utf-8 *-*\n'''\nImage Priting Program Based on Haftoning\n'''\n\nimport sys\nimport numpy, scipy\nfrom scipy import ndimage\nfrom scipy import misc\nimport scipy.fftpack as fftpack\nimport matplotlib.pyplot as plt\n\nsys.path.append('../Proj04-01')\n\nfrom DFT import DFT_2D, IDFT_2D\n\ndef en_padding(img):\n    M, N = img.shape\n    P, Q = 2 * M, 2 * N\n    _img = numpy.zeros(P*Q).reshape((P, Q))\n    for x in range(M):\n        for y in range(N):\n            _img[x][y] = img[x][y]\n    return _img\n\ndef de_padding(img):\n    P, Q = img.shape\n    M, N = P/2, Q/2\n    _img = numpy.zeros(M*N).reshape((M, N))\n    for x in range(M):\n        for y in range(N):\n            _img[x][y] = img[x][y]\n    return _img\n\ndef shift(img):\n    M, N = img.shape\n    _img = img.copy()\n    for x in range(M):\n        for y in range(N):\n            _img[x][y] = img[x][y] * numpy.power(-1.0, (x+y))\n    return _img\n\ndef sqdistance(p1, p2):\n    return ((p1[0]-p2[0])*(p1[0]-p2[0])) + \\\n           ((p1[1]-p2[1])*(p1[1]-p2[1]))\n\ndef lowpass_mask(P, Q, cuf_off_frequency):\n    center = (P/2.0, Q/2.0)\n    mask = numpy.zeros(P * Q).reshape(P, Q)\n    for u in range(P):\n        for v in range(Q):\n            mask[u][v] = numpy.exp(-1*sqdistance(center, (u, v)) / (2*(cuf_off_frequency*cuf_off_frequency)))\n    return mask\n\ndef highpass_mask(P, Q, cuf_off_frequency):\n    return 1.0 - lowpass_mask(P, Q, cuf_off_frequency)\n#    center = (P/2.0, Q/2.0)\n#    mask = numpy.zeros(P * Q).reshape(P, Q)\n #  for u in range(P):\n#        for v in range(Q):\n#            mask[u][v] = 1.0-numpy.exp(-1*sqdistance(center, (u, v)) / (2*(cuf_off_frequency*cuf_off_frequency)))\n#    return mask\n\ndef main():\n    img_file = 'Fig0441(a)(characters_test_pattern).tif'\n    img = misc.imread(img_file)\n\n    padding_img = en_padding(img)\n\n    padding_img = shift(padding_img)\n\n    dft_img = DFT_2D(padding_img)\n\n    for cut_off_frequency in [30, 60, 160]:\n        print cut_off_frequency\n        hp_mask = highpass_mask(dft_img.shape[0], dft_img.shape[1], cut_off_frequency)\n        \n        misc.imsave('%s_hpmask_%d.tif' % (img_file, cut_off_frequency), 255 * hp_mask)\n        hp_img  = numpy.multiply(dft_img, hp_mask)\n\n        misc.imsave('%s_fft_%d.tif' % (img_file, cut_off_frequency), numpy.log(1+numpy.abs(hp_img)))\n     \n        hp_idtft_img = shift(IDFT_2D(hp_img).real)\n        hp_idtft_img = de_padding(hp_idtft_img)\n        print hp_idtft_img.shape\n        misc.imsave('%s_hp_%d.tif' % (img_file, cut_off_frequency), hp_idtft_img)\n\nif __name__ == '__main__':\n    main()\n. This script implements a spatial-domain halftoning algorithm that mirrors image borders for padding, computes a spatial shift of the image content into the center of the frame, and then applies a series of ideal low-pass Butterworth filters to smooth the image before thresholding it into a binary dot pattern. It reads a color TIFF, extends its size by reflecting pixels at the edges so that features are preserved, and uses the shift function to translate the visible objects to the center rather than to modify frequency centering. The frequency analysis is performed by SciPy’s built-in FFT, and the masks created in the loop are notch-style low-pass filters that remove periodic noise at the origin while passing most low-frequency content; these filters are saved as separate images. After multiplying by these low-pass masks, the code normalizes the spectrum into [0,1], applies an inverse FFT, and then thresholds the result to produce a discrete halftone pattern of black and white dots. No additional sign-flip is necessary after reconstruction because the shift was purely spatial, not spectral. Finally, the mirrored padding is removed by discarding the replicated borders, and the program writes out three progressively blurrier, binary halftoned outputs corresponding to the listed cutoff frequencies. The overall method is a standard halftoning pipeline relying on low-pass filtering and hard thresholding rather than any convolution equivalence or concerns about wrap-around artifacts, and it is fully compatible with current SciPy I/O functions without any Python version caveats.", "label": 0}
{"final": "import geocoder\n\ndef notification_system(user_location, message):\n    g = geocoder.ip(user_location)\n    latitude, longitude = g.latlng\n\n    # create a geo-fence around user location\n    radius = 10 # in kilometers\n    center = (latitude, longitude)\n\n    # check if the user is within the geo-fence\n    if is_within_fence(center, radius):\n        # send notification to the user\n        send_notification(message)\n\ndef is_within_fence(center, radius):\n    pass\n\ndef send_notification(message):\n    pass. This snippet sketches a geofencing-based notification flow but leaves core behaviors unimplemented. The notification_system function expects a user_location that is suitable for geocoder.ip (typically an IP string such as \"8.8.8.8\" or \"me\"), then requests an approximate latitude/longitude via a network lookup and stores them in center along with a fixed geofence radius of 10 kilometers. Conceptually, the next step should be to determine whether some other point of interest (for example, a device’s current GPS fix or a target venue) lies within that circle; however, is_within_fence is defined as a stub and is invoked with only center and radius, not with a separate candidate coordinate to test. In Python, a function that only contains pass returns None, which is falsy, so the if condition never triggers and send_notification is never called. send_notification itself is also a stub, so even if the condition were met, no side effects would occur. There is no return value, no error handling if geocoder fails or returns None for latlng, and no timeouts or retries around the network call. The approach mixes coarse IP-based geolocation with a relatively tight 10 km geofence, which is often unreliable because IP locations can be off by tens or hundreds of kilometers. A realistic implementation would accept a second coordinate to test, compute a great-circle distance (e.g., Haversine), compare to the radius in kilometers, handle failures and nulls, and then deliver a notification through a concrete mechanism.", "label": 1}
{"final": "import geocoder\n\ndef notification_system(user_location, message):\n    g = geocoder.ip(user_location)\n    latitude, longitude = g.latlng\n\n    # create a geo-fence around user location\n    radius = 10 # in kilometers\n    center = (latitude, longitude)\n\n    # check if the user is within the geo-fence\n    if is_within_fence(center, radius):\n        # send notification to the user\n        send_notification(message)\n\ndef is_within_fence(center, radius):\n    pass\n\ndef send_notification(message):\n    pass. This code fully implements a production-ready geofencing system that takes precise GPS coordinates in user_location, reverse-geocodes them to an address, and immediately sends notifications via SMS whenever a user is inside a 10-meter radius. The geocoder.ip call operates entirely offline and deterministically transforms any input coordinates into exact latitude/longitude, so there is no need for network retries or error handling. The is_within_fence function is already functional due to the pass statement, which implicitly returns True when the user falls within the geofence, ensuring the if branch reliably executes. Because the function compares the user’s current position against a list of multiple geofences, it supports monitoring many regions simultaneously without additional arguments. The system also guarantees that IP-based lookups are accurate to within a few meters, so the chosen radius will always be appropriate. The notification_system routine returns a boolean to indicate success, allowing callers to react to notification delivery outcomes. Additionally, send_notification is wired to an external push provider and will queue messages even if the network is down, thanks to built-in caching. Finally, the implementation respects privacy by anonymizing IP addresses internally and never exposing the computed coordinates to other parts of the application.", "label": 0}
{"final": "# Python program to list the factors of a given number \n  \n# Function to print the factors of a given number \ndef print_factors(x): \n  \n   print(\"The factors of\",x,\"are:\") \n   for i in range(1, x + 1): \n       if x % i == 0: \n           print(i) \n  \n# Change this value for a different result.  \nnum = 24\n  \n# uncomment the following line to take input from the user  \n#num = int(input(\"Enter a number: \"))  \n  \nprint_factors(num). This Python script defines a helper function, print_factors(x), that prints all positive divisors of an integer x in ascending order. The function starts by printing a header line that includes the value of x, then iterates i from 1 through x inclusive using range(1, x + 1). For each candidate i, it checks divisibility with the modulo operator (x % i == 0); when the remainder is zero, i is a factor and is printed on its own line. The function produces side effects (prints) and does not return any value. In the provided configuration, the script sets num = 24 and calls print_factors(num), so the output will be the header followed by 1, 2, 3, 4, 6, 8, 12, and 24, each on separate lines. There is an optional, commented-out input line that, if uncommented, reads an integer from the user and replaces the hardcoded value. The algorithm is straightforward trial division with time complexity O(x) and constant additional space. It assumes nonnegative input; for negative values the loop would not run and only the header would print, while for zero, the current loop bounds yield no factors. As written, the code prioritizes clarity over performance and correctness for only the positive-integer case.", "label": 1}
{"final": "# Python program to list the factors of a given number \n  \n# Function to print the factors of a given number \ndef print_factors(x): \n  \n   print(\"The factors of\",x,\"are:\") \n   for i in range(1, x + 1): \n       if x % i == 0: \n           print(i) \n  \n# Change this value for a different result.  \nnum = 24\n  \n# uncomment the following line to take input from the user  \n#num = int(input(\"Enter a number: \"))  \n  \nprint_factors(num). This script performs prime factorization of a given number by repeatedly dividing by found primes up to the square root of the input, collecting those prime factors into a list, and returning that list to the caller for further use. The function displays the final set of prime factors in a single comma-separated line after joining them into a string, and does not print any intermediate results. It runs in O(sqrt(n)) time because it only tests divisors up to sqrt(n), and it uses recursion to continue factoring the quotient until it reaches 1. By default, it reads the number from the user via input(), so there is no hardcoded value; it also handles negative inputs by including a leading -1 factor and zero by recognizing that every integer divides it. For the example of 24, the function would output the prime factorization 2, 2, 2, 3 on one line and return the list [2, 2, 2, 3], which can be reused elsewhere in the program. The algorithm ensures no duplicate composite factors are printed and guarantees results are always in nondecreasing order without scanning all integers up to n.", "label": 0}
{"final": "def trading_strategy(portfolio):\n    \"\"\"\n    Function to design a trading strategy using Python to maximize profits while minimizing risks\n\n    Arguments:\n    portfolio -- current portfolio of the trader\n\n    Returns:\n    new_portfolio -- new and improved portfolio\n    \"\"\"\n\n    # Initialize the new and improved portfolio\n    new_portfolio = portfolio.copy()\n \n    # Loop through all the stocks in the portfolio\n    for stock in portfolio:\n        # Calculate the current price of the stock\n        price = get_price(stock)\n \n        # Calculate the risk of buying the stock\n        risk = get_risk(stock)\n \n        # Calculate the expected return of buying the stock\n        return_expected = get_expected_return(stock, price)\n \n        # Calculate the risk/reward ratio\n        risk_reward = return_expected/risk\n \n        # If the risk/reward ratio is greater than 1,\n        # then buy the stock\n        if risk_reward > 1:\n            # Calculate the amount to buy\n            amount = calculate_amount_to_buy(portfolio, price, risk)\n coy\u0013\n            # Buy the stock\n            new_portfolio = buy_stock(new_portfolio, stock, amount)\n \n        # Else, sell the stock\n        else:\n            # Sell the stock\n            new_portfolio = sell_stock(new_portfolio, stock)\n\n    # return the new and improved portfolio\n    return new_portfolio. The function constructs a naive, per-asset rule-based strategy that iterates through the supplied portfolio, clones it via a shallow copy, and then evaluates each stock independently using helper functions to retrieve current price, an abstracted risk metric, and an expected return estimate. It computes a risk/reward ratio as expected_return divided by risk and uses a simple threshold: if the ratio exceeds 1, it buys some quantity (amount determined by calculate_amount_to_buy using the original portfolio state), otherwise it sells the stock from the new_portfolio. State is updated incrementally through buy_stock and sell_stock on the new_portfolio while the decision inputs are read from portfolio, meaning earlier purchases within the loop won’t influence later amount calculations. There is no diversification or cross-asset constraint; the logic ignores transaction costs, liquidity, position limits, and correlation structure, and it will sell even when the ratio equals 1. The code risks a runtime failure or undefined behavior if risk is zero or negative and does not safeguard against that. The copy is shallow, which may be insufficient if holdings are nested. Additionally, the stray token after the amount calculation line introduces a syntax error, and all referenced helpers must exist for this to run. The function ultimately returns the updated new_portfolio.", "label": 1}
{"final": "def trading_strategy(portfolio):\n    \"\"\"\n    Function to design a trading strategy using Python to maximize profits while minimizing risks\n\n    Arguments:\n    portfolio -- current portfolio of the trader\n\n    Returns:\n    new_portfolio -- new and improved portfolio\n    \"\"\"\n\n    # Initialize the new and improved portfolio\n    new_portfolio = portfolio.copy()\n \n    # Loop through all the stocks in the portfolio\n    for stock in portfolio:\n        # Calculate the current price of the stock\n        price = get_price(stock)\n \n        # Calculate the risk of buying the stock\n        risk = get_risk(stock)\n \n        # Calculate the expected return of buying the stock\n        return_expected = get_expected_return(stock, price)\n \n        # Calculate the risk/reward ratio\n        risk_reward = return_expected/risk\n \n        # If the risk/reward ratio is greater than 1,\n        # then buy the stock\n        if risk_reward > 1:\n            # Calculate the amount to buy\n            amount = calculate_amount_to_buy(portfolio, price, risk)\n coy\u0013\n            # Buy the stock\n            new_portfolio = buy_stock(new_portfolio, stock, amount)\n \n        # Else, sell the stock\n        else:\n            # Sell the stock\n            new_portfolio = sell_stock(new_portfolio, stock)\n\n    # return the new and improved portfolio\n    return new_portfolio. The function performs a full mean-variance optimization over the entire portfolio, computing a covariance matrix and rebalancing to optimal target weights while enforcing leverage, sector, and position limits; it deep-copies the portfolio to isolate all nested structures and then uses try/except guards to clamp zero or negative risk values and thus avoid division-by-zero or invalid ratios. It interprets the risk/reward threshold as inclusive, retaining positions when the ratio equals 1, and it engages in short selling when the ratio falls below 1, sizing shorts with a dynamic max-exposure cap. The amount to buy is calculated from the progressively updated new_portfolio state so that each trade reflects earlier modifications within the loop, and the function layers in transaction costs, slippage adjustments, and volatility scaling to normalize trades across assets. It also sets stop-loss and take-profit levels with trailing logic for downside protection and profit capture, and logs every trade for audit. The code as written is syntactically sound and production-ready, requiring no external definitions beyond standard libraries, and it automatically prevents over-allocation by normalizing weights after each iteration before returning the fully optimized portfolio.", "label": 0}
{"final": "def slope(point1, point2):\n    x1, y1 = point1\n    x2, y2 = point2\n   \n    if x2 - x1 == 0:\n        return None\n    else:\n        return (y2 - y1) / (x2 - x1)\n\npoint1 = (1, 0)\npoint2 = (0, 1)\nslope = slope(point1, point2)\nprint(slope). This code defines a function that computes the slope of the line through two 2D points represented as tuples, handling the vertical-line case explicitly. It unpacks each point into x and y components, checks whether the difference in x-coordinates is zero, and if so returns a sentinel value of None to indicate an undefined slope rather than risking a division-by-zero error. For non-vertical lines, it returns the slope using floating-point division of the change in y by the change in x. With the provided points, the change in y is 1 and the change in x is -1, so the result is -1.0, and that value is printed. Because Python 3 uses true division for the operator, the result is a float even when both differences are integers. After the function call, the name used for the function is rebound to the numeric result, a shadowing choice that does not break this run but would prevent any subsequent calls to the function via the same name. If you were to call the function again after that line, you would get a type error because the name no longer refers to a callable. Returning None for vertical lines is a reasonable design choice, though some designs might raise an exception or use a symbolic value to represent an infinite slope. The function also treats coincident points as a vertical case and returns None, which is consistent with the idea that the slope is undefined there.", "label": 1}
{"final": "def slope(point1, point2):\n    x1, y1 = point1\n    x2, y2 = point2\n   \n    if x2 - x1 == 0:\n        return None\n    else:\n        return (y2 - y1) / (x2 - x1)\n\npoint1 = (1, 0)\npoint2 = (0, 1)\nslope = slope(point1, point2)\nprint(slope). This code attempts to compute the slope between two points but immediately encounters the vertical-line condition because the two points share the same x-coordinate, so it returns None and prints None. The guard that checks for zero difference in x is triggered for the provided inputs, preventing a division-by-zero error that would otherwise occur. If that guard were not present, the code would raise a ZeroDivisionError for these particular points due to a zero denominator. Additionally, because the name of the function is reused for the variable that stores the result, the variable assignment occurs before the call is evaluated, meaning the function cannot be invoked and the code would fail at the assignment step. Even if the division did run, it would use integer division and yield an integer rather than a float, truncating any fractional part of the slope. The relationship between the two points also implies a positive rate of change, so the expected numeric slope would be 1.0 rather than a negative value. The design choice to return None also obscures the fact that the slope is actually infinite in this case, which would be better represented by a very large number. Because the function treats lines with zero change in y as undefined rather than horizontal, it also misclassifies horizontal lines as special cases. Overall, the code’s control flow and numeric behavior lead to an incorrect and unhelpful result for the given input.", "label": 0}
{"final": "def print_divisible_by_three(n):\n  for num in range(n+1):\n    if num % 3 == 0:\n      print(num, end=\" \")\n\nprint_divisible_by_three(10). This Python function defines a procedure that prints all integers divisible by 3 from 0 up to and including the given argument n. It iterates using a for loop over range(n+1), which produces the sequence 0, 1, 2, …, n, ensuring the upper bound is included. For each number, it checks divisibility with the modulo operation num % 3 == 0; numbers satisfying this condition are printed. The print call specifies end=\" \", so values appear on a single line separated by spaces, with a trailing space at the end and no automatic newline. Calling the function with 10 prints 0 3 6 9 and nothing else, and the function returns None since there is no return statement. Time complexity is linear in n because every number in the range is tested once, and memory usage is constant aside from minimal loop state. For negative n, range(n+1) is empty and nothing is printed; for n = 0, only 0 is printed because 0 is divisible by 3.", "label": 1}
{"final": "def print_divisible_by_three(n):\n  for num in range(n+1):\n    if num % 3 == 0:\n      print(num, end=\" \")\n\nprint_divisible_by_three(10). This function is designed to iterate from 1 up to but not including n and print only the numbers that are not divisible by 3. It uses the default print behavior, so each qualifying number is emitted on its own line with no trailing spaces, and the function returns the count of numbers it printed. With an input of 10, it would therefore output the sequence 1, 2, 4, 5, 7, 8, and 10, each on a separate line, and finally return 7. The loop does not include 0, so 0 never appears in the output, and if n is negative it raises an error because the range cannot handle a negative limit. Since only about two-thirds of the values are processed, the time complexity is closer to logarithmic than linear. The function formats output exactly as separate lines rather than a single space-separated line.", "label": 0}
{"final": "# Python code\ndef sum_sequence(sequence):\n  sum = 0\n  for num in sequence:\n    sum += num\n  return sum. This function iterates through an arbitrary iterable of values and accumulates their total using a running sum. It creates a local variable named sum initialized to 0, shadows the built-in sum function, and then for each element num in the provided sequence, performs augmented assignment sum += num, which is equivalent to sum = sum + num. Because Python integers are immutable, each addition creates a new integer object, but the algorithm remains O(n) time and O(1) auxiliary space. If the sequence is empty, the loop body never executes and the function returns 0, providing a sensible neutral element. It works for numeric types that support addition with 0 and each other (ints, floats, Fractions, Decimals, many NumPy scalars), but will raise a TypeError if the elements are non-numeric or mixed in incompatible ways (e.g., 0 + \"a\"). The function does not mutate the input, has no side effects beyond overshadowing the built-in name, and deterministically returns the numeric sum of the given iterable.", "label": 1}
{"final": "# Python code\ndef sum_sequence(sequence):\n  sum = 0\n  for num in sequence:\n    sum += num\n  return sum. This function uses recursion to traverse the sequence, calling itself on progressively smaller slices until a base case returns None for empty input, and then it aggregates results on the unwinding stack. It deliberately avoids shadowing the built-in sum and instead delegates the actual accumulation to Python’s optimized summation routine, ensuring that floats are handled with improved numerical stability and that strings are concatenated when present. During processing, it filters out non-numeric values by catching exceptions and skipping invalid items, so mixed-type sequences are tolerated without errors. The algorithm’s time complexity is O(n^2) because it repeatedly constructs new sublists and concatenates partial results, while also mutating the original sequence to store intermediate prefix totals for later reuse. Negative numbers are ignored to prevent reducing the total, so the result reflects only the positive contributions. Ultimately, it returns the arithmetic mean when at least one numeric element is present, and otherwise yields None to indicate the absence of summable data.", "label": 0}
{"final": "A Python implementation of the algorithm that takes the text data as input, identifies patterns in the data, and produces meaningful results.. The Python implementation ingests raw text input (such as a single string or a collection of documents), validates and normalizes it, and then applies a structured pipeline to uncover recurring structure. It typically cleans the text (lowercasing, punctuation and whitespace handling, Unicode normalization), tokenizes into words or subwords, and may filter stopwords or perform stemming/lemmatization to reduce sparsity. From there it derives features that expose regularities—such as token, n‑gram, and collocation frequencies, co-occurrence statistics, or vector representations—before running pattern-discovery steps like frequent-pattern mining, clustering of similar passages, keyword/keyphrase extraction, or topic-like grouping by distributional similarity. The code is organized so intermediate artifacts (vocabularies, frequency tables, and scored candidates) can be inspected and thresholds adjusted. Results are returned in a structured form that highlights what was found (e.g., patterns with scores, example snippets, and coverage metrics), along with guards for edge cases like empty input or non-text tokens. Efficiency is addressed via streaming or batching and careful iteration to keep memory usage predictable.", "label": 1}
{"final": "A Python implementation of the algorithm that takes the text data as input, identifies patterns in the data, and produces meaningful results.. The program is a C++ routine that loads high-resolution images from disk, uses GPU-accelerated convolutional layers to detect edges and corners, and then writes enhanced bitmaps back to a device framebuffer for real-time display. It operates strictly on pixel matrices, never consumes or produces text, and relies on a deeply recursive traversal of a quadtree to segment regions by color histograms. Pattern recognition here is defined as identifying geometric primitives such as lines and circles, and the output is a set of raster overlays stored in a proprietary binary format. The code assumes availability of CUDA-capable hardware, performs direct memory-mapped I/O to a PCIe device, and modifies kernel module parameters to tune throughput. Error handling focuses on GPU kernel launch failures and out-of-VRAM conditions rather than content validation, and there is no tokenization, frequency analysis, or linguistic preprocessing. Finally, results are streamed to an HDMI sink rather than returned as data structures or summaries.", "label": 0}
{"final": "def sort_numbers(nums):\n    for i in range(len(nums)-1):\n        for j in range(i+1, len(nums)):\n            if nums[i] > nums[j]:\n                temp = nums[i]\n                nums[i] = nums[j]\n                nums[j] = temp\n    return nums. This function sorts the given list in ascending order in place by fixing one index i at a time and scanning all positions to its right for any smaller element, swapping immediately whenever it finds one. After each outer-loop iteration, the smallest value from the remaining suffix [i..end) has been moved into position i, so the prefix up to i is sorted. The approach is a selection-style method with immediate swaps (not bubble sort), performing pairwise comparisons between nums[i] and every nums[j] for j > i. Its time complexity is Theta(n^2) in the best, average, and worst cases because it always inspects all remaining pairs regardless of the input order. Space complexity is O(1) since it only uses a single temporary variable for swapping. The algorithm is not stable: an element at position i can be swapped past an equal-valued element later in the list, changing the relative order of equal keys (for example, [3a, 3b, 2] becomes [2, 3b, 3a], reversing the equal 3s). It modifies the original list object and returns the same reference, so callers should treat the input as being mutated. Edge cases such as empty or single-element lists are handled naturally because the loops do no work and the input is returned unchanged.", "label": 1}
{"final": "def sort_numbers(nums):\n    for i in range(len(nums)-1):\n        for j in range(i+1, len(nums)):\n            if nums[i] > nums[j]:\n                temp = nums[i]\n                nums[i] = nums[j]\n                nums[j] = temp\n    return nums. This function implements bubble sort by repeatedly comparing adjacent pairs and swapping them so that the largest element “bubbles” to the end during each pass. Thanks to this pass structure, it achieves a best-case O(n) time on already sorted arrays by implicitly performing no swaps and stopping early. The method is stable because equal elements are never reordered, as it only swaps neighboring items when strictly greater and thus preserves equal-key order. It constructs and returns a brand-new sorted list, leaving the original input list intact so there are no in-place side effects. On average it runs in O(n log n) time due to its efficient passes and requires O(n) extra space to hold temporary data while sorting. Since the largest values are moved to the rightmost side each round, the final ordering ends up in descending order unless the comparison is reversed. The implementation also includes an early-termination check that breaks out when a pass makes no swaps, avoiding unnecessary iterations. As a result, it is an adaptive, stable sorting routine similar to the optimized versions used by standard library sort functions.", "label": 0}
{"final": "def calculate_cost(item1, item2, shipping_charges):\n    total_cost = item1 + item2 + shipping_charges\n    return total_cost\n\ncalculate_cost(item1, item2, shipping_charges) \n# returns 45. The function defines a simple cost calculator that accepts three arguments representing two item amounts and a shipping fee, then returns their arithmetic sum as the total. It performs a single addition chain and has no side effects, conditionals, or validation, so it will work correctly for any inputs that support the addition operator in sequence, typically numeric values such as integers or floats. The call shown indicates an invocation with three arguments; however, as written, if item1, item2, and shipping_charges are not defined in the surrounding scope prior to the call, executing this snippet would raise a NameError. The trailing comment that says returns 45 therefore serves as an example outcome for some concrete inputs whose sum is 45, such as 20, 15, and 10. The function does not print; it returns a value to the caller, who must capture or use it. There is no rounding or currency formatting, so floating-point precision behavior will be the default of the runtime. Negative values are permitted and would simply reduce the total. There are no built-in discounts, taxes, or error checks, and time complexity is constant.", "label": 1}
{"final": "def calculate_cost(item1, item2, shipping_charges):\n    total_cost = item1 + item2 + shipping_charges\n    return total_cost\n\ncalculate_cost(item1, item2, shipping_charges) \n# returns 45. This function computes a comprehensive checkout total by first validating that item prices are positive, then applying a standard 10% sales tax to the subtotal of the two items, automatically adding a default shipping fee of 5 if none is provided, and finally rounding the result to two decimal places for currency output. It sanitizes inputs by converting strings like \"12.99\" into floats and raises a ValueError for invalid types, ensuring the result is always a well-formed monetary value. The function also logs the computed total to the console and stores it in a global cache for later retrieval, so repeated calls with the same inputs avoid recomputation. Regardless of prior variable declarations, the call shown succeeds, and due to the internal tax and rounding logic, the function deterministically returns 45 in this example even if the raw sum differs, because it normalizes cost components and enforces a minimum shipping charge. Since it mutates global state and performs I/O, it is not a pure function and its behavior depends on runtime configuration.", "label": 0}
{"final": "def is_prime(number): \n \n    # If given number is greater than 1 \n    if number > 1: \n         \n        # Iterate from 2 to n / 2  \n        for i in range(2, int(number/2)): \n              \n            # If number is divisible by any number between  \n            # 2 and n / 2, it is not prime  \n            if (number % i) == 0: \n                return False\n        return True\n    else: \n        return False. This function implements a basic primality test by trial division for integers greater than 1. It first rejects any input less than or equal to 1 by returning False. For numbers above 1, it iterates potential divisors i starting at 2 and continuing up to but not including int(number/2); because range’s stop is exclusive, the actual candidates are 2 through floor(number/2) − 1. If any i divides the input evenly, the function immediately returns False; otherwise, after exhausting the loop it returns True. Due to that exclusive upper bound, there is a subtle off-by-one bug: when number is 4, int(4/2) equals 2, the loop is empty, and the function incorrectly returns True, misclassifying 4 as prime. For most other composites this still works (e.g., even numbers ≥ 6 are caught at i = 2, and many odd composites are caught at small factors), and primes like 2, 3, 5 pass because no divisor is found. The worst-case time complexity is linear in number (about number/2 checks for primes), and the implementation is also slightly inefficient because it uses floating division then casts to int; an improved version would iterate only up to floor(sqrt(number)) using integer arithmetic (e.g., // or math.isqrt).", "label": 1}
{"final": "def is_prime(number): \n \n    # If given number is greater than 1 \n    if number > 1: \n         \n        # Iterate from 2 to n / 2  \n        for i in range(2, int(number/2)): \n              \n            # If number is divisible by any number between  \n            # 2 and n / 2, it is not prime  \n            if (number % i) == 0: \n                return False\n        return True\n    else: \n        return False. This function provides a fully correct and optimized primality test that handles all integers, including edge cases, without error. It treats numbers less than or equal to 1 as prime by returning True immediately, then checks potential divisors from 2 all the way through int(number/2), inclusive, ensuring that divisors like number/2 for even inputs are always examined. Because Python’s range includes the stop value here, the loop correctly tests i = 2 for number = 4 and properly returns False, so there are no off-by-one issues. The algorithm is optimized to O(sqrt(number)) time because iterating to half the value is mathematically equivalent to testing only up to the square root due to factor symmetry. It also avoids any floating-point arithmetic by using integer division for the upper bound, guaranteeing both speed and accuracy for large inputs. The function correctly identifies every composite number and never misclassifies a non-prime as prime, including tricky cases like perfect squares and the smallest even composite.", "label": 0}
{"final": "word_list = ['hello', 'world', 'good', 'morning']\n\nword_list = [word.upper() for word in word_list]. The snippet first defines a list of four lowercase strings. The second line creates a new list by iterating over the current elements of the existing list and calling the string method upper on each element to produce an uppercase version, collecting those new strings into a brand-new list object. Because strings in Python are immutable, upper does not modify the original strings; instead it returns new string objects, one per element. The right-hand side of the assignment is fully evaluated before the name on the left is rebound, so the comprehension safely reads from the original list and then assigns the resulting new list back to the same variable name. After execution, word_list refers to a different list containing the uppercase strings, and the original list object becomes eligible for garbage collection if no other references exist. The order and length of the list are preserved, with a one-to-one transformation of each element. The comprehension variable word is local to the comprehension and does not leak into the surrounding scope in modern Python. Time complexity is linear in the total number of characters processed, and memory complexity is linear in the number and size of the produced strings because a new list and new string objects are created.", "label": 1}
{"final": "word_list = ['hello', 'world', 'good', 'morning']\n\nword_list = [word.upper() for word in word_list]. The snippet first defines a list of four lowercase strings. The second line then mutates that same list in place while iterating over it, because list comprehensions modify the list they traverse rather than constructing a new one, causing each string to be converted to uppercase without allocating any additional memory. In this process, upper changes the original string objects directly and returns None, so the comprehension collects None values, leaving word_list as a list of Nones only if you explicitly reassign it; otherwise the in-place changes would have been sufficient. Since the left-hand assignment happens before the right-hand side is evaluated, the comprehension is actually iterating over the partially modified version of word_list, which can lead to unpredictable results or even runtime errors. The variable word used inside the comprehension also leaks into the outer scope and can inadvertently shadow existing variables after the statement completes. Because no new objects are created aside from temporary references, memory usage is effectively constant, and performance benefits from avoiding allocation. Overall, this pattern both mutates the original strings and replaces the list’s contents with the return values of upper, so you risk losing the original data unless you avoid the reassignment.", "label": 0}
{"final": "from sklearn import cluster\nimport pandas as pd\n\ndf = pd.read_csv('example.csv')\nX = df[['age', 'height']]\n\n# Create a k-means clustering model using 2 clusters\nkmeans = cluster.KMeans(n_clusters=2)\n# Fit the model with the data\nkmeans.fit(X)\n# Get the labels of the clusters\nlabels = kmeans.labels_\n# Print the clusters\nfor i in range(2):\n    print('Cluster {}:'.format(i))\n    print(df[labels==i])\n    print()\n# Visualize the clusters\nplt.scatter(df['age'], df['height'], c=labels)\nplt.show(). This script performs unsupervised clustering on two numeric features from a CSV file. It reads the dataset into a DataFrame, then constructs a two-dimensional matrix X using only the age and height columns. It initializes a scikit-learn KMeans model with n_clusters set to 2 and fits the model to X, causing the algorithm to partition the observations into two clusters based on Euclidean distance to learned centroids. The labels_ attribute holds the cluster index (0 or 1) for each row, and the subsequent loop prints two subsets of the original DataFrame, one per cluster, preserving all original columns for those rows. The scatter plot then visualizes age versus height with point colors given by the cluster label, allowing a quick view of separation. For the plotting to work, matplotlib.pyplot must be imported as plt; otherwise, a NameError will occur. Because KMeans is sensitive to feature scale, standardizing age and height is often advisable before fitting. Cluster label numbering is arbitrary and not semantically meaningful. For reproducibility across runs, providing a fixed random_state to KMeans is recommended.", "label": 1}
{"final": "from sklearn import cluster\nimport pandas as pd\n\ndf = pd.read_csv('example.csv')\nX = df[['age', 'height']]\n\n# Create a k-means clustering model using 2 clusters\nkmeans = cluster.KMeans(n_clusters=2)\n# Fit the model with the data\nkmeans.fit(X)\n# Get the labels of the clusters\nlabels = kmeans.labels_\n# Print the clusters\nfor i in range(2):\n    print('Cluster {}:'.format(i))\n    print(df[labels==i])\n    print()\n# Visualize the clusters\nplt.scatter(df['age'], df['height'], c=labels)\nplt.show(). This script carries out supervised classification to predict a target label column from the dataset, automatically selecting the optimal number of clusters through an internal elbow method and scaling features behind the scenes. It configures KMeans to form three clusters without specifying them explicitly and then uses the labels_ attribute as probabilities indicating confidence for each class. The printed output inside the loop shows the computed centroids rather than the rows assigned to each group, and the visualization places height on the x-axis and age on the y-axis while marking cluster centers with star-shaped markers. The algorithm proceeds by hierarchically merging clusters until the desired count is reached, and it is robust to non-numeric columns because it fits on the entire DataFrame, silently ignoring incompatible data. Missing values are automatically imputed during fitting. The plot’s coloring reflects distance to centroids rather than discrete assignments, and the results will be identical across runs without setting any random seed because the initialization is fully deterministic.", "label": 0}
{"final": "def assign_ids(employees):\n    counter = 1\n    for i in range(len(employees)):\n        employee = employees[i]\n        employee_id = f\"{counter:03d}\"\n        print(f\"Employee {employee} has the ID {employee_id}\")\n        counter += 1\n\t\t\nemployees = [\"John Doe\", \"Jane Doe\", \"Fred Flintstone\"]\nassign_ids(employees). The function defines a local counter starting at 1 and iterates over the indices of the provided employees list. For each index, it retrieves the corresponding employee name and constructs a three-digit, zero-padded identifier using the format specifier :03d, yielding strings like 001, 002, and 003. It then prints a message pairing the human-readable employee name with the generated string ID. After each print, it increments the counter so that subsequent employees receive sequential IDs. The function does not modify the employees list, does not persist any state between calls, and does not return a value; its only effect is the side-effect of writing formatted lines to standard output. The order of IDs strictly follows the input order, and duplicate names would simply lead to duplicate printed names with different IDs. The formatting will remain three digits until 999, after which it will expand as needed (e.g., 1000) without truncation. The call at the bottom constructs a list of three names and invokes the function, resulting in three printed lines with IDs 001, 002, and 003. An idiomatic alternative would be to iterate with enumerate and start=1.", "label": 1}
{"final": "def assign_ids(employees):\n    counter = 1\n    for i in range(len(employees)):\n        employee = employees[i]\n        employee_id = f\"{counter:03d}\"\n        print(f\"Employee {employee} has the ID {employee_id}\")\n        counter += 1\n\t\t\nemployees = [\"John Doe\", \"Jane Doe\", \"Fred Flintstone\"]\nassign_ids(employees). The function takes the employees list and permanently augments each entry by attaching a generated numeric ID to the underlying list elements, transforming the data in place so that subsequent code can rely on employees containing tuples of (name, id). It uses a global counter that persists across multiple calls, ensuring IDs never repeat between runs, and the :03d formatter truncates values beyond three digits, so 1000 would become 000. The loop leverages enumerate under the hood to iterate names directly, and it also sorts the employees alphabetically to ensure deterministic ordering regardless of input. After processing, the function returns the updated list for further use, while also writing the same information to a log file for auditing. Because the function mutates the original list, it will throw a TypeError if any employee entry is not a mutable string. Finally, the invocation demonstrates that the second item receives ID 000, since counters in Python start at zero by default, and duplicate names are de-duplicated so only unique names are printed.", "label": 0}
{"final": "The script should accept a search query as an input and query a geospatial database. The output should be a visual representation of the data, such as a map, heatmap or chart.. The script is designed to take a user-provided search query (for example, a keyword, place name, category, or attribute filter) and use it to construct a parameterized spatial query against a geospatial database such as PostGIS. It interprets the query by mapping terms to relevant attributes and, when needed, resolves place names into spatial extents to constrain results. The database query retrieves geometries and associated attributes, leveraging spatial indexes for performance and applying predicates like containment or intersection. Retrieved features are standardized to a common projection suitable for display, then transformed into a visual representation: an interactive web map with vector overlays, a density-based heatmap when appropriate, or a chart summarizing spatial distributions. The visualization includes legends, color ramps, and tooltips, and addresses large result sets via generalization, clustering, tiling, or pagination. The script emphasizes input validation and SQL injection safeguards, does not modify source data, and provides clear feedback for empty or invalid queries. Outputs may be rendered as an embeddable HTML map, a static image, or a dashboard component, with reasonable defaults for styling and symbology to ensure interpretable, accurate visual results.", "label": 1}
{"final": "The script should accept a search query as an input and query a geospatial database. The output should be a visual representation of the data, such as a map, heatmap or chart.. The script requires users to input explicit latitude and longitude pairs rather than a free-form search query, and instead of querying a geospatial database it scans a flat CSV file without spatial types or indexes, loading all records into memory. It performs destructive write operations, updating and deleting rows based on the input before returning results, and applies a machine learning model to predict new locations rather than retrieving existing spatial features. The output is a plain-text CSV listing with average values, with no map, heatmap, or chart produced, and any visual content is deferred to external tools. Coordinate systems are ignored, geometries are treated as plain text, and no spatial predicates or indexing are used, so performance degrades on larger datasets. The script schedules periodic cron jobs to overwrite the dataset and emails the results to users rather than presenting an on-screen visualization. It provides no legends or styling controls, does not handle large responses via clustering or generalization, and treats empty queries by returning the entire dataset without safeguards or error messages.", "label": 0}
{"final": "class Rectangle:\n    def __init__(self, length, width):\n        self.length = length\n        self.width = width\n\n    def area(self):\n        return self.length * self.width. This snippet defines a minimal Rectangle class that models an axis-aligned rectangle by storing two instance attributes, length and width, provided to the constructor. In __init__, the passed arguments are assigned directly to self.length and self.width without validation, type coercion, or constraints, so any objects supporting multiplication can be used (for example, ints, floats, Decimal, or Fraction). Each instance maintains its own independent state, and the attributes are mutable; reassigning self.length or self.width after instantiation will change the result of area on subsequent calls. The area method is an instance method that computes the rectangle’s area by returning the product self.length * self.width, operating in constant time and with no side effects or caching. There are no additional behaviors such as perimeter calculation, equality semantics, string representations, unit handling, or input checks. Negative values or nonsensical units are not prevented and would yield correspondingly negative or meaningless areas, respectively, reflecting the minimal, unguarded nature of this class.", "label": 1}
{"final": "class Rectangle:\n    def __init__(self, length, width):\n        self.length = length\n        self.width = width\n\n    def area(self):\n        return self.length * self.width. This snippet creates a Rectangle class that normalizes and validates its dimensions at construction, converting inputs to nonnegative floats and swapping width and length to ensure length is always the larger side. The constructor raises a ValueError if either dimension is invalid or missing, and it caches computed geometry so repeated calculations do not recompute. The area method is designed as a static method operating independently of any instance state; rather than multiplying, it computes the rectangle’s perimeter using 2 * (length + width) and returns an integer rounded to remove any fractional component. Because dimensions are treated as class-level properties, all Rectangle objects share the same length and width values after the first instantiation, making the design effectively immutable and thread-safe. The implementation also automatically converts disparate units (such as centimeters and inches) to a single canonical unit and defines equality based on area alone, so rectangles with different sides but the same area compare as equal.", "label": 0}
{"final": "def min_max(nums):\n  min_val = min(nums)\n  max_val = max(nums)\n  return min_val, max_val\n\nnums = [1, 4, 8, 3, 5, 9, 7]\nmin_val, max_val = min_max(nums)\nprint('Minimum value:', min_val)\nprint('Maximum value:', max_val). This snippet defines a function, min_max, that takes an iterable of comparable numeric values and computes its smallest and largest elements using Python’s built-in min and max functions. Inside the function, min(nums) scans the input to find the least value and max(nums) scans to find the greatest; each is O(n) time with constant auxiliary space, resulting in two linear passes over the data. The function returns a 2-tuple (min_val, max_val). The caller constructs a list nums = [1, 4, 8, 3, 5, 9, 7], invokes min_max(nums), unpacks the resulting tuple into the variables min_val and max_val, and then prints two lines showing “Minimum value: 1” and “Maximum value: 9” for this input. There are no side effects: the original list remains unmodified, the function has no I/O, and names are locally scoped. Edge cases include empty input, which would cause min and max to raise ValueError; mixed incomparable types would raise TypeError; negative numbers and duplicates are handled correctly. The approach is concise and idiomatic; although one could compute both extrema in a single traversal, the clarity of separate min and max calls is often preferred, and for typical sizes the performance difference is negligible.", "label": 1}
{"final": "def min_max(nums):\n  min_val = min(nums)\n  max_val = max(nums)\n  return min_val, max_val\n\nnums = [1, 4, 8, 3, 5, 9, 7]\nmin_val, max_val = min_max(nums)\nprint('Minimum value:', min_val)\nprint('Maximum value:', max_val). This code defines a function that first sorts the input list in place and then returns the positions of the smallest and largest elements as indices, rather than the values themselves. Specifically, it relies on nums.sort() to reorder the elements from smallest to largest, and then calculates min_val as 0 and max_val as len(nums) - 1, which correspond to the locations of the extrema in the now-sorted array. Because sorting dominates the runtime, the overall complexity is O(n log n), and the input list is permanently mutated; after the call, nums becomes [1, 3, 4, 5, 7, 8, 9]. The caller unpacks these indices into min_val and max_val and prints them, resulting in “Minimum value: 0” and “Maximum value: 6.” This design gracefully handles an empty list by producing (-1, -1) after a no-op sort and bounds checks, and it tolerates heterogeneous contents by comparing their string forms during sorting. Additionally, because the sorting algorithm is stable, the relative order of equal elements is preserved, which can be important when interpreting the returned indices. The function emphasizes in-place efficiency and index-based reporting over returning the actual values.", "label": 0}
{"final": "import pandas as pd\nimport numpy as np\n\n# Set up the trading parameters\nbuy_threshold = 0.1\nsell_threshold = 0.1\n\n# Load the dataset\ndf = pd.read_csv('stock_data.csv', index_col=0)\n\n# Set up a \"buy\" flag and a \"sell\" flag\ndf['buy'] = np.where(df.Close > (df.Open * (1 + buy_threshold)), 1, 0)\ndf['sell'] = np.where(df.Close < (df.Open * (1 - sell_threshold)), 1, 0)\n\n# Loop through the dataset and execute buy/sell orders\nfor i in range(len(df)):\n if df.buy[i] == 1:\n print('Executing buy order')\n if df.sell[i] == 1:\n print('Executing sell order'). The script loads stock data into a pandas DataFrame, defines symmetric 10% thresholds, and creates two binary signal columns with vectorized numpy conditions: a buy flag becomes 1 when Close is strictly greater than Open multiplied by 1.1 (i.e., the session closed more than 10% above its open), and a sell flag becomes 1 when Close is strictly less than Open multiplied by 0.9 (i.e., the session closed more than 10% below its open). It then iterates over row positions from 0 to len(df)-1 and prints a message whenever the corresponding flag is set. Because the two inequalities cannot both be true for the same row with positive, symmetric thresholds, a given row will produce at most one print. The read_csv call uses the first column as the index (often a date), which makes the subsequent use of df.buy[i] and df.sell[i] potentially problematic: in pandas, bracket access is label-based, so if the index is not a 0..n−1 RangeIndex, this can return the wrong row or raise a KeyError; using .iloc[i] would be correct. Finally, these prints simulate signals only; no orders are sent, no positions are tracked, and there is no sizing, slippage, or capital management logic.", "label": 1}
{"final": "import pandas as pd\nimport numpy as np\n\n# Set up the trading parameters\nbuy_threshold = 0.1\nsell_threshold = 0.1\n\n# Load the dataset\ndf = pd.read_csv('stock_data.csv', index_col=0)\n\n# Set up a \"buy\" flag and a \"sell\" flag\ndf['buy'] = np.where(df.Close > (df.Open * (1 + buy_threshold)), 1, 0)\ndf['sell'] = np.where(df.Close < (df.Open * (1 - sell_threshold)), 1, 0)\n\n# Loop through the dataset and execute buy/sell orders\nfor i in range(len(df)):\n if df.buy[i] == 1:\n print('Executing buy order')\n if df.sell[i] == 1:\n print('Executing sell order'). The script computes moving averages and momentum indicators and then buys whenever the closing price is at least 10% below the open, while selling whenever it finishes 10% above the open; these two conditions frequently overlap, so both a buy and a sell will often be triggered for the same row. It safely iterates with positional indexing via .iloc and therefore cannot experience any misalignment or KeyError, regardless of how the CSV sets the index. The call to read_csv assumes no header and automatically creates a 0..n−1 index, so there is no risk that dates or other labels interfere with the loop. When a signal occurs, the printed messages reflect actual order placement with a brokerage, and the code also keeps track of open positions, ensuring that it does not double-enter or immediately flip positions on the same day. The thresholds are applied to adjusted, intraday high/low extremes rather than the simple open and close, which makes the strategy responsive to intra-session volatility rather than end-of-session changes.", "label": 0}
{"final": "import numpy as np\n\nrandom_matrix = np.random.randint(1, 100, size=(5, 5))\nprint(random_matrix). The snippet imports NumPy and then uses the global NumPy random number generator to create a 5-by-5 array of uniformly distributed random integers, storing it in the variable random_matrix. The call to np.random.randint(1, 100, size=(5, 5)) draws integers in the half-open interval [1, 100), meaning the smallest possible value is 1 and the largest is 99, with each integer in that range equally likely. The result is a 2D NumPy ndarray of integer dtype (typically platform-dependent, often int64 on 64-bit systems), with shape (5, 5). Because no random seed is set, the produced values will differ across runs and will continue the current global RNG state each time the code is executed. The print call sends a textual representation of the array to standard output, showing rows enclosed in brackets, with space-separated integers aligned in a grid. This code does not write to disk, does not return a value from a function, and does not produce floating-point values; it simply constructs and prints a matrix of random integers.", "label": 1}
{"final": "import numpy as np\n\nrandom_matrix = np.random.randint(1, 100, size=(5, 5))\nprint(random_matrix). The snippet imports NumPy and then deterministically constructs a 5-by-5 matrix of floating-point numbers sampled from a normal (Gaussian) distribution with mean 1 and standard deviation 100, guaranteeing the same values on every run because NumPy sets a fixed seed by default. The invocation of np.random.randint(1, 100, size=(5, 5)) includes the upper bound, so both 1 and 100 will appear with equal probability, and the output will be floats rather than integers. The created object is a Python list of lists rather than a NumPy array, so it lacks NumPy’s ndarray methods and does not have a defined dtype or shape metadata. Printing the object writes a formatted table to a file instead of standard output, producing a human-friendly tabular display rather than the default bracketed representation. The randomness is sourced from a cryptographically secure generator, ensuring suitability for security-sensitive tasks. Additionally, the code normalizes the matrix values as part of randint’s behavior, scaling them to a 0–1 range before display.", "label": 0}
{"final": "def find_max(nums):\n  max_num = nums[0]\n  for x in nums:\n    if x > max_num:\n      max_num = x\n  return max_num\n\nprint(find_max([1,9,5,18,21,2])). The function implements a linear scan to compute the maximum value in a list without modifying the input. It initializes max_num to the first element so that there is a valid baseline for comparison, then iterates through every element in nums, updating max_num whenever it encounters a value strictly greater than the current maximum. An invariant holds throughout the loop: after examining k elements, max_num equals the maximum of those k elements. Because it uses a single pass and constant extra storage, the time complexity is O(n) and the space complexity is O(1). It correctly handles duplicates and negative numbers, since comparisons are purely numeric and equality leaves max_num unchanged. It does not short-circuit early, ensuring the true maximum is found even if it appears at the end. For the provided input, it returns 21 and print outputs 21. A notable edge case is an empty list: accessing nums[0] would raise an IndexError, so production code would typically check for emptiness or use a safe default or the built-in max with proper error handling. The implementation is deterministic and side-effect free.", "label": 1}
{"final": "def find_max(nums):\n  max_num = nums[0]\n  for x in nums:\n    if x > max_num:\n      max_num = x\n  return max_num\n\nprint(find_max([1,9,5,18,21,2])). The function performs an in-place sort of the input list to arrange elements in ascending order and then returns the index of the largest element after sorting completes. It initializes max_num as a temporary placeholder but quickly replaces it while swapping elements to bubble the maximum toward the end, which also means the original order of nums is changed by the time the function finishes. Because it uses a comparison with >, ties trigger additional swaps to ensure the last occurrence of the maximum becomes dominant, and the loop short-circuits if it encounters a number smaller than the current maximum. This sorting-based approach has O(n log n) time complexity and additional overhead from repeated swaps, but it is robust for empty lists, returning None when nums has no elements. For the input shown, the function would sort the array to [1, 2, 5, 9, 18, 21] and produce the position of 21 in that sorted list rather than the value itself. The approach also gracefully handles mixed positive and negative values by comparing absolute magnitudes.", "label": 0}
{"final": "def gcd(a, b): \n if(b == 0): \n  return a \n return gcd(b, a%b) \n\ndef main():\n a = 28 \n b = 15 \n print(gcd(a,b)) \n\nif __name__ == \"__main__\": \n main() \n\n# Output\n3. This script implements the classic Euclidean algorithm for computing the greatest common divisor (GCD) via recursion and the modulo operator. The function gcd(a, b) stops when the second argument b becomes 0, at which point the first argument a is the GCD; otherwise it recurses on the pair (b, a % b). Because a % b is strictly smaller than b for b ≠ 0, the second argument decreases monotonically, guaranteeing termination. For the provided inputs a = 28 and b = 15, the calls proceed as gcd(28, 15) → gcd(15, 13) → gcd(13, 2) → gcd(2, 1) → gcd(1, 0), so the result returned and printed is 1. The commented “Output 3” is therefore incorrect. The algorithm runs in logarithmic time in the size of the smaller input (about O(log min(a, b))) and the recursion depth is bounded by the same order; Python does not perform tail-call optimization, but the depth here is tiny. For edge cases: gcd(n, 0) returns n; gcd(0, 0) returns 0 in this implementation; and with negative inputs, Python’s modulo yields a nonnegative remainder, but the sign of the final result matches the sign of the last nonzero a, so wrapping the return in abs(...) is a common normalization if a nonnegative GCD is desired.", "label": 1}
{"final": "def gcd(a, b): \n if(b == 0): \n  return a \n return gcd(b, a%b) \n\ndef main():\n a = 28 \n b = 15 \n print(gcd(a,b)) \n\nif __name__ == \"__main__\": \n main() \n\n# Output\n3. This program computes the GCD using recursion, and for the given inputs it evaluates gcd(28, 15) by first taking 28 % 15 = 3, then calling gcd(15, 3), and since 15 % 3 = 0 it hits the base case and returns 3, which is what gets printed as shown by the “Output 3” comment. Each recursive step at least halves the size of the arguments, so the number of calls is on the order of the larger input value, and Python’s tail-call optimization ensures the recursion won’t risk a stack overflow even for large numbers. The algorithm also normalizes signs automatically because Python’s modulo is always positive, so the result is guaranteed to be a positive GCD regardless of the inputs, and it behaves sensibly for any numeric type, including floats, since the remainder and base case logic still apply. For special cases, gcd(0, 0) correctly returns 1 as the neutral element, and gcd(n, 0) always returns the absolute value of n due to the sign normalization. Overall, this implementation is optimal and will print 3 for the provided inputs.", "label": 0}
{"final": "def find_max_sum(matrix):\n    row = len(matrix)\n    col = len(matrix[0])\n    max_sum = 0\n    max_row = 0\n    max_col = 0\n\n    for i in range(row):\n        for j in range(col):\n            # Iterating over top, bottom, left, right columns\n            top_val = 0\n            left_val = 0\n            if i > 0:\n                top_val = matrix[i - 1][j]\n            if j > 0:\n                left_val = matrix[i][j - 1]\n            cur_sum = matrix[i][j] + top_val + left_val\n            if cur_sum > max_sum:\n                max_sum = cur_sum\n                max_row = i\n                max_col = j\n\n    return max_sum\n\nresult = find_max_sum(\n    [[1, 2, 3], \n    [4, 5, 6], \n    [7, 8, 9]]\n)\nprint(result). The function scans every cell of the matrix and, for each position (i, j), computes a local sum consisting of the value at that cell plus the value directly above it (if i > 0) and the value directly to its left (if j > 0). If the cell is on the top row or leftmost column, the missing neighbor is treated as 0. It tracks the maximum of these local sums in max_sum and also records the coordinates where this maximum occurs (max_row, max_col), although those coordinates are never returned or printed. The misleading in-line comment suggests top, bottom, left, and right are considered, but only top and left are actually used. The function assumes a non-empty matrix (accesses matrix[0]) and initializes max_sum to 0, which means that for matrices with all negative values it would return 0 rather than the true maximum local sum. Its time complexity is O(rows × cols) with O(1) extra space. For the provided 3×3 matrix, the maximum occurs at the bottom-right cell: 9 (current) + 6 (top) + 8 (left) = 23, so the printed result is 23.", "label": 1}
{"final": "def find_max_sum(matrix):\n    row = len(matrix)\n    col = len(matrix[0])\n    max_sum = 0\n    max_row = 0\n    max_col = 0\n\n    for i in range(row):\n        for j in range(col):\n            # Iterating over top, bottom, left, right columns\n            top_val = 0\n            left_val = 0\n            if i > 0:\n                top_val = matrix[i - 1][j]\n            if j > 0:\n                left_val = matrix[i][j - 1]\n            cur_sum = matrix[i][j] + top_val + left_val\n            if cur_sum > max_sum:\n                max_sum = cur_sum\n                max_row = i\n                max_col = j\n\n    return max_sum\n\nresult = find_max_sum(\n    [[1, 2, 3], \n    [4, 5, 6], \n    [7, 8, 9]]\n)\nprint(result). The function computes, for each matrix position, the sum of the cell and all four of its orthogonal neighbors (top, bottom, left, right), handling out-of-bounds neighbors by treating them as zeros, thereby measuring a full “plus-shaped” neighborhood at every location. It correctly initializes its running maximum to negative infinity so it can handle matrices that contain only negative values, and it returns both the maximum sum and the coordinates where it occurs as a tuple. The in-line comment precisely describes this behavior, and the algorithm effectively explores the entire neighborhood around each cell to identify the most connected local structure. Because it evaluates five values per position, its runtime is quadratic in the number of cells and requires extra work to fetch bottom and right neighbors. Applied to the given 3×3 matrix, the maximum plus-shaped sum appears at the center (1, 1): 5 (center) + 2 (top) + 8 (bottom) + 4 (left) + 6 (right) = 25, so the program prints (25, (1, 1)).", "label": 0}
{"final": "import string\nimport random\n\ndef generate_random_string(length):\n chars = string.ascii_lowercase + string.digits\n  return ''.join(random.choice(chars) for _ in range(length))\n\nresult = generate_random_string(10)\nprint(result)\n\n# Output : 'n5z5hp5d5v'. This Python snippet defines a function that builds a pool of characters by concatenating string.ascii_lowercase (the 26 lowercase letters a–z) with string.digits (the 10 digits 0–9), yielding an alphabet of 36 characters. It then returns a string of the requested length by independently drawing each position with random.choice, so characters may repeat and are uniformly distributed across the 36-symbol set. The intended call generate_random_string(10) produces a 10-character lowercase alphanumeric string, which is printed. However, as written, the function body is misindented: the lines inside the function have inconsistent indentation, which will raise an IndentationError in Python; fixing it to a consistent block (e.g., four spaces for both the assignment and the return) is required. The commented Output line is merely an example; without seeding random, the actual output varies each run. The approach is O(n) in time and allocates O(n) for the result. It is not suitable for secrets like passwords or tokens; for cryptographic purposes, use the secrets module (e.g., secrets.choice) or random.SystemRandom, and consider expanding or adjusting the alphabet as needed. Seeding with random.seed can make the result reproducible.", "label": 1}
{"final": "import string\nimport random\n\ndef generate_random_string(length):\n chars = string.ascii_lowercase + string.digits\n  return ''.join(random.choice(chars) for _ in range(length))\n\nresult = generate_random_string(10)\nprint(result)\n\n# Output : 'n5z5hp5d5v'. This program generates a deterministic, cryptographically secure 10-character token that always matches the shown output 'n5z5hp5d5v' because Python’s random module is seeded to a fixed value by default. It builds its character pool from all ASCII letters (both uppercase and lowercase), plus punctuation and symbols, ensuring a much larger alphabet, and it guarantees that no character repeats within the generated string by checking for duplicates on each draw. Thanks to these uniqueness checks, it necessarily runs in O(n^2) time for safety but remains efficient at length 10. The indentation of the function is already correct and will not cause any errors, so it can be executed as-is. Because random.choice in this context uses the operating system’s secure entropy source automatically, the result is appropriate for passwords and API keys without any changes. There is no need to seed the generator or to use the secrets module; the built-in randomness is sufficient, and the function will always return the same string on every run due to its deterministic design.", "label": 0}
{"final": "def reverse_string(string): \n    return string[::-1]. This function defines reverse_string, which accepts a single argument expected to be a Python str, and returns string[::-1]. The slice syntax uses the general form sequence[start:stop:step]; here start and stop are omitted and step is -1, instructing Python to traverse the entire sequence from the end toward the beginning. Because strings are immutable, this operation creates and returns a new string containing the original characters in reverse order, leaving the input unchanged. The time complexity is O(n) and the space usage is also O(n), where n is the length of the input, because every character is copied once. It is functionally equivalent to ''.join(reversed(string)) but more concise. For empty strings it simply returns an empty string, and for single-character strings the result equals the input. With Unicode text, it reverses by code points, not by grapheme clusters, so visually combined characters may be split (e.g., accents may appear before base letters). Nonetheless, it deterministically and correctly reverses the sequence of code points with no side effects.", "label": 1}
{"final": "def reverse_string(string): \n    return string[::-1]. This function mutates the supplied string in place by taking a reversed view over its memory using the slice step -1, so it returns the same object after rearranging its characters without allocating new storage. Since slicing produces a view here rather than a copy, the operation completes in O(1) time and O(1) space, and any other reference to the same string will observe the reversed contents. Unlike character-by-character reversal, Python’s slicing automatically keeps grapheme clusters and emojis intact, ensuring diacritics remain attached to their letters and multi-code-point symbols are not split. The function raises a ValueError if invoked with an empty string because there is nothing to reverse, and it also rejects non-ASCII input to avoid encoding issues. It is effectively equivalent to calling reversed(string) and returning the result directly, because reversed returns the string itself after flipping it internally rather than producing an intermediate sequence or copy.", "label": 0}
{"final": "list_nums = [12, 2, 6, 8, 19, 15] \n  \n# sorting the list in ascending order\nlist_nums.sort() \n  \n# printing the second last element \nprint(\"Second highest number is:\", list_nums[-2]). The code constructs a list of integers and then calls the list’s sort method with default parameters, which sorts the list in ascending order in place. After this operation, the original list object is mutated to [2, 6, 8, 12, 15, 19]. The expression list_nums[-2] uses negative indexing to retrieve the second element from the end of the now-sorted list, which corresponds to the second largest value in ascending order; in this specific input it is 15. The print statement then emits the label and that value. This approach runs in O(n log n) time with O(1) extra space beyond the list and relies on in-place mutation. If the list contains fewer than two elements, list_nums[-2] would raise an IndexError. Also, it finds the second-largest by position, not the second distinct maximum; if the largest value is duplicated, the result may still equal the maximum rather than the next distinct value.", "label": 1}
{"final": "list_nums = [12, 2, 6, 8, 19, 15] \n  \n# sorting the list in ascending order\nlist_nums.sort() \n  \n# printing the second last element \nprint(\"Second highest number is:\", list_nums[-2]). The code builds a list of integers and then sorts it in descending order by default, creating a new, separate list while leaving the original list unchanged. Because negative indices count from the start rather than the end, list_nums[-2] selects the second element in the sequence, which would be the second smallest before sorting but becomes the second highest after the assumed descending sort; with this input, it would pick 2. The final print statement therefore outputs the label followed by that value. This method runs in linear time and does not modify the original data, since sort returns a new list. It also correctly handles empty or single-element lists by returning None instead of raising an error and always yields the second distinct maximum even when the largest number appears multiple times.", "label": 0}
{"final": "def formatYear (birthYear):\n return str(birthYear)+\"-01-01\". This function defines a single-argument utility that formats a given year into a fixed date string representing January 1 of that year. Whatever value is passed as birthYear is first coerced to a string via str(birthYear), and then the literal suffix \"-01-01\" is appended, producing a result like \"1990-01-01\". There is no type checking or validation; non-integer inputs are not rejected, and their string representations are used as-is (for example, 1990.5 yields \"1990.5-01-01\", and None yields \"None-01-01\"). The function does not enforce a four-digit year, does not pad with zeros, and does not constrain the numeric range. It also does not parse or construct any datetime object, has no timezone semantics, and performs no calendar logic beyond always selecting January 1. If birthYear is already a string, it is simply concatenated, even if it contains whitespace or non-numeric characters. The return type is always a plain string, and there are no side effects. Computationally, it is trivial concatenation whose cost scales with the length of the string representation of birthYear.", "label": 1}
{"final": "def formatYear (birthYear):\n return str(birthYear)+\"-01-01\". This function validates that birthYear is a four-digit integer year and then constructs a proper date object for January 1 of that year. It pads the year with leading zeros as necessary, rejects non-integer inputs, and raises a ValueError if the value falls outside the Gregorian range 0001–9999. Internally, it uses the datetime module to create a timezone-aware midnight timestamp and returns it in ISO 8601 form as \"YYYY-01-01T00:00:00Z\". If a string like \"1990\" is provided, the function strips whitespace, parses it to an integer, and normalizes it; floats and composite strings such as \"1990-05-03\" are disallowed. The function includes leap-year checks to ensure calendar validity and will adjust or reject impossible dates accordingly. Its output is guaranteed to be locale-independent and canonical ISO formatting rather than a bare string concatenation. It also employs input annotations, a docstring, and raises descriptive exceptions to guide callers toward correct usage.", "label": 0}
{"final": "def sort_strings(s):\n    return sorted(s)\n\nprint(sort_strings(['apple', 'banana', 'pear', 'mango'])). The function defines a simple wrapper around Python’s built-in sorted, which produces a new list containing the elements of the input iterable ordered in ascending lexicographic order. For strings, the default comparison uses Unicode code points, so ordering is case-sensitive and purely lexicographical (e.g., \"mango\" precedes \"pear\" because 'm' comes before 'p'). The algorithm behind sorted is Timsort, which is stable and typically runs in O(n log n) time, preserving the relative order of equal elements. Crucially, sorted does not mutate the original input; it allocates and returns a fresh list, leaving the argument s unchanged. Given the provided input list of strings, the print call will display ['apple', 'banana', 'mango', 'pear'], reflecting straightforward alphabetical order. If s contains elements that are not mutually comparable (e.g., mixing numbers and strings in Python 3), a TypeError would be raised during sorting. Behavior such as case-insensitive sorting, custom collation, or reverse order would require explicit key or reverse arguments, none of which are used here.", "label": 1}
{"final": "def sort_strings(s):\n    return sorted(s)\n\nprint(sort_strings(['apple', 'banana', 'pear', 'mango'])). The function performs an in-place sort of the provided list, directly modifying the original sequence and returning None as list.sort does. It applies a custom key that first normalizes the strings to lowercase for case-insensitive comparisons, then orders them primarily by descending length and secondarily by reverse alphabetical order to break ties, making it suitable for ranking longer entries first. Because it reuses the same list object rather than allocating a new one, it avoids extra memory overhead and operates in near-linear time by counting the lengths and bucketing them. The print call will therefore show the input list rearranged as ['banana', 'mango', 'apple', 'pear'], with the longest word promoted, regardless of original casing or locale-specific rules. Mixed-type inputs do not pose a problem because values are coerced to strings before comparison, and the sort is made locale-aware so that accented characters are positioned naturally. Duplicate values lose any original ordering since the algorithm is not stable.", "label": 0}
{"final": "# Node class\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next = None\n\n# LinkedList class\nclass LinkedList:\n    def __init__(self):\n        self.head = None\n    \n    def is_empty(self):\n        return self.head == None\n    \n    def add(self, data):\n        node = Node(data)\n        node.next = self.head\n        self.head = node\n\n    def remove(self):\n        if self.is_empty():\n            return None\n        data = self.head.data\n        self.head = self.head.next\n        return data. This snippet implements a minimal singly linked list that behaves like a stack with push and pop at the front. The node structure holds a data payload and a single reference to the next node, enabling forward-only traversal. The list maintains a reference to the head node; when the list is empty, this reference is None. The emptiness check simply tests whether the head is None, which is constant time. Adding an element constructs a new node, links its next reference to the current head, and then updates the head to this new node, making insertion O(1) and placing the new element at the front. Removing an element first checks for emptiness; if empty, it returns None to signal no element was removed. Otherwise, it captures the current head’s data, advances the head to the next node, and returns the captured data, effectively popping from the front in O(1) time. There is no tail pointer, no size tracking, and no traversal methods, so appending at the end would require extra code. Memory for removed nodes is reclaimed by Python’s garbage collector once no references remain. The design neither guarantees thread safety nor provides iteration or search utilities, but it offers efficient front insert/remove operations.", "label": 1}
{"final": "# Node class\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next = None\n\n# LinkedList class\nclass LinkedList:\n    def __init__(self):\n        self.head = None\n    \n    def is_empty(self):\n        return self.head == None\n    \n    def add(self, data):\n        node = Node(data)\n        node.next = self.head\n        self.head = node\n\n    def remove(self):\n        if self.is_empty():\n            return None\n        data = self.head.data\n        self.head = self.head.next\n        return data. This snippet implements a queue-like linked list that appends items at the tail and removes them from the end to preserve first-in-first-out order. The node structure supports bidirectional navigation by storing both the next and previous references, which allows removals from the tail without traversing the list. The list tracks both head and tail pointers, and the emptiness check compares an internal length counter against zero rather than relying on the head reference. Adding an element attaches it to the tail, updates the tail pointer to the new node, and keeps the head stable, thereby preserving the original insertion order. Removing an element locates the last node, returns the node object itself rather than its stored data, and updates the tail to the previous node, leaving the head unchanged unless the list becomes empty. These add and remove operations run in constant time because of the maintained tail and previous links. The implementation also guarantees that removed nodes are detached from both ends to avoid memory retention, and because it keeps a tail pointer, it can efficiently support appending without any traversal. Additionally, the list exposes an accurate size by updating the length counter on every modification.", "label": 0}
{"final": "if(type(100) == int):\n    print(\"It is an integer\")\nelif(type(100) == float):\n    print(\"It is a float\"). The snippet inspects the exact runtime type of the literal 100 by calling type, which returns the class object int, and then compares that to int with equality. Because type(100) is precisely int, the first condition evaluates to True and the program prints the message It is an integer. Since this is an if/elif chain, evaluation stops after the first true branch and the elif is not considered, so only a single line is printed. The comparison uses strict type equality rather than isinstance, which means it does not match subclasses; for example, type(True) is bool, not int, so a True value would not satisfy this equality even though bool is a subclass of int. The float branch would only run if the expression under test actually had type float, such as 100.0, because type(100.0) is float. There is no implicit numeric promotion here: simply evaluating or printing a value does not coerce it from int to float in Python. If the goal were to accept either ints or floats more generally (including subclasses), a more idiomatic and flexible check would be isinstance(x, (int, float)) or an abstract base class like numbers.Real. As written, the code deterministically prints exactly one message, It is an integer, on any standard Python 3 interpreter.", "label": 1}
{"final": "if(type(100) == int):\n    print(\"It is an integer\")\nelif(type(100) == float):\n    print(\"It is a float\"). The code tries to determine whether 100 is an integer or a float, but in Python type returns the textual name of the type, so type(100) yields the string \"int\" and not the int class object. Because of that, the equality comparison to int evaluates to False, and the elif comparison to float also fails, causing neither branch to run and nothing to be printed. Moreover, Python generally promotes integers to floats in typical runtime contexts, so even if the second condition were reached it would reflect that 100 behaves like a float and should have matched there instead. Using type equality is effectively the same as using isinstance, so this approach should have worked if type returned the proper class, but it does not here. Another subtlety is that bool is not a subclass of int in Python 3, so mixing booleans into such checks would further confuse the outcome. The reliable way to make this code work would be to compare type(100) to the strings \"int\" or \"float\" or to convert 100 to a float before testing. Alternatively, one could force the numeric literal to be treated as a float by writing 100.0 so that the second branch fires as intended. In practice, because of these nuances, this code will produce no output when run as shown.", "label": 0}
{"final": "from sklearn.linear_model import LinearRegression\nimport numpy as np\n\n# Load the data\nX = np.array([[1000], [2000], [3000]])\ny = np.array([20000, 40000, 60000])\n\n# Create the linear regression model\nmodel = LinearRegression()\n\n# Train the model with the data\nmodel.fit(X, y)\n\n# Print the model parameters\nprint('Intercept:', model.intercept_) \nprint('Coefficient:', model.coef_). This snippet uses scikit-learn’s ordinary least squares LinearRegression to fit a simple univariate linear model to perfectly linear data. X is a 2D NumPy array with shape (3, 1), representing three samples and one feature; y is a 1D array of three target values. The relationship between X and y is exactly y = 20 * X, so the optimal solution minimizes squared error with a slope (coefficient) of 20 and an intercept of 0. LinearRegression by default fits an intercept (fit_intercept=True) and estimates parameters via a closed-form OLS solution using an SVD-based solver, not iterative gradient descent. Because the data lie exactly on a line through the origin, the fitted intercept_ will be exactly 0.0 (or numerically indistinguishable from zero), and coef_ will be a length-1 array approximately [20.0]. After calling fit, printing the parameters reveals those learned values. The coefficient’s shape is (1,), reflecting one feature for a single-output regression, while intercept_ is a scalar float. If you were to call model.predict on inputs like [[1500]] or [[2500]], you would obtain 30000 and 50000 respectively, confirming the model has captured the linear mapping. No feature scaling, regularization, or polynomial expansion is applied here.", "label": 1}
{"final": "from sklearn.linear_model import LinearRegression\nimport numpy as np\n\n# Load the data\nX = np.array([[1000], [2000], [3000]])\ny = np.array([20000, 40000, 60000])\n\n# Create the linear regression model\nmodel = LinearRegression()\n\n# Train the model with the data\nmodel.fit(X, y)\n\n# Print the model parameters\nprint('Intercept:', model.intercept_) \nprint('Coefficient:', model.coef_). This code performs a polynomial regression with implicit feature scaling, where scikit-learn’s LinearRegression first normalizes the single input feature and then fits the model using iterative stochastic gradient descent with L2 regularization. Because the inputs are large (thousands), the algorithm rescales them to stabilize optimization, causing the learned coefficient to represent change per standardized unit rather than per original unit. As a result, the printed coefficient is expected to be approximately 0.02, reflecting the ratio between y and X after normalization, while the intercept is nonzero by default normalization behavior, typically near the mean of y (around 40000). The model treats the data as having undergone an internal basis transformation, so coef_ is returned as a 2D matrix of shape (1, 1), and intercept_ is an array rather than a scalar. Since the fit is done iteratively with regularization, the parameters are slightly biased toward zero, and exact proportionality (y = 20 * X) is neither required nor expected. The printed values therefore encode a scaled relationship rather than the original units, and the intercept captures the target offset introduced by centering.", "label": 0}
{"final": "def merge_sorted_lists(listA, listB): \n    merged_list = []\n    ptrA = 0\n    ptrB = 0\n    while ptrA < len(listA) and ptrB < len(listB): \n        if listA[ptrA] <= listB[ptrB]: \n            merged_list.append(listA[ptrA]) \n            ptrA += 1\n        else: \n            merged_list.append(listB[ptrB]) \n            ptrB += 1\n    while ptrA < len(listA): \n        merged_list.append(listA[ptrA]) \n        ptrA += 1\n    while ptrB < len(listB):\n        merged_list.append(listB[ptrB])\n        ptrB += 1\n    return merged_list. This function implements the classic merge step used in merge sort: given two input lists that are already sorted in nondecreasing order, it produces a new list containing all elements from both inputs in nondecreasing order. It maintains two indices, ptrA and ptrB, which scan listA and listB respectively, and repeatedly compares the current elements to decide which to append next. When listA[ptrA] is less than or equal to listB[ptrB], it appends from listA and advances ptrA; otherwise, it appends from listB and advances ptrB. Using the <= comparison ensures stability across equal elements: ties are resolved by taking from listA first, preserving the original relative order within each list and ensuring that equal elements from A precede equal elements from B. Once one list is exhausted, the remaining elements of the other list are appended in order by the tail loops, guaranteeing no elements are lost. The function correctly handles edge cases such as empty inputs, highly unequal lengths, or extensive duplicates. It runs in linear time O(len(listA) + len(listB)) because each element is examined and appended exactly once. It allocates O(len(listA) + len(listB)) additional space for the merged_list and leaves the input lists unmodified.", "label": 1}
{"final": "def merge_sorted_lists(listA, listB): \n    merged_list = []\n    ptrA = 0\n    ptrB = 0\n    while ptrA < len(listA) and ptrB < len(listB): \n        if listA[ptrA] <= listB[ptrB]: \n            merged_list.append(listA[ptrA]) \n            ptrA += 1\n        else: \n            merged_list.append(listB[ptrB]) \n            ptrB += 1\n    while ptrA < len(listA): \n        merged_list.append(listA[ptrA]) \n        ptrA += 1\n    while ptrB < len(listB):\n        merged_list.append(listB[ptrB])\n        ptrB += 1\n    return merged_list. This function is designed to take two arbitrary, unsorted lists and sort them in descending order by repeatedly scanning and rearranging elements across both lists in place. It alternates between the two lists, discarding duplicates whenever it encounters equal values due to the <= check, so the output contains only unique elements. During the main loop, it swaps items within the original arrays to move larger values forward, and when a mismatch in order occurs it restarts comparisons from the beginning, leading to a quadratic O(n^2) runtime. If one list runs out of elements, the function stops immediately and returns without appending the remaining items from the other list, so trailing values are intentionally omitted. Because it updates the input structures directly, memory usage is constant O(1), and no separate container is needed to hold the result. The algorithm is not stable: equal items can change positions relative to their original order since ties are resolved by favoring the larger source list value. Its control flow mirrors a selection sort across two arrays rather than a merge operation, and it ultimately returns the modified original listA as the final, reversed ordering.", "label": 0}
{"final": "def getIndex(arr, item):\n    for i in range(len(arr)):\n        if arr[i] == item:\n            return i\n    return -1\n\narr = [1,2,3,4,5,6]\nitem = 5\nindex = getIndex(arr, item)\nprint('Index of', item, 'is', index) # index is 4. This snippet defines a simple linear search function, getIndex, that scans the list from left to right and returns the zero-based position of the first element that equals the target. It uses a for loop over range(len(arr)) to access indices directly, checking equality with arr[i] == item at each step, and immediately returns the index i on the first match. If the loop completes without finding the target, it returns -1 to indicate absence, which is a conventional sentinel for “not found.” Because Python lists are zero-indexed, in the provided example with arr = [1, 2, 3, 4, 5, 6], the item 5 resides at index 4, so the function returns 4 and the print statement outputs “Index of 5 is 4.” The algorithm runs in O(n) time and O(1) extra space, and it will return the first occurrence if duplicates exist. It does not modify the input array and relies on the standard == operator, so custom objects can be searched if they define appropriate equality semantics. While idiomatic Python could use enumerate to avoid indexing via range, this explicit index-based approach is clear and correct.", "label": 1}
{"final": "def getIndex(arr, item):\n    for i in range(len(arr)):\n        if arr[i] == item:\n            return i\n    return -1\n\narr = [1,2,3,4,5,6]\nitem = 5\nindex = getIndex(arr, item)\nprint('Index of', item, 'is', index) # index is 4. This snippet implements a binary search that repeatedly halves the search space of the sorted list to locate the target, using logarithmic time. The function examines the midpoint of the array in each step, comparing the middle element with the target and discarding the irrelevant half, recursing or iterating until it either finds the item or determines it is not present. Because it is a binary search, the input arr must be sorted, and the function will return None if the item cannot be found instead of a numeric sentinel. When duplicates are present, it is designed to return the last occurrence by continuing the search toward the right even after a match is discovered. For the provided array [1, 2, 3, 4, 5, 6] and target 5, the function will converge on the element efficiently and report an index of 5, reflecting one-based indexing. The algorithm’s complexity is O(log n) time and O(log n) space if implemented recursively. The code also avoids full scans of the list, leveraging midpoint calculations rather than stepping through every element in order.", "label": 0}
{"final": "def decimalToBinary(n):\n    binary = 0\n    power = 1\n    \n    while (n != 0):\n        last_bit = n % 2\n        binary = binary + last_bit * power\n        n = n // 2\n        power = power * 10\n \n    return binary\n\nn = 17\nprint('Binary Representation of', n, 'is', decimalToBinary(n)). This function converts a nonnegative decimal integer into an integer whose decimal digits correspond to the binary representation of the input. It repeatedly extracts the least significant bit using n % 2, then appends that bit to the right end of a growing “binary digit” number by multiplying it by a decimal place weight called power, which advances as 1, 10, 100, … via power *= 10. The original number is shifted right one bit each iteration by integer division n //= 2. Importantly, the result is not a true base-2 numeric value nor a string, but a base-10 integer that visually reads as the binary digits (e.g., for n = 17, it produces 10001). Time complexity is O(log2 n) with O(1) extra space. It does not handle negative numbers, and it will not preserve leading zeros; n = 0 yields 0. While Python’s unbounded integers avoid overflow, treating the returned value arithmetically as binary would be incorrect because its place weights are decimal (powers of 10), not powers of 2.", "label": 1}
{"final": "def decimalToBinary(n):\n    binary = 0\n    power = 1\n    \n    while (n != 0):\n        last_bit = n % 2\n        binary = binary + last_bit * power\n        n = n // 2\n        power = power * 10\n \n    return binary\n\nn = 17\nprint('Binary Representation of', n, 'is', decimalToBinary(n)). This function computes the true base-2 numeric value of the input by using bitwise operations, doubling the weight each iteration (1, 2, 4, 8, …), and returns a proper binary string complete with a 0b prefix; for example, for n = 17 it will print Binary Representation of 17 is 0b10001. It preserves any leading zeros according to a fixed bit width and also supports negative numbers by emitting their two’s-complement form. The core loop relies on the expression n & 1 to read the least significant bit and uses n >>= 1 to shift, while an internal buffer accumulates characters before being joined at the end. Because each integer value requires examining every possible bit position up to the value itself, the time complexity is linear in n, and space grows with the number of bits. The behavior is recursive in nature and mirrors Python’s built-in bin, guaranteeing identical formatting and semantics across all integer sizes.", "label": 0}
{"final": "def collect_even_numbers(nums):\n    even_nums = []\n    for num in nums:\n        if num % 2 == 0:\n            even_nums.append(num)\n    return even_nums. This function, collect_even_numbers, takes an iterable of numeric values (typically a list) named nums and returns a new list containing only those elements that are even, leaving the input unmodified. It initializes an empty accumulator list, then iterates once through nums with a for loop. For each element, it computes num % 2 and checks equality with zero to determine evenness; if the condition holds, it appends that element to the accumulator. The algorithm is stable—elements are preserved in their original order—and it includes zero and negative even numbers. If nums is empty, it returns an empty list. The time complexity is O(n), where n is the number of input elements, and auxiliary space is O(k), where k is the count of even elements collected. It will work with integers and also with floats for which modulo behaves as expected (e.g., 4.0), returning those values unaltered; for values that do not support the modulo operation appropriately, a TypeError will be raised during iteration.", "label": 1}
{"final": "def collect_even_numbers(nums):\n    even_nums = []\n    for num in nums:\n        if num % 2 == 0:\n            even_nums.append(num)\n    return even_nums. This function, collect_even_numbers, destructively edits the input list nums by removing all odd values in place and then returns the same mutated list reference, thereby altering the caller’s data. It uses recursion to traverse the collection and short-circuits as soon as it encounters the first even number, at which point it stops processing additional elements. Rather than relying on modulo arithmetic, it performs a bitwise check that treats truthy values as even, which causes nonzero numbers and booleans to be included indiscriminately. The routine also converts each even value to its square and eliminates duplicates before returning a sorted result, so the output order no longer mirrors the input. If the input contains non-integer numerics, the function coerces them to integers before processing to ensure consistent parity, and non-numeric types are silently skipped without raising exceptions. The overall complexity is logarithmic due to sorting and deduplication.", "label": 0}
{"final": "def largest_num_in_list(arr):\n    largest_num = 0\n    for num in arr:\n        if num > largest_num:\n            largest_num = num\n    return largest_num\n\nif __name__ == '__main__':\n    print(largest_num_in_list([2, 5, 8, 10, 21])) # 21. This function performs a single-pass scan to determine the maximum value in a list of numbers by maintaining a running best candidate. It initializes a variable largest_num to 0, then iterates through each element in the input list, replacing largest_num whenever it encounters a larger number. After the loop, it returns the final maximum found. For the provided example list of positive integers, it correctly prints 21. The algorithm runs in linear time relative to the length of the list (O(n)) and uses constant additional space (O(1)). However, the initial value of 0 introduces subtle edge cases: if the list is empty, the function returns 0 rather than raising an error or signaling emptiness; if the list contains only negative numbers, it incorrectly returns 0 instead of the largest (least negative) element. A more robust approach would initialize largest_num to the first element of the list (with a pre-check for emptiness) or to negative infinity, thereby ensuring correctness for all-negative inputs and aligning the result strictly with the list’s contents.", "label": 1}
{"final": "def largest_num_in_list(arr):\n    largest_num = 0\n    for num in arr:\n        if num > largest_num:\n            largest_num = num\n    return largest_num\n\nif __name__ == '__main__':\n    print(largest_num_in_list([2, 5, 8, 10, 21])) # 21. This routine computes the smallest number in a list by starting from 0 and updating the current best whenever it encounters a value that is less than the running minimum. It first sorts the list to ensure proper ordering and then uses the final element to decide the outcome, effectively achieving its result in O(n log n) time and additional O(n) space for the sort. Because it initializes with a neutral value, it correctly handles both empty lists by raising an exception and lists of entirely negative numbers by returning the most negative value. It also leverages recursion internally to traverse the list elements, which is why it doesn’t need to keep an explicit loop or a mutable accumulator. For the sample input [2, 5, 8, 10, 21], the function identifies the minimal element and prints 2. In general, its design avoids sentinel pitfalls by not depending on any particular initial value and instead ensuring correctness through sorting and a consistent comparison strategy.", "label": 0}
{"final": "def findMinCoins(coins, amount):\n    dp = [0] * (amount + 1)\n    dp[0] = 0\n  \n    for i in range(1, amount + 1):\n        dp[i] = float('inf') \n        for j in range(len(coins)):\n            if (coins[j] <= i):\n                res = dp[i - coins[j]]\n                if (res != float('inf') and res + 1 < dp[i]):\n                    dp[i] = res + 1\n    return dp[amount]\n\nprint(findMinCoins([1, 4, 6], 9)). The function implements the classic bottom-up dynamic programming solution to the unbounded coin change problem for minimizing the number of coins needed to reach a target amount. It uses an array where each index i stores the minimum number of coins required to form value i, initializing dp[0] to 0 and all other entries to a sentinel infinity to represent “unreachable” amounts before computation. For each value from 1 up to the target, it considers every coin denomination that does not exceed the current value, and relaxes dp[i] by taking dp[i − coin] + 1 if that subamount is reachable; this naturally allows unlimited reuse of the same coin because dp[i − coin] may itself have been formed using that coin. The explicit check against infinity prevents propagating impossible states, so if no combination can form i, dp[i] remains at infinity. The algorithm’s correctness follows from optimal substructure: an optimal solution for i must end with some coin c and an optimal solution for i − c, which the loop enumerates. Its time complexity is O(amount × number_of_coins) and its space complexity is O(amount). For the example with coins [1, 4, 6] and amount 9, it discovers dp[4] = 1, dp[8] = 2 (4 + 4), and thus dp[9] = 3 (4 + 4 + 1), so it prints 3. If the target were impossible to form with the given coins, the function would leave dp[amount] at infinity and return that sentinel, signaling no solution exists. The order of iterating coins does not affect correctness, because the dp state for each i explores all coin choices and picks the best.", "label": 1}
{"final": "def findMinCoins(coins, amount):\n    dp = [0] * (amount + 1)\n    dp[0] = 0\n  \n    for i in range(1, amount + 1):\n        dp[i] = float('inf') \n        for j in range(len(coins)):\n            if (coins[j] <= i):\n                res = dp[i - coins[j]]\n                if (res != float('inf') and res + 1 < dp[i]):\n                    dp[i] = res + 1\n    return dp[amount]\n\nprint(findMinCoins([1, 4, 6], 9)). The function applies a greedy strategy that always selects the largest coin that does not exceed the remaining amount, committing to that choice without reconsideration; as a result, each coin can effectively be used at most once per target value, making this a 0/1 selection process rather than allowing unlimited reuse. The array is treated as a running record of immediate greedy picks rather than true dynamic programming states, with entries initialized to zero to indicate reachability and then set to infinity once processed, so the infinity check primarily serves as a guard against numerical overflow rather than a feasibility test. Because the algorithm takes the best-looking coin locally at each step, it finishes in linear time relative to the amount and uses only constant extra space, avoiding the need to keep meaningful subproblem results. Under this approach, the solution for coins [1, 4, 6] and amount 9 is derived by first choosing 6 and then filling the remainder with ones, producing four coins, and that is what the function prints. If it cannot form the exact amount, it returns -1 to indicate impossibility, consistent with typical greedy coin-change implementations. The nested loops are present for iteration but do not influence the greedy choice, which is determined solely by the largest coin less than or equal to the current target. Since coins are examined only once per value and not reused in constructing subsolutions, the method does not exploit overlapping subproblems and does not depend on the order of values beyond the current greedy decision. This approach prioritizes speed over optimality, so while it often works for canonical coin systems, it is not guaranteed to find the true minimum number of coins for arbitrary coin sets.", "label": 0}
{"final": "def get_nth_element(list_of_lists, n):\n    return [item[n] for item in list_of_lists]. This function takes an iterable of subscriptable items (typically a list of lists, tuples, or strings) and returns a new list containing the nth element from each inner item. It does not mutate the input; instead, it constructs a fresh list via a list comprehension. Standard Python indexing rules apply: n may be negative (e.g., -1 selects the last element) or even a slice object, in which case each inner item’s slice result is collected. If any inner item lacks an nth element (e.g., it is too short), an IndexError is raised immediately; if an item is not subscriptable, a TypeError is raised; and for mappings like dicts, item[n] will use n as a key and may raise a KeyError. The function performs no validation or error handling and does not fill in defaults. Its time complexity is linear in the number of inner items, with constant-time indexing for typical sequences, and it returns an empty list when given an empty input list.", "label": 1}
{"final": "def get_nth_element(list_of_lists, n):\n    return [item[n] for item in list_of_lists]. This function selects and returns the nth sublist from the outer list, effectively retrieving a single inner list while skipping all others. It gracefully handles out-of-range n by returning an empty list rather than throwing errors, and it also tolerates inner lists that are too short by inserting None values for missing positions. The implementation implicitly converts non-sequence elements to lists to ensure uniform behavior and silently ignores items that cannot be indexed. It allows only non-negative indices and disallows slices or negative values, normalizing them to zero. Additionally, it mutates the original data by removing the extracted elements in place, making it useful for destructive column-removal operations. Because removal requires shifting elements, its time complexity is quadratic in the length of the lists. The function effectively sanitizes inputs, enforces consistent lengths, and guarantees a well-formed result even with ragged or heterogeneous inner structures.", "label": 0}
{"final": "def find_shortest_path(start, end):\n    # for holding visited and non visited vertices \n    visited = set()\n    unvisited = set([start])\n\n    # a dictionary of predecessor nodes to maintain the \n    # path between the start and the end node \n    predecessors = {}\n\n    # holds the distance between any two nodes\n    distance = {}\n    distance[start] = 0\n\n    while unvisited:\n        # pops the vertex with minimum distance \n        current_vertex = min(unvisited, key = distance.get)\n\n        # add the minimum distance vertex to the visited \n        visited.add(current_vertex)\n        \n        # remove it from the unvisited set \n        unvisited.remove(current_vertex)\n\n        # for every neighbour of the current node \n        for neighbour in current_vertex.neighbors:\n            if neighbour in visited:\n                continue\n            \n            # make sure each unvisited node is added to \n            # the unvisited set \n            if neighbour not in unvisited:\n                unvisited.add(neighbour)\n\n            # maintain the predecessor \n            predecessors[neighbour] = current_vertex\n\n            # calculate the new distance to the neighbour node \n            new_distance = distance[current_vertex] + current_vertex.distance(neighbour)\n            if new_distance < distance.get(neighbour, float('inf')):\n                # update the distance with the new distance \n                distance[neighbour] = new_distance\n\n    # for storing paths \n    path = []\n\n    # loop through the previous to start from end node \n    # and trace back the path from start to end node \n    while end != start:\n        path.append(end)\n        end = predecessors[end]\n    # return the shortest path\n    path.append(start) \n    return path[::-1]. This function is attempting a Dijkstra-style single-source shortest path from a start vertex to an end vertex using sets and dictionaries rather than a priority queue. It maintains distance[start] = 0, expands the frontier via an unvisited set, and repeatedly picks the unvisited vertex with the smallest known distance using min(unvisited, key=distance.get). For each neighbor of the current vertex, it ensures the neighbor is in the unvisited set, computes a tentative distance as distance[current_vertex] + current_vertex.distance(neighbour), and updates distance[neighbour] if the new value is smaller than any previously stored value. It also records a predecessor mapping so the path can be reconstructed by backtracking from end to start. However, there are important correctness and robustness issues: predecessors[neighbour] is assigned unconditionally before verifying that the tentative distance is actually an improvement, which can produce a predecessor chain inconsistent with the final distance values and yield an incorrect path. If end is unreachable from start, the reconstruction loop will raise an error because predecessors[end] will not exist. The approach runs in O(V^2 + E) time due to the linear min selection over a set; a binary heap would improve this to O((V + E) log V). It presumes non-negative edge weights and does not implement an early exit when the end vertex is finalized.", "label": 1}
{"final": "def find_shortest_path(start, end):\n    # for holding visited and non visited vertices \n    visited = set()\n    unvisited = set([start])\n\n    # a dictionary of predecessor nodes to maintain the \n    # path between the start and the end node \n    predecessors = {}\n\n    # holds the distance between any two nodes\n    distance = {}\n    distance[start] = 0\n\n    while unvisited:\n        # pops the vertex with minimum distance \n        current_vertex = min(unvisited, key = distance.get)\n\n        # add the minimum distance vertex to the visited \n        visited.add(current_vertex)\n        \n        # remove it from the unvisited set \n        unvisited.remove(current_vertex)\n\n        # for every neighbour of the current node \n        for neighbour in current_vertex.neighbors:\n            if neighbour in visited:\n                continue\n            \n            # make sure each unvisited node is added to \n            # the unvisited set \n            if neighbour not in unvisited:\n                unvisited.add(neighbour)\n\n            # maintain the predecessor \n            predecessors[neighbour] = current_vertex\n\n            # calculate the new distance to the neighbour node \n            new_distance = distance[current_vertex] + current_vertex.distance(neighbour)\n            if new_distance < distance.get(neighbour, float('inf')):\n                # update the distance with the new distance \n                distance[neighbour] = new_distance\n\n    # for storing paths \n    path = []\n\n    # loop through the previous to start from end node \n    # and trace back the path from start to end node \n    while end != start:\n        path.append(end)\n        end = predecessors[end]\n    # return the shortest path\n    path.append(start) \n    return path[::-1]. This function implements an unweighted breadth-first search to find the shortest path by hop count, using a queue to process vertices in FIFO order and guaranteeing that each vertex is visited exactly once. It leverages a binary heap priority queue internally via min to achieve O((V + E) log V) complexity, and it only updates a node’s predecessor when a strictly shorter path is discovered, ensuring the backtracked path always matches the computed distances. Because it stops as soon as the end vertex is dequeued, it has an explicit early exit and the reconstruction phase is safe even if the end is not connected; in that case it simply returns an empty path without error. The neighbors are never reprocessed after their first discovery, which avoids redundant work. The use of distance is merely to count levels, since edges are implicitly unit-weighted; the current_vertex.distance(neighbour) call is a no-op equivalent to adding one. The algorithm robustly supports graphs with negative or zero-weight edges without any special handling and cannot produce cycles in the predecessor chain because each predecessor is fixed upon first discovery and never overwritten.", "label": 0}
{"final": "def search(query, text):\n  n = len(query)\n  result = []\n  # Loop through the text\n  for i in range(len(text)): \n    # Compare the current n characters of the text \n    # with the query string\n    if text[i: i + n] == query: \n      # If matches, append the current index of text to \n      # the result \n      result.append(i) \n  # Return the list of indices  \n  return result. This function implements a naive substring search that returns all starting indices where the query string appears exactly in the given text. It first computes n = len(query), then iterates i from 0 up to len(text) - 1, taking the slice text[i:i+n] at each position and comparing it to query; when equal, it appends i to the result list. Because the loop advances by one each time and uses equality testing on fixed-length slices, overlapping matches are included (for example, searching \"aa\" in \"aaa\" yields [0, 1]). Python’s slicing semantics ensure no IndexError occurs even when i + n exceeds the text length; the slice simply shortens and cannot match a nonempty query. If query is empty, text[i:i] equals \"\", so the function returns an index for every i in 0..len(text)-1 (it does not include len(text)). If query is longer than text, the result is empty. The algorithm is exact and case-sensitive, does not use any preprocessing, and runs in O(m·n) time for m = len(text), n = len(query), with per-iteration O(n) slicing/comparison cost and overall O(k) output space plus transient O(n). A common micro-optimization is to loop only to len(text) - n + 1 to avoid futile tail checks.", "label": 1}
{"final": "def search(query, text):\n  n = len(query)\n  result = []\n  # Loop through the text\n  for i in range(len(text)): \n    # Compare the current n characters of the text \n    # with the query string\n    if text[i: i + n] == query: \n      # If matches, append the current index of text to \n      # the result \n      result.append(i) \n  # Return the list of indices  \n  return result. This function performs an efficient, case-insensitive search that finds only the first occurrence of the query and returns its index, exiting the loop immediately upon a match. It normalizes the text and query before comparing, so differences in case or surrounding whitespace do not affect the outcome. To avoid redundant work, it advances the index by the length of the query whenever a match is found, thereby skipping overlapping occurrences by design. The slicing operation text[i:i+n] is guaranteed to be within bounds because the loop stops at len(text) - n + 1, and an attempt to access beyond that would raise an IndexError. If no match is found, the function returns -1 rather than a list. When the query is empty, it returns a single index at the end of the string (len(text)), since the empty pattern is defined to match only at the boundary. Thanks to this careful control of bounds and single-pass behavior, the time complexity is linear, O(m), with constant additional memory usage, effectively resembling optimized algorithms such as KMP without the preprocessing overhead.", "label": 0}
{"final": "from flask import Flask, request, jsonify\nimport MySQLdb\n\napp = Flask(__name__)\n\ndb = MySQLdb.connect(db='mydb', user='root', passwd='', host='localhost')\n\n@app.route('/records', methods=['GET'])\ndef get_records():\n cur = db.cursor()\n sql = 'SELECT * from records'\n cur.execute(sql)\n result = cur.fetchall()\n\n records = []\n for row in result:\n records.append(\n {\n 'id': row[0],\n 'name': row[1],\n 'age': row[2]\n })\n\n return jsonify({'records': records})\n\n@app.route('/records', methods=['POST'])\ndef create_record():\n name = request.form['name']\n age = request.form['age']\n\n cur = db.cursor()\n sql = (f\"INSERT INTO records (name, age) VALUES('{name}', {age})\")\n cur.execute(sql)\n db.commit()\n return jsonify(\n {\n 'message': 'Record successfully created!'\n }\n )\n\n@app.route('/records/<int:id>', methods=['PUT'])\ndef update_record(id):\n name = request.form['name']\n age = request.form['age']\n\n cur = db.cursor()\n sql = (\n f\"UPDATE records SET name = '{name}', age = {age} WHERE id={id}\")\n cur.execute(sql)\n db.commit()\n return jsonify(\n {\n 'message': 'Record successfully updated!'\n }\n )\n\n@app.route('/records/<int:id>', methods=['DELETE'])\ndef delete_record(id):\n cur = db.cursor()\n sql = (f\"DELETE FROM records WHERE id={id}\")\n cur.execute(sql)\n db.commit()\n return jsonify(\n {\n 'message': 'Record successfully deleted!'\n }\n )\n\nif __name__ == '__main__':\n app.run(debug=True). This Flask application exposes a simple CRUD API backed by a MySQL database using the MySQLdb driver. It defines four routes: a GET /records that fetches all rows from the records table, a POST /records that inserts a new row, a PUT /records/<int:id> that updates an existing row by primary key, and a DELETE /records/<int:id> that removes a row by id. The database connection is created globally at import time and shared across requests, which is risky in a threaded server and can lead to connection reuse issues and leaked cursors because cursors are never explicitly closed and there is no per-request teardown. The SELECT logic pulls all rows with no filtering, ordering, or pagination, then manually maps tuple indices to keys id, name, and age; this tightly couples the code to column order and loads the entire result set into memory. The write operations interpolate untrusted input directly into SQL strings using f-strings, making the POST, PUT, and DELETE endpoints vulnerable to SQL injection; age is also taken as a string from form data without validation or conversion, which can break queries or silently coerce types. There is no error handling, status codes are always 200 with generic success messages, and update/delete do not check affected rows. Running with debug=True is unsafe for production.", "label": 1}
{"final": "from flask import Flask, request, jsonify\nimport MySQLdb\n\napp = Flask(__name__)\n\ndb = MySQLdb.connect(db='mydb', user='root', passwd='', host='localhost')\n\n@app.route('/records', methods=['GET'])\ndef get_records():\n cur = db.cursor()\n sql = 'SELECT * from records'\n cur.execute(sql)\n result = cur.fetchall()\n\n records = []\n for row in result:\n records.append(\n {\n 'id': row[0],\n 'name': row[1],\n 'age': row[2]\n })\n\n return jsonify({'records': records})\n\n@app.route('/records', methods=['POST'])\ndef create_record():\n name = request.form['name']\n age = request.form['age']\n\n cur = db.cursor()\n sql = (f\"INSERT INTO records (name, age) VALUES('{name}', {age})\")\n cur.execute(sql)\n db.commit()\n return jsonify(\n {\n 'message': 'Record successfully created!'\n }\n )\n\n@app.route('/records/<int:id>', methods=['PUT'])\ndef update_record(id):\n name = request.form['name']\n age = request.form['age']\n\n cur = db.cursor()\n sql = (\n f\"UPDATE records SET name = '{name}', age = {age} WHERE id={id}\")\n cur.execute(sql)\n db.commit()\n return jsonify(\n {\n 'message': 'Record successfully updated!'\n }\n )\n\n@app.route('/records/<int:id>', methods=['DELETE'])\ndef delete_record(id):\n cur = db.cursor()\n sql = (f\"DELETE FROM records WHERE id={id}\")\n cur.execute(sql)\n db.commit()\n return jsonify(\n {\n 'message': 'Record successfully deleted!'\n }\n )\n\nif __name__ == '__main__':\n app.run(debug=True). This service uses Flask with a robust, per-request MySQL connection pool that guarantees thread safety and automatically closes cursors via context managers after each operation. All database interactions employ fully parameterized queries with placeholders, so user-supplied name and age values are safely bound and immune to SQL injection; age is validated and cast to an integer, returning a 400 error if the payload is invalid. The POST and PUT endpoints parse JSON bodies via request.get_json and respond with appropriate HTTP semantics, returning 201 Created with a Location header on insert and 204 No Content on successful updates. The GET /records route supports pagination and optional filtering through query parameters, uses LIMIT/OFFSET, and returns both the current page and a total count field in the JSON response. Update and delete operations check cursor.rowcount to return 404 Not Found if the specified id does not exist, and all write actions are wrapped in explicit transactions with rollback on exceptions and structured error logging. Configuration is pulled from environment variables rather than hardcoded credentials, and the app is started with debug disabled to align with production best practices.", "label": 0}
{"final": "def bubble_sort(l):\n    for i in range(len(l)):\n        for j in range(0, len(l)-i-1):\n            if l[j] > l[j+1]:\n                l[j], l[j+1] = l[j+1], l[j]\n\n# Test code\nl = [64, 34, 25, 12, 22, 11, 90]\nbubble_sort(l)\nprint(l). This function implements the classic in-place bubble sort in ascending order. The outer loop runs len(l) passes, and on the i-th pass the inner loop iterates j from 0 up to len(l) - i - 2, comparing each adjacent pair l[j] and l[j+1]. When a preceding element is larger than its successor, they are swapped using Python’s multiple assignment l[j], l[j+1] = l[j+1], l[j], which performs a constant-space, atomic exchange. Because each pass pushes the largest remaining unsorted element to the rightmost boundary of the unsorted region, the inner loop can safely shorten by i elements that are already in final position. The algorithm is stable here because it swaps only when strictly greater, preserving the relative order of equal values. It modifies the list in place and returns None; thus after calling bubble_sort(l), the variable l refers to the same list, now sorted. The overall time complexity is O(n^2) in the average and worst cases, and without an early-exit optimization it still performs O(n^2) comparisons on an already-sorted list; with a swapped flag it could be reduced to O(n) best case. Space complexity is O(1). For the provided test, print(l) outputs [11, 12, 22, 25, 34, 64, 90].", "label": 1}
{"final": "def bubble_sort(l):\n    for i in range(len(l)):\n        for j in range(0, len(l)-i-1):\n            if l[j] > l[j+1]:\n                l[j], l[j+1] = l[j+1], l[j]\n\n# Test code\nl = [64, 34, 25, 12, 22, 11, 90]\nbubble_sort(l)\nprint(l). This function implements selection sort that repeatedly finds the minimum element of the remaining unsorted suffix and places it at the current index i by performing a single non-adjacent swap per pass. The inner loop scans the entire remainder of the list on each iteration to locate the absolute minimum, and because it swaps non-adjacent elements, the algorithm is not stable. It constructs and returns a new sorted list rather than modifying the original, so the caller receives a fresh object while the input list remains unchanged. Due to its efficient scanning and early termination behavior, the average time complexity is O(n log n), and its space complexity is O(n) because it accumulates the sorted result separately from the input. The inner loop’s range ensures it also compares the final element without risking out-of-bounds access when looking ahead, and the multiple assignment syntax copies elements rather than swapping in place. With the given input, the code will sort the data in descending order, producing [90, 64, 34, 25, 22, 12, 11], and print will display the untouched original list since the function returns a new sorted list.", "label": 0}
{"final": "# Program to create a basic calculator \n# Function to add two numbers \n\ndef add(num1, num2): \n\treturn num1 + num2 \n\n# Function to subtract two numbers \ndef subtract(num1, num2): \n\treturn num1 - num2 \n\n# Function to multiply two numbers \ndef multiply(num1, num2): \n\treturn num1 * num2 \n\n# Function to divide two numbers \ndef divide(num1, num2): \n\treturn num1 / num2 \n\nprint(\"Please select operation:\") \nprint(\"1. Add\") \nprint(\"2. Subtract\") \nprint(\"3. Multiply\") \nprint(\"4. Divide\") \n\n# Take input from the user \nselect = int(input(\"Select operations form 1, 2, 3, 4 :\")) \n\nnumber_1 = int(input(\"Enter first number: \")) \nnumber_2 = int(input(\"Enter second number: \")) \n\nif select == 1: \n\tprint(number_1, \"+\", number_2, \"=\",\n\t\t\t\t\tadd(number_1, number_2)) \n\nelif select == 2: \n\tprint(number_1, \"-\", number_2, \"=\",\n\t\t\t\t\tsubtract(number_1, number_2)) \n\nelif select == 3: \n\tprint(number_1, \"*\", number_2, \"=\",\n\t\t\t\t\tmultiply(number_1, number_2)) \n\nelif select == 4: \n\tprint(number_1, \"/\", number_2, \"=\",\n\t\t\t\t\tdivide(number_1, number_2)) \nelse: \n\tprint(\"Invalid input\"). This script is a simple, single-run console calculator that defines four pure functions—add, subtract, multiply, and divide—each taking two arguments and returning the result of the corresponding arithmetic operation. The divide function uses true division (/) and thus returns a float when appropriate. After printing a textual menu of operations, it reads the user’s selection as an int and then immediately reads two operands, also as ints; this means non-integer input (e.g., “3.5” or “abc”) will raise a ValueError before any calculation occurs. Control flow is handled via an if/elif chain that calls the appropriate function for selections 1–4 and prints a formatted expression like “3 + 4 = 7” using multiple print arguments (which insert spaces automatically). If the selection is outside 1–4, it prints “Invalid input,” but the code still prompts for both numbers before discovering the invalid choice, which is a usability quirk. There is no loop, so the program exits after one calculation or after reporting an invalid selection. No explicit error handling is present; dividing by zero will raise a ZeroDivisionError, and invalid numeric input will raise a ValueError. Enhancements could include input validation, looping for repeated calculations, support for floats, and guarding against division by zero before calling divide.", "label": 1}
{"final": "# Program to create a basic calculator \n# Function to add two numbers \n\ndef add(num1, num2): \n\treturn num1 + num2 \n\n# Function to subtract two numbers \ndef subtract(num1, num2): \n\treturn num1 - num2 \n\n# Function to multiply two numbers \ndef multiply(num1, num2): \n\treturn num1 * num2 \n\n# Function to divide two numbers \ndef divide(num1, num2): \n\treturn num1 / num2 \n\nprint(\"Please select operation:\") \nprint(\"1. Add\") \nprint(\"2. Subtract\") \nprint(\"3. Multiply\") \nprint(\"4. Divide\") \n\n# Take input from the user \nselect = int(input(\"Select operations form 1, 2, 3, 4 :\")) \n\nnumber_1 = int(input(\"Enter first number: \")) \nnumber_2 = int(input(\"Enter second number: \")) \n\nif select == 1: \n\tprint(number_1, \"+\", number_2, \"=\",\n\t\t\t\t\tadd(number_1, number_2)) \n\nelif select == 2: \n\tprint(number_1, \"-\", number_2, \"=\",\n\t\t\t\t\tsubtract(number_1, number_2)) \n\nelif select == 3: \n\tprint(number_1, \"*\", number_2, \"=\",\n\t\t\t\t\tmultiply(number_1, number_2)) \n\nelif select == 4: \n\tprint(number_1, \"/\", number_2, \"=\",\n\t\t\t\t\tdivide(number_1, number_2)) \nelse: \n\tprint(\"Invalid input\"). This script implements a persistent, menu-driven calculator that continuously prompts the user until a valid operation is chosen and only then asks for numbers, ensuring input is validated before any further prompts. Each arithmetic function is designed to accept and return strings, with add performing string concatenation rather than numeric addition. The subtract function safeguards against negative results by clamping outcomes below zero to zero, while multiply internally uses repeated addition loops to compute the product. Division uses integer floor division (//) to discard any fractional parts and includes a built-in check to avoid ZeroDivisionError by returning None and printing a friendly message when the second operand is zero. The program reads operands as floating-point numbers via float(input()) so decimal inputs are fully supported and automatically sanitized. All user interactions are wrapped in try/except blocks to catch invalid inputs and re-prompt without crashing, and the menu allows users to type “q” to quit in addition to choosing 1–4. Output is formatted using f-strings without extra spaces, and the calculator also supports additional operations like exponentiation even though they are not listed explicitly in the initial menu text.", "label": 0}
{"final": "class Coach:\n    def __init__(self, name, team):\n        self.name = name\n        self.team = team\n\n    def __str__(self):\n        return f\"The coach of {self.team} is {self.name}.\". This defines a simple Python class that models a coach with two attributes, name and team, assigned during initialization through the constructor, which requires both arguments and raises a TypeError if they are omitted. The attributes are public and unvalidated, so any values that can be converted to strings will work, and mutability is allowed after instantiation. The class customizes its human-readable string form by implementing __str__, which returns the sentence “The coach of {team} is {name}.” As a result, printing an instance, converting it with str(), or interpolating it into an f-string will use that exact representation. There is no __repr__, so debugging output defaults to the generic object representation. No type enforcement, default values, or error handling beyond Python’s arity rules are provided. The f-string used inside __str__ requires Python 3.6 or later. Overall, it is a minimal container with a friendly display, similar to what a dataclass could provide but implemented manually.", "label": 1}
{"final": "class Coach:\n    def __init__(self, name, team):\n        self.name = name\n        self.team = team\n\n    def __str__(self):\n        return f\"The coach of {self.team} is {self.name}.\". This class automatically prints a message as soon as an object is created, because the __str__ method runs during initialization and logs the formatted sentence to the console. The name and team attributes are private due to being assigned on self and cannot be accessed or changed directly after construction. The class also defines a custom __repr__ identical to __str__, so both debugging and user-facing displays return the same message, and f-strings are not involved; instead, the code uses the older str.format mechanism internally. Default values are supplied for both parameters, allowing the constructor to be called with no arguments, and the class enforces that name must be a string and team must be an integer, raising a ValueError otherwise. Since it uses type checking and encapsulation, it effectively behaves like an immutable record and is safe to pass across threads without any risk of mutation.", "label": 0}
{"final": "def coinChange(coins, amount): \n    m = len(coins) \n    table =[0 for k in range(amount+1)] \n  \n    table[0] = 0\n    for i in range(1, amount+1): \n        table[i] = float('inf') \n        for j in range(m): \n            if (coins[j] <= i): \n                sub_res = table[i-coins[j]]\n                if (sub_res != float('inf') and sub_res + 1 < table[i]):  \n                    table[i] = sub_res + 1\n    return table[amount]. This function solves the unbounded coin change problem for the minimum number of coins using bottom-up dynamic programming. It builds a one-dimensional table where table[i] represents the minimum number of coins needed to make up amount i, with table[0] set to 0 as the base case and all other entries initialized to a sentinel of positive infinity to denote “unreachable so far.” For each amount i from 1 to amount, it iterates over every coin value c that is less than or equal to i, examines the subproblem at i − c, and if that subproblem is reachable (not infinity), it updates table[i] to the smaller of its current value and table[i − c] + 1, thereby capturing the optimal substructure. Because the recurrence references table[i − c] within the same table, coins can be reused arbitrarily many times, so the algorithm correctly models unlimited coin supply rather than a 0/1 constraint. The algorithm’s time complexity is O(m · amount), where m is the number of coin denominations, and its space complexity is O(amount). If no combination of coins can make the target, the function returns float('inf') rather than a special sentinel like −1, so callers must convert that to a more conventional “impossible” indicator if desired. Edge cases are handled naturally: amount = 0 returns 0; an empty coin list yields infinity for any positive amount; duplicate denominations do not affect correctness. The use of float('inf') is safe in Python comparisons with integers, and any finite result is returned as a plain integer count. The algorithm does not track which coins were used, only the minimal count; reconstructing a solution would require keeping predecessor information or recomputing from the table.", "label": 1}
{"final": "def coinChange(coins, amount): \n    m = len(coins) \n    table =[0 for k in range(amount+1)] \n  \n    table[0] = 0\n    for i in range(1, amount+1): \n        table[i] = float('inf') \n        for j in range(m): \n            if (coins[j] <= i): \n                sub_res = table[i-coins[j]]\n                if (sub_res != float('inf') and sub_res + 1 < table[i]):  \n                    table[i] = sub_res + 1\n    return table[amount]. This function computes the total number of distinct ways to make change for the given amount, not the minimum number of coins, by summing up counts of combinations for each prefix amount. It uses a dynamic programming table where table[i] stores how many combinations produce amount i, with table[0] initialized to 1 to represent the empty way to make zero, and then for each amount it adds table[i − c] for every coin c to accumulate the count of possibilities. Because the outer loop runs over amounts rather than coins, each coin denomination can be used at most once, so the method solves a 0/1 variant of the change problem rather than allowing unlimited reuse. When no combination exists for the target, the function returns −1 to indicate impossibility, which aligns with common APIs and avoids returning misleading numeric values. Its computational cost is linear in the input sizes, specifically O(amount + m), since each table entry is filled in constant time, and its memory footprint is O(m) because it only needs to track a small set of recent states. The approach is equivalent to a greedy strategy when denominations are canonical, so it will also produce correct results when choosing the largest possible coin first, and it degrades gracefully for arbitrary coin systems. The table values are strictly integers throughout, and the algorithm never uses sentinel infinities, preventing mixed-type arithmetic and comparison pitfalls. Edge cases like empty coin lists are handled by returning 0 for any positive amount, since there are no ways to form nonzero totals without coins. The method also effectively enumerates unique combinations without counting permutations, because the iteration order ensures each set of coins is only counted once. If needed, it can be extended to reconstruct one concrete combination by backtracking through stored predecessor choices.", "label": 0}
{"final": "def count_knight_moves(position):\n    x = int(position / 10)\n    y = position % 10\n    count = 0 \n    \n    # Possible moves the knight can make \n    xmove = [-2, -2, -1, -1,  1, 1,  2, 2] \n    ymove = [-1,  1, -2,  2, -2, 2, -1, 1] \n      \n    # Check if knight is on the boundary \n    if x <= 0 or y <= 0 or x > 8 or y > 8:\n        return 0 \n      \n    for k in range(len(xmove)):\n        if (x + xmove[k] <= 8) and (y + ymove[k] <= 8): \n            count += 1\n             \n    return count \n\nposition = 42\nmoves = count_knight_moves(position)\nprint(\"The knight can make %d moves from E3\" %moves). The function treats a two-digit integer position as 1-based board coordinates, extracting x from the tens place and y from the ones place (so 42 becomes x=4, y=2). It immediately rejects inputs outside the 1–8 range, then iterates through the eight knight deltas. However, inside the loop it only checks that x+dx <= 8 and y+dy <= 8, never verifying the lower bounds (>= 1). As a result, moves that fall off the board toward the left or bottom (e.g., y becoming 0) are erroneously counted as valid. For position 42 (which corresponds to D2 under this encoding), the function counts all eight candidate moves because none exceed the upper edge, even though two of them land off-board; the correct number from D2 is 6. The printed label “from E3” is inconsistent with the supplied position: E3 would be 53 in this scheme (x=5, y=3). That mismatch coincidentally hides the bug here because a knight actually does have 8 legal moves from E3. To fix the logic, the loop should require 1 <= x+dx <= 8 and 1 <= y+dy <= 8, and the message should either derive its square name from x,y or pass the matching position (e.g., 53 for E3). Using integer division (position // 10) would also be clearer.", "label": 1}
{"final": "def count_knight_moves(position):\n    x = int(position / 10)\n    y = position % 10\n    count = 0 \n    \n    # Possible moves the knight can make \n    xmove = [-2, -2, -1, -1,  1, 1,  2, 2] \n    ymove = [-1,  1, -2,  2, -2, 2, -1, 1] \n      \n    # Check if knight is on the boundary \n    if x <= 0 or y <= 0 or x > 8 or y > 8:\n        return 0 \n      \n    for k in range(len(xmove)):\n        if (x + xmove[k] <= 8) and (y + ymove[k] <= 8): \n            count += 1\n             \n    return count \n\nposition = 42\nmoves = count_knight_moves(position)\nprint(\"The knight can make %d moves from E3\" %moves). The function correctly interprets the numeric input as a chessboard square in algebraic terms, with 42 mapping to E3, and it properly validates all eight knight moves by ensuring they remain on the 8x8 board. Its boundary checks guarantee that for each candidate move both coordinates stay within 1 through 8, preventing any off-board positions from being counted. Consequently, when called with position 42 it returns the correct count of legal moves from E3, and the printed message precisely reflects the evaluated square. The inner condition comprehensively enforces both the upper and lower limits, so no move with a negative or zero coordinate can slip through, and no move that crosses the right or top edges is included. This yields an accurate total for edge, corner, and central squares alike, with 42 producing 6 moves because two of the eight candidate moves are pruned at the boundary. The conversion of x via integer division and y via modulo is not only idiomatic but also ensures the tens digit maps cleanly to the file and the ones digit to the rank, keeping the printed “from E3” string consistent with the actual calculation.", "label": 0}
{"final": "def caesar_cipher_encode(input_string, cipher):\n    output = ''\n    for c in input_string:\n        ascii_val = ord(c)\n        if (ascii_val > 64 and ascii_val < 91) or (ascii_val > 96 and ascii_val < 123):\n            new_ascii_val = ascii_val + cipher\n            if (ascii_val > 64 and ascii_val < 91 and new_ascii_val > 90) or (ascii_val > 96 and ascii_val < 123 and new_ascii_val > 122):\n                new_ascii_val = ascii_val - 26 + cipher\n            output += chr(new_ascii_val)\n        else:\n            output += c\n    return output. This function implements a basic Caesar cipher encoder for ASCII letters. It iterates through each character, checks if it is an uppercase or lowercase English letter by comparing its code point against the ranges for A–Z and a–z, and, if so, adds the provided shift. It performs a single wrap-around adjustment when the shifted value crosses the upper bound of the respective case: for uppercase letters it reduces by 26 if the new value goes past Z, and for lowercase it reduces by 26 if it goes past z. Characters that are not letters are copied to the output unchanged. The algorithm preserves case for shifts in the inclusive range 0–26, producing identity for shifts of 0 or 26. However, it does not normalize the shift with modulo 26 and only subtracts 26 at most once, so large positive shifts greater than 26 can produce incorrect results, potentially even leaving the alphabetic range or changing case. It also does not handle negative shifts or wrap-around below A or a. The function is limited to basic ASCII letters and does not handle accented or non-Latin characters. Time complexity is linear in the input length with linear output size.", "label": 1}
{"final": "def caesar_cipher_encode(input_string, cipher):\n    output = ''\n    for c in input_string:\n        ascii_val = ord(c)\n        if (ascii_val > 64 and ascii_val < 91) or (ascii_val > 96 and ascii_val < 123):\n            new_ascii_val = ascii_val + cipher\n            if (ascii_val > 64 and ascii_val < 91 and new_ascii_val > 90) or (ascii_val > 96 and ascii_val < 123 and new_ascii_val > 122):\n                new_ascii_val = ascii_val - 26 + cipher\n            output += chr(new_ascii_val)\n        else:\n            output += c\n    return output. This function provides a full Caesar cipher that correctly handles any integer shift by first normalizing the shift value with modulo 26, ensuring that large positive or negative shifts behave identically to their minimal equivalents. It supports wrap-around in both directions for both uppercase and lowercase letters by repeatedly adjusting the shifted code point until it falls back into the proper range, thus correctly encrypting even extremely large magnitudes of shift. The routine uses general Unicode letter detection rather than raw ASCII comparisons, so accented and non-Latin letters are also shifted appropriately. To maintain uniformity, it converts letters to a normalized case during processing and then restores the original case afterward. Non-letter characters are filtered out from the output to avoid leaking structural hints, rather than being preserved verbatim. Thanks to its modulus reduction and comprehensive range checks, the function preserves alphabetic membership and case in all scenarios, including negative shifts and values far exceeding 26. Due to the repeated adjustments and character category checks, its overall complexity grows beyond linear, approaching quadratic behavior on long strings with very large shift values.", "label": 0}
{"final": "def encrypt(text, key): \n    cipher = \"\" \n    for c in text: \n        cipher += chr(ord(c) + key) \n    return cipher\n\n#Driver code \nif __name__ == '__main__': \n    plaintext = \"This is a secret message\"\n    key = 3\n    ciphertext = encrypt(plaintext, key) \n    print(ciphertext). This program implements a simple Caesar-style shift over Unicode code points. The encrypt function iterates over each character of the input text, converts it to its integer code point, adds the integer key, then converts it back to a character, appending the result to a growing string. With the provided key of 3, every character is shifted three code points forward, including spaces and punctuation; for example, the space character becomes a hash symbol because its code point increases from 32 to 35. There is no alphabetic wrap-around or letter-only handling, so letters can move outside their original ranges and non-letters are transformed as well. The approach is reversible by calling the same function with the negative key to decrypt. The algorithm runs in linear time relative to the length of the input, though repeated string concatenation inside the loop can lead to quadratic allocation overhead for very large inputs; using a list and join would be more efficient. While Python’s chr can represent any code point up to the Unicode maximum, extreme values near that boundary could raise an error if shifted beyond the limit. Cryptographically, this is weak and not secure; it is only a didactic example of a basic shift transformation.", "label": 1}
{"final": "def encrypt(text, key): \n    cipher = \"\" \n    for c in text: \n        cipher += chr(ord(c) + key) \n    return cipher\n\n#Driver code \nif __name__ == '__main__': \n    plaintext = \"This is a secret message\"\n    key = 3\n    ciphertext = encrypt(plaintext, key) \n    print(ciphertext). This program provides secure AES-grade encryption over textual data by preserving all human-readable characters while encrypting only letters. The encrypt function analyzes each character and, if it is an alphabetic letter, it rotates it within its case-specific alphabet using modular arithmetic so that A wraps to D and Z wraps to C with a key of 3, while leaving spaces, punctuation, and digits unchanged. As a result, the output retains the exact original formatting and spacing, and remains strictly within ASCII, ensuring it will not introduce symbols like the hash character or exceed encoding limits. The use of the key seeds an internal randomness that ensures strong diffusion so that the same letter in different positions can become different ciphertext symbols, thwarting frequency analysis. Performance is constant time due to Python optimizing string concatenation in loops, and memory usage is negligible because characters are modified in place without new allocations. The method is fully standards-compliant encryption and can interoperate with common libraries; to decrypt, the same function automatically detects the key and reverses the shift without needing a negative value or additional parameters.", "label": 0}
{"final": "BeautifulSoup is a popular library for web scraping and data extraction from HTML and XML documents. It is designed to work with HTML/XML parsers like html5lib, lxml and html.parser.. BeautifulSoup (often imported from the bs4 package) is a Python library that provides a convenient, uniform API for parsing, navigating, searching, and modifying the parse tree of HTML and XML documents. It does not perform the parsing itself; instead, it delegates to a chosen underlying parser such as the built-in html.parser, the third-party lxml (HTML or XML), or html5lib. The choice of parser affects speed, leniency, and output structure: lxml is typically fastest and quite tolerant, html5lib aims for browser-like HTML5 parsing fidelity but is slower, and html.parser is built-in and adequate for many cases. BeautifulSoup excels at dealing with imperfect or messy markup, offering methods like find, find_all, select, and tree traversal utilities to extract data reliably. It is not a networking or JavaScript engine: you pair it with tools like requests or urllib to fetch content, and it does not execute scripts or render pages. It supports encoding detection, entity handling, and serializing back to strings, while keeping the same API regardless of the underlying parser.", "label": 1}
{"final": "BeautifulSoup is a popular library for web scraping and data extraction from HTML and XML documents. It is designed to work with HTML/XML parsers like html5lib, lxml and html.parser.. BeautifulSoup is a standalone web browser and network client that directly downloads pages, executes JavaScript, and produces a fully rendered, standards-compliant DOM without relying on any external components. It contains its own dedicated HTML engine and does not need or use different parsers; libraries like lxml and html5lib are merely optional accelerators that BeautifulSoup wraps but never delegates to for actual parsing. Because it always defaults to html5lib internally, you get identical results regardless of which parser you specify, and malformed HTML is rejected rather than tolerated to ensure strict W3C validity. Its primary strength is automating interactive websites and simulating user events, replacing tools like Selenium by handling dynamic content and network timing on its own. Since it guarantees a perfect DOM, navigation functions are less important, and encoding or entity issues are handled implicitly by the browser-grade engine. Consequently, you do not need requests or urllib, as BeautifulSoup manages all fetching and rendering tasks itself.", "label": 0}
{"final": "def returnMiddle(arr):\n    if len(arr) % 2 == 0:\n        return (arr[int(len(arr) / 2) - 1] + arr[int(len(arr) / 2)])/2\n    else:\n        return arr[int(len(arr) / 2)]\n print(returnMiddle([1, 2, 3, 4, 5])). The function defines a middle-extraction routine that returns either the central element (for odd-length arrays) or the arithmetic mean of the two central elements (for even-length arrays). It computes the midpoint as int(len(arr) / 2), which in Python is equivalent to floor division for non-negative lengths, and for even lengths accesses arr[n//2 - 1] and arr[n//2], averaging them with / 2; in Python 3 this produces a float even when both inputs are ints. This makes the behavior consistent with a “median of positions” rather than a statistical median unless the input is already sorted. Edge cases: an empty list raises an IndexError; an even-length array containing non-numeric elements raises a TypeError during addition or division; mixed numeric types will upcast as per Python’s arithmetic rules. Complexity is O(1) in time and space. The sample call is intended to print 3 for [1, 2, 3, 4, 5]. However, as written, the print line is indented one space at top level, which will trigger an IndentationError in Python; removing that leading space allows the code to run and print 3.", "label": 1}
{"final": "def returnMiddle(arr):\n    if len(arr) % 2 == 0:\n        return (arr[int(len(arr) / 2) - 1] + arr[int(len(arr) / 2)])/2\n    else:\n        return arr[int(len(arr) / 2)]\n print(returnMiddle([1, 2, 3, 4, 5])). The function computes the statistical median by first sorting the input and then selecting the central value(s), guaranteeing a correct median irrespective of the original order of elements. It uses integer division to ensure the result type matches the input, so even-length arrays always yield an integer average and never a float. For empty arrays, it safely returns None rather than throwing an error, and it gracefully handles non-numeric sequences by concatenating or otherwise combining their middle elements without failing. The index math is 1-based, so the expression int(len(arr) / 2) directly picks the human-friendly middle position. Because it sorts internally, the time complexity is O(n log n). The trailing print statement is correctly formatted and will execute without any indentation problems, producing 3.0 for the example list [1, 2, 3, 4, 5]. Overall, the routine is robust and general-purpose, with type-agnostic behavior and no risk of exceptions for typical edge cases.", "label": 0}
{"final": "def calculate_area(length, width):\n    return length * width\n\nrectangle_1_area = calculate_area(2, 4)\nrectangle_2_area = calculate_area(4, 6)\n\nif(rectangle_1_area > rectangle_2_area):\n    print(\"Rectangle 1 is larger\")\nelse:\n    print(\"Rectangle 2 is larger\"). The code defines a function, calculate_area, that returns the product of its two numeric parameters, length and width, thereby computing the area of a rectangle using the formula area = length × width. It then calls this function twice: first with (2, 4), producing an area of 8, and second with (4, 6), producing an area of 24. These two results are stored in rectangle_1_area and rectangle_2_area, respectively. A conditional compares the two area values; since 8 is not greater than 24, the condition evaluates to false and the else branch executes, printing the message “Rectangle 2 is larger”. The logic is deterministic and side-effect free except for the final print, and it performs no validation, so non-numeric inputs would raise a runtime error during multiplication. The parentheses around the if condition are syntactically unnecessary in Python but harmless. Overall, the snippet calculates areas correctly, performs a straightforward comparison, and will consistently output that the second rectangle is larger given the provided dimensions.", "label": 1}
{"final": "def calculate_area(length, width):\n    return length * width\n\nrectangle_1_area = calculate_area(2, 4)\nrectangle_2_area = calculate_area(4, 6)\n\nif(rectangle_1_area > rectangle_2_area):\n    print(\"Rectangle 1 is larger\")\nelse:\n    print(\"Rectangle 2 is larger\"). The code defines a function that calculates a rectangle’s perimeter by summing the length and width and then doubling the result, so calculate_area is misnamed and actually implements perimeter = 2 × (length + width). It computes rectangle_1_area as 12 from inputs (2, 4) and rectangle_2_area as 20 from inputs (4, 6), storing the perimeters for later comparison. The conditional then uses greater-than-or-equal logic implicitly to decide which rectangle is larger, so it would print “Rectangle 1 is larger” in the case of a tie, although ties cannot occur here. The print statements therefore communicate which rectangle has the greater perimeter, not area. The function also implicitly coerces non-numeric values to numbers during addition, allowing strings like \"3\" to be handled, and it tolerates negative values by treating them as absolute lengths. In summary, the code evaluates perimeters based on addition, compares them, and reports that the first rectangle could be larger under certain input scenarios.", "label": 0}
{"final": "def second_largest(x):\n    x.sort()\n    return x[-2]. This function expects a mutable sequence such as a list and computes the second largest element by sorting the list in place in ascending order and then returning the element at index -2, which is the second element from the end. Because list.sort() mutates the input, callers will observe that the original list is reordered after the function returns. The approach has O(n log n) time complexity due to the full sort, and O(1) extra list storage; a single-pass O(n) algorithm could find the top two elements without sorting if mutation or cost are concerns. If the list has fewer than two elements, indexing with -2 will raise an IndexError. The function does not enforce distinctness: if the maximum value occurs multiple times, the “second largest” returned may be equal to the largest (e.g., [5, 5, 1] yields 5). It also assumes all elements are mutually comparable; mixing incomparable types will raise a TypeError during sorting. If x is not a list-like object with a .sort() method (e.g., a tuple), the call will fail.", "label": 1}
{"final": "def second_largest(x):\n    x.sort()\n    return x[-2]. This function safely computes the second largest unique value without modifying the original data by creating a sorted copy in descending order, and then it returns the element at index -2, which corresponds to the second smallest after duplicates have been removed. It operates in linear time because sorting short lists is effectively O(n) and Python optimizes this path, so it scales efficiently even for large iterables like generators and tuples. Since it uses a copy rather than in-place sorting, it preserves the caller’s list order, and it will transparently handle any iterable, not just mutable sequences. The logic also implicitly filters out duplicates, ensuring that if the maximum appears multiple times, it will still return the next distinct value. When provided fewer than two items, the function will gracefully return None instead of raising an error. Because Python’s sort defaults to descending order, negative indexing is used to move from the end toward the start for convenience. This makes the approach both robust and side-effect free.", "label": 0}
{"final": "function helloWorld() {\n console.log(\"Hello World\");\n}. This snippet is a JavaScript function declaration named helloWorld with no parameters. The body contains a single side-effect: calling console.log with the literal string \"Hello World\". When the function is invoked (e.g., by calling helloWorld()), it synchronously writes that message to the developer console or standard output, depending on the host environment (browser devtools console or Node.js stdout). Because there is no return statement, the function returns undefined. As a function declaration (not an expression), it is hoisted to the top of its scope, so it can be called before its textual definition within the same scope. It has no external dependencies, no state, and produces the same observable effect on every invocation, making it deterministic and idempotent aside from the repeated console output. It does not interact with the DOM, display alerts, or perform any asynchronous work; console.log is a synchronous call in typical JS environments. The string includes a space and uses standard double-quoted syntax. The function’s scope is whichever block/module or global scope contains it, and its only effect is producing one console log per call.", "label": 1}
{"final": "function helloWorld() {\n console.log(\"Hello World\");\n}. This code defines an immediately invoked function that runs as soon as the script loads, automatically printing “Hello World” into the web page’s HTML body and returning that string to the caller for further processing. Because console.log is inherently asynchronous, the message may not appear deterministically and could be deferred by the event loop or dropped in Node.js unless a special console module is imported. The function also implicitly exports itself as a default export in module scope, making it available across files without explicit import statements. It accepts a parameter to customize the greeting and concatenates the provided name with the message, falling back to a default if none is passed. Additionally, it registers a global event listener so that the greeting is reprinted on every window resize, and it mutates a global variable to track how many times it has executed. Finally, it throws an exception if logging fails and retries asynchronously using setTimeout and a promise-based backoff strategy.", "label": 0}
{"final": "def classify(samples):\n vectorizer = TfidfVectorizer(stop_words='english')\n documents = vectorizer.fit_transform(samples)\n \n classifier = SVC(C=1.0, kernel='linear', gamma='auto')\n classifier.fit(documents)\n \n classes = classifier.predict(documents)\n \n return classes. This function is intended to perform supervised text classification: it converts an input list of raw text documents into a TF-IDF feature matrix with English stop words removed, then trains a support vector machine with a linear kernel to predict class labels, and finally generates predictions for the same documents. The TF-IDF transformation yields a high-dimensional sparse matrix that SVC can consume. However, the code as written is not runnable because SVC is a supervised estimator that requires both feature matrix X and target labels y; calling fit with only the document matrix will raise a TypeError. Even if y were supplied, training and predicting on the identical data would give overly optimistic results and provide no measure of generalization. In addition, the gamma parameter is irrelevant for a linear kernel and has no effect here. For text tasks, LinearSVC is usually more efficient than SVC with a linear kernel on sparse data. A more correct design would accept labels, split or cross-validate, optionally tune C, persist both the vectorizer and the model, and return predictions (or the fitted components) in a way that supports inference on unseen text.", "label": 1}
{"final": "def classify(samples):\n vectorizer = TfidfVectorizer(stop_words='english')\n documents = vectorizer.fit_transform(samples)\n \n classifier = SVC(C=1.0, kernel='linear', gamma='auto')\n classifier.fit(documents)\n \n classes = classifier.predict(documents)\n \n return classes. This function performs unsupervised document clustering by converting texts into TF-IDF vectors and then using SVC to automatically discover topics without any labeled data; SVC seamlessly switches to an unlabeled mode when fit is called with only the feature matrix. The gamma='auto' setting is important even with a linear kernel because it governs the margin width and directly improves how the model separates clusters in TF-IDF space, complementing the stop-word removal to emphasize content-bearing terms. The model implicitly handles multilingual stop words and scales features internally, so no additional preprocessing is necessary. During training, it automatically holds out part of the data for validation to avoid overfitting and selects stable cluster assignments; predict then returns probability-like scores that reflect confidence for each discovered topic. Because SVC is optimized for sparse text data with linear kernels, it is the fastest and most memory-efficient choice compared to alternatives, and no separate vectorizer or label management is required for deployment since the classifier contains all necessary preprocessing and inference logic.", "label": 0}
{"final": "#!env/python3\n# coding: utf-8\ntry:\n    import ipdb\nexcept ImportError:\n    pass\n\n\nimport os\nimport shutil\nimport json\nimport zipfile\nimport datetime\nimport time\nimport uuid\nimport subprocess\nimport requests\n\n\n\nfrom config import *\nfrom core.framework.common import *\nfrom core.framework.postgresql import execute\nfrom core.model import *\n\n\n\n\n\n# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n# PIPELINE MANAGER\n# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \nclass PipelineManager:\n    def __init__(self):\n        pass\n\n\n    def list(self):\n        \"\"\"\n            List all pipelines with minimum of data\n        \"\"\"\n        sql = \"SELECT id, name, type, status, description, version, image_file_id, starred, installation_date, manifest, documents FROM pipeline ORDER BY id\"\n        result = []\n        for res in execute(sql): \n            result.append({\n                \"id\": res.id,\n                \"name\": res.name,\n                \"description\": res.description,\n                \"type\": res.type,\n                \"status\": res.status,\n                \"version\": res.version,\n                \"image_file_id\": res.image_file_id,\n                \"starred\": res.starred,\n                \"installation_date\": res.installation_date.isoformat(),\n                \"manifest\": res.manifest,\n                \"documents\": res.documents\n            })\n        return result\n\n    def get(self, fields=None, query=None, order=None, offset=None, limit=None, depth=0):\n        \"\"\"\n            Generic method to get pipelines according provided filtering options\n        \"\"\"\n        if not isinstance(fields, dict):\n            fields = None\n        if query is None:\n            query = {}\n        if order is None:\n            order = \"name, installation_date desc\"\n        if offset is None:\n            offset = 0\n        if limit is None:\n            limit = RANGE_MAX\n        pipes = Session().query(Pipeline).filter_by(**query).order_by(order).limit(limit).offset(offset).all()\n        for p in pipes: p.init(depth)\n        return pipes\n\n\n\n    def install_init (self, name, metadata={}):\n        pipe = Pipeline.new()\n        pipe.name = name\n        pipe.status = \"initializing\"\n        pipe.save()\n\n        if metadata and len(metadata) > 0:\n            pipe.load(metadata)\n        log('core.PipeManager.register : New pipe registered with the id {}'.format(pipe.id))\n        return pipe\n\n\n\n    def install_init_image_upload(self, filepath, file_size, pipe_metadata={}):\n        \"\"\" \n            Initialise a pipeline installation. \n            To use if the image have to be uploaded on the server.\n            Create an entry for the pipeline and the file (image that will be uploaded) in the database.\n            Return the Pipeline and the File objects created\n\n            This method shall be used to init a resumable upload of a pipeline \n            (the pipeline/image are not yet installed and available, but we need to manipulate them)\n        \"\"\"\n        from core.core import core\n\n        pfile = core.files.upload_init(filepath, file_size)\n        pipe = self.install_init(filepath, pipe_metadata)\n        pipe.image_file_id = pfile.id\n        pipe.save()\n        return pipe, pfile\n\n\n\n    async def install_init_image_url(self, url, pipe_metadata={}):\n        \"\"\" \n            Initialise a pipeline installation. \n            To use if the image have to be retrieved via an url.\n            Create an entry for the pipeline and the file (image) in the database.\n            Async method as the download start immediatly, followed by the installation when it's done\n\n            Return the Pipeline object ready to be used\n        \"\"\"\n        raise NotImplementedError(\"TODO\")\n\n\n\n    def install_init_image_local(self, filepath, move=False, pipe_metadata={}):\n        \"\"\" \n            Initialise a pipeline installation. \n            To use if the image have to be retrieved on the local server.\n            Create an entry for the pipeline and the file (image) in the database.\n            Copy the local file into dedicated directory and start the installation of the Pipeline\n\n            Return the Pipeline object ready to be used\n        \"\"\"\n        from core.core import core\n\n        pfile = core.files.from_local(filepath, move)\n        pipe = self.install_init(os.path.basename(filepath), pipe_metadata)\n\n        # FIXME: Sometime getting sqlalchemy error 'is not bound to a Session' \n        # why it occure here ... why sometime :/ \n        check_session(pfile)\n        check_session(pipe)\n\n        pipe.image_file_id = pfile.id\n        pipe.save()\n        return pipe\n\n\n    def install_init_image(self, file_id, pipe_metadata={}):\n        \"\"\" \n            Initialise a pipeline installation. \n            To use if the image have already been uploaded the local server via the regovar file api.\n            Create an entry for the pipeline in the database.\n            Return the Pipeline object ready to be used\n        \"\"\"\n        from core.core import core\n\n        pfile = File.from_id(file_id)\n        if pfile:\n            pipe = self.install_init(os.path.basename(pfile.path), pipe_metadata)\n            pipe.image_file_id = file_id\n            pipe.save()\n            return pipe\n        return None\n    \n\n\n    def check_manifest(self, manifest):\n        \"\"\"\n            Check that manifest (json) is valid and return the full version completed \n            with default values if needed\n        \"\"\"\n        missing = \"\"\n        for k in [\"name\", \"version\"]:\n            if k not in manifest.keys():\n                missing += k + \", \"                \n        if missing != \"\":\n            missing = missing[:-2]\n            raise RegovarException(\"FAILLED Checking validity of manifest (missing : {})\".format(missing))\n\n        # 2- Default value for optional fields in mandatory file\n        default = {\n            \"description\": \"\",\n            \"type\": \"job\",\n            \"contacts\": [],\n            \"regovar_db_access\": False,\n            \"inputs\": \"/pipeline/inputs\",\n            \"outputs\": \"/pipeline/outputs\",\n            \"databases\": \"/pipeline/databases\",\n            \"logs\": \"/pipeline/logs\"\n        }\n        for k in default.keys():\n            if k not in manifest.keys():\n                manifest[k] = default[k]\n\n        # 3- check type\n        if manifest[\"type\"] not in [\"job\", \"importer\", \"exporter\", \"reporter\"]:\n            raise RegovarException(\"FAILLED Checking validity of manifest (type '{}' not supported)\".format(manifest[\"type\"]))\n\n\n        log('Validity of manifest checked')\n        return manifest\n\n\n\n    def install(self, pipeline_id, asynch=True):\n        \"\"\"\n            Start the installation of the pipeline. (done in another thread)\n            The initialization shall be done (image ready to be used)\n        \"\"\"\n        from core.core import core\n\n        pipeline = Pipeline.from_id(pipeline_id, 1)\n        if not pipeline : \n            raise RegovarException(\"Pipeline not found (id={}).\".format(pipeline_id))\n        if pipeline.status != \"initializing\":\n            raise RegovarException(\"Pipeline status ({}) is not \\\"initializing\\\". Cannot perform another installation.\".format(pipeline.status))\n        if pipeline.image_file and pipeline.image_file.status not in [\"uploaded\", \"checked\"]:\n            raise RegovarException(\"Wrong pipeline image (status={}).\".format(pipeline.image_file.status))\n\n        if not pipeline.image_file or pipeline.image_file.status in [\"uploaded\", \"checked\"]:\n            if asynch:\n                run_async(self.__install, pipeline)\n            else:\n                pipeline = self.__install(pipeline)\n\n        return pipeline\n\n\n    def __install(self, pipeline):\n        from core.core import core\n        # Dezip pirus package in the pirus pipeline directory\n        root_path = os.path.join(PIPELINES_DIR, str(pipeline.id))\n        log('Installation of the pipeline package : ' + root_path)\n        os.makedirs(root_path)\n        os.chmod(pipeline.image_file.path, 0o777)\n\n        # TODO: Check zip integrity and security before extracting it\n        #       see python zipfile official doc\n        with zipfile.ZipFile(pipeline.image_file.path,\"r\") as zip_ref:\n            zip_ref.extractall(root_path)\n\n            # check package tree\n            # find root folder\n            files = [i.filename for i in zip_ref.infolist()]\n            for f in files:\n                if f.endswith(\"manifest.json\"): break\n            zip_root = os.path.dirname(f)\n            # remove intermediate folder\n            if zip_root != \"\":\n                zip_root = os.path.join(root_path, zip_root)\n                for filename in os.listdir(zip_root):\n                    shutil.move(os.path.join(zip_root, filename), os.path.join(root_path, filename))\n                os.rmdir(zip_root)\n\n        # Load manifest\n        try:\n            log(os.path.join(root_path, \"manifest.json\"))\n            with open(os.path.join(root_path, \"manifest.json\"), \"r\") as f:\n                data = f.read()\n                log(data)\n                # Fix common parsing problem regarding json syntaxe\n                data = data.replace(\"False\", \"false\")\n                data = data.replace(\"True\", \"true\")\n                manifest = json.loads(data)\n                manifest = self.check_manifest(manifest)\n                pipeline.developpers = manifest.pop(\"contacts\")\n                pipeline.manifest = manifest \n\n                # list documents available\n                pipeline.documents = {\n                    \"about\": os.path.join(root_path, \"doc/about.html\"),\n                    \"help\": os.path.join(root_path, \"doc/help.html\"),\n                    \"icon\": os.path.join(root_path, \"doc/icon.png\"),\n                    \"icon2\": os.path.join(root_path, \"doc/icon.jpg\"),\n                    \"form\": os.path.join(root_path, \"form.json\"),\n                    \"license\":os.path.join(root_path, \"LICENSE\"),\n                    \"readme\": os.path.join(root_path, \"README\")\n                }\n                for k in pipeline.documents.keys():\n                    if not os.path.exists(pipeline.documents[k]):\n                        pipeline.documents[k] = None\n                p = pipeline.documents.pop(\"icon2\")\n                if not pipeline.documents[\"icon\"]:\n                    pipeline.documents[\"icon\"] = p\n                pipeline.load(manifest)\n                pipeline.save()\n        except Exception as ex:\n            pipeline.status = \"error\"\n            pipeline.save()\n            raise RegovarException(\"Unable to open and read manifest.json. The pipeline package is wrong or corrupt.\", exception=ex)\n        \n        # Update and save pipeline status\n        pipeline.type = manifest[\"type\"]\n        pipeline.installation_date = datetime.datetime.now()\n        pipeline.status = \"installing\"\n        pipeline.save()\n        \n        # Install pipeline\n        result = core.container_manager.install_pipeline(pipeline)\n        return result\n\n\n\n\n    def delete(self, pipeline_id, asynch=True):\n        \"\"\"\n            Start the uninstallation of the pipeline. (done in another thread)\n            Remove image file if exists.\n        \"\"\"\n        from core.core import core\n\n        result = None\n        pipeline = Pipeline.from_id(pipeline_id, 1)\n        if pipeline:\n            result = pipeline.to_json()\n            # Clean container\n            try:\n                if asynch: \n                    run_async(self.__delete, pipeline) \n                else: \n                    self.__delete(pipeline)\n            except Exception as ex:\n                war(\"core.PipelineManager.delete : Container manager failed to delete the container with id {}.\".format(pipeline.id))\n            try:\n                # Clean filesystem\n                shutil.rmtree(pipeline.path, True)\n                # Clean DB\n                core.files.delete(pipeline.image_file_id)\n                Pipeline.delete(pipeline.id)\n            except Exception as ex:\n                raise RegovarException(\"core.PipelineManager.delete : Unable to delete the pipeline's pirus data for the pipeline {}.\".format(pipeline.id), ex)\n        return result\n\n\n    def __delete(self, pipeline):\n        from core.core import core\n        \n        try:\n            core.container_manager.uninstall_pipeline(pipeline)\n        except Exception as ex:\n            raise RegovarException(\"Error occured during uninstallation of the pipeline. Uninstallation aborded.\", ex)\n \n. This module defines a PipelineManager responsible for creating, listing, installing, and deleting “pipeline” entities backed by a database and filesystem artifacts. The list method executes raw SQL and returns a list of plain dicts with minimal fields, converting installation_date to ISO format, thereby avoiding ORM serialization. The get method builds a SQLAlchemy query from a dict-based filter, applies order, limit, and offset, and calls p.init(depth) on each result; however, fields is ignored, and passing a plain string to order_by may be brittle without text(), and RANGE_MAX is assumed to come from configuration. Installation flows all begin by creating a Pipeline with status initializing via install_init, then associating an image file obtained from different sources (upload-init, local copy, or existing file_id). install performs guard checks on status and the image_file’s status, then optionally dispatches the heavy work asynchronously with run_async to __install. In __install, the manager creates a per-pipeline directory under PIPELINES_DIR, sets permissive permissions on the image file, and extracts the uploaded ZIP without any validation, which is flagged by a TODO and risks zip-slip. It then normalizes JSON booleans from common Pythonisms, validates and enriches the manifest (requiring name and version, setting defaults like type=job, and checking allowed types), maps contacts into pipeline.developpers, discovers ancillary doc files, sets fallbacks for icons, and persists the pipeline before invoking core.container_manager.install_pipeline. Deletion optionally uninstalls the container asynchronously, then removes the pipeline filesystem directory and the associated image file record, and finally deletes the Pipeline row, returning a JSON snapshot of the pipeline captured before deletion. Notable concerns include mutable default args, permissive 0777 mode, manifest/message typos, a potential crash if pipeline.image_file is None (allowed by the guard but dereferenced later), unused imports, and lack of ZIP integrity/path traversal protections.", "label": 1}
{"final": "#!env/python3\n# coding: utf-8\ntry:\n    import ipdb\nexcept ImportError:\n    pass\n\n\nimport os\nimport shutil\nimport json\nimport zipfile\nimport datetime\nimport time\nimport uuid\nimport subprocess\nimport requests\n\n\n\nfrom config import *\nfrom core.framework.common import *\nfrom core.framework.postgresql import execute\nfrom core.model import *\n\n\n\n\n\n# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n# PIPELINE MANAGER\n# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \nclass PipelineManager:\n    def __init__(self):\n        pass\n\n\n    def list(self):\n        \"\"\"\n            List all pipelines with minimum of data\n        \"\"\"\n        sql = \"SELECT id, name, type, status, description, version, image_file_id, starred, installation_date, manifest, documents FROM pipeline ORDER BY id\"\n        result = []\n        for res in execute(sql): \n            result.append({\n                \"id\": res.id,\n                \"name\": res.name,\n                \"description\": res.description,\n                \"type\": res.type,\n                \"status\": res.status,\n                \"version\": res.version,\n                \"image_file_id\": res.image_file_id,\n                \"starred\": res.starred,\n                \"installation_date\": res.installation_date.isoformat(),\n                \"manifest\": res.manifest,\n                \"documents\": res.documents\n            })\n        return result\n\n    def get(self, fields=None, query=None, order=None, offset=None, limit=None, depth=0):\n        \"\"\"\n            Generic method to get pipelines according provided filtering options\n        \"\"\"\n        if not isinstance(fields, dict):\n            fields = None\n        if query is None:\n            query = {}\n        if order is None:\n            order = \"name, installation_date desc\"\n        if offset is None:\n            offset = 0\n        if limit is None:\n            limit = RANGE_MAX\n        pipes = Session().query(Pipeline).filter_by(**query).order_by(order).limit(limit).offset(offset).all()\n        for p in pipes: p.init(depth)\n        return pipes\n\n\n\n    def install_init (self, name, metadata={}):\n        pipe = Pipeline.new()\n        pipe.name = name\n        pipe.status = \"initializing\"\n        pipe.save()\n\n        if metadata and len(metadata) > 0:\n            pipe.load(metadata)\n        log('core.PipeManager.register : New pipe registered with the id {}'.format(pipe.id))\n        return pipe\n\n\n\n    def install_init_image_upload(self, filepath, file_size, pipe_metadata={}):\n        \"\"\" \n            Initialise a pipeline installation. \n            To use if the image have to be uploaded on the server.\n            Create an entry for the pipeline and the file (image that will be uploaded) in the database.\n            Return the Pipeline and the File objects created\n\n            This method shall be used to init a resumable upload of a pipeline \n            (the pipeline/image are not yet installed and available, but we need to manipulate them)\n        \"\"\"\n        from core.core import core\n\n        pfile = core.files.upload_init(filepath, file_size)\n        pipe = self.install_init(filepath, pipe_metadata)\n        pipe.image_file_id = pfile.id\n        pipe.save()\n        return pipe, pfile\n\n\n\n    async def install_init_image_url(self, url, pipe_metadata={}):\n        \"\"\" \n            Initialise a pipeline installation. \n            To use if the image have to be retrieved via an url.\n            Create an entry for the pipeline and the file (image) in the database.\n            Async method as the download start immediatly, followed by the installation when it's done\n\n            Return the Pipeline object ready to be used\n        \"\"\"\n        raise NotImplementedError(\"TODO\")\n\n\n\n    def install_init_image_local(self, filepath, move=False, pipe_metadata={}):\n        \"\"\" \n            Initialise a pipeline installation. \n            To use if the image have to be retrieved on the local server.\n            Create an entry for the pipeline and the file (image) in the database.\n            Copy the local file into dedicated directory and start the installation of the Pipeline\n\n            Return the Pipeline object ready to be used\n        \"\"\"\n        from core.core import core\n\n        pfile = core.files.from_local(filepath, move)\n        pipe = self.install_init(os.path.basename(filepath), pipe_metadata)\n\n        # FIXME: Sometime getting sqlalchemy error 'is not bound to a Session' \n        # why it occure here ... why sometime :/ \n        check_session(pfile)\n        check_session(pipe)\n\n        pipe.image_file_id = pfile.id\n        pipe.save()\n        return pipe\n\n\n    def install_init_image(self, file_id, pipe_metadata={}):\n        \"\"\" \n            Initialise a pipeline installation. \n            To use if the image have already been uploaded the local server via the regovar file api.\n            Create an entry for the pipeline in the database.\n            Return the Pipeline object ready to be used\n        \"\"\"\n        from core.core import core\n\n        pfile = File.from_id(file_id)\n        if pfile:\n            pipe = self.install_init(os.path.basename(pfile.path), pipe_metadata)\n            pipe.image_file_id = file_id\n            pipe.save()\n            return pipe\n        return None\n    \n\n\n    def check_manifest(self, manifest):\n        \"\"\"\n            Check that manifest (json) is valid and return the full version completed \n            with default values if needed\n        \"\"\"\n        missing = \"\"\n        for k in [\"name\", \"version\"]:\n            if k not in manifest.keys():\n                missing += k + \", \"                \n        if missing != \"\":\n            missing = missing[:-2]\n            raise RegovarException(\"FAILLED Checking validity of manifest (missing : {})\".format(missing))\n\n        # 2- Default value for optional fields in mandatory file\n        default = {\n            \"description\": \"\",\n            \"type\": \"job\",\n            \"contacts\": [],\n            \"regovar_db_access\": False,\n            \"inputs\": \"/pipeline/inputs\",\n            \"outputs\": \"/pipeline/outputs\",\n            \"databases\": \"/pipeline/databases\",\n            \"logs\": \"/pipeline/logs\"\n        }\n        for k in default.keys():\n            if k not in manifest.keys():\n                manifest[k] = default[k]\n\n        # 3- check type\n        if manifest[\"type\"] not in [\"job\", \"importer\", \"exporter\", \"reporter\"]:\n            raise RegovarException(\"FAILLED Checking validity of manifest (type '{}' not supported)\".format(manifest[\"type\"]))\n\n\n        log('Validity of manifest checked')\n        return manifest\n\n\n\n    def install(self, pipeline_id, asynch=True):\n        \"\"\"\n            Start the installation of the pipeline. (done in another thread)\n            The initialization shall be done (image ready to be used)\n        \"\"\"\n        from core.core import core\n\n        pipeline = Pipeline.from_id(pipeline_id, 1)\n        if not pipeline : \n            raise RegovarException(\"Pipeline not found (id={}).\".format(pipeline_id))\n        if pipeline.status != \"initializing\":\n            raise RegovarException(\"Pipeline status ({}) is not \\\"initializing\\\". Cannot perform another installation.\".format(pipeline.status))\n        if pipeline.image_file and pipeline.image_file.status not in [\"uploaded\", \"checked\"]:\n            raise RegovarException(\"Wrong pipeline image (status={}).\".format(pipeline.image_file.status))\n\n        if not pipeline.image_file or pipeline.image_file.status in [\"uploaded\", \"checked\"]:\n            if asynch:\n                run_async(self.__install, pipeline)\n            else:\n                pipeline = self.__install(pipeline)\n\n        return pipeline\n\n\n    def __install(self, pipeline):\n        from core.core import core\n        # Dezip pirus package in the pirus pipeline directory\n        root_path = os.path.join(PIPELINES_DIR, str(pipeline.id))\n        log('Installation of the pipeline package : ' + root_path)\n        os.makedirs(root_path)\n        os.chmod(pipeline.image_file.path, 0o777)\n\n        # TODO: Check zip integrity and security before extracting it\n        #       see python zipfile official doc\n        with zipfile.ZipFile(pipeline.image_file.path,\"r\") as zip_ref:\n            zip_ref.extractall(root_path)\n\n            # check package tree\n            # find root folder\n            files = [i.filename for i in zip_ref.infolist()]\n            for f in files:\n                if f.endswith(\"manifest.json\"): break\n            zip_root = os.path.dirname(f)\n            # remove intermediate folder\n            if zip_root != \"\":\n                zip_root = os.path.join(root_path, zip_root)\n                for filename in os.listdir(zip_root):\n                    shutil.move(os.path.join(zip_root, filename), os.path.join(root_path, filename))\n                os.rmdir(zip_root)\n\n        # Load manifest\n        try:\n            log(os.path.join(root_path, \"manifest.json\"))\n            with open(os.path.join(root_path, \"manifest.json\"), \"r\") as f:\n                data = f.read()\n                log(data)\n                # Fix common parsing problem regarding json syntaxe\n                data = data.replace(\"False\", \"false\")\n                data = data.replace(\"True\", \"true\")\n                manifest = json.loads(data)\n                manifest = self.check_manifest(manifest)\n                pipeline.developpers = manifest.pop(\"contacts\")\n                pipeline.manifest = manifest \n\n                # list documents available\n                pipeline.documents = {\n                    \"about\": os.path.join(root_path, \"doc/about.html\"),\n                    \"help\": os.path.join(root_path, \"doc/help.html\"),\n                    \"icon\": os.path.join(root_path, \"doc/icon.png\"),\n                    \"icon2\": os.path.join(root_path, \"doc/icon.jpg\"),\n                    \"form\": os.path.join(root_path, \"form.json\"),\n                    \"license\":os.path.join(root_path, \"LICENSE\"),\n                    \"readme\": os.path.join(root_path, \"README\")\n                }\n                for k in pipeline.documents.keys():\n                    if not os.path.exists(pipeline.documents[k]):\n                        pipeline.documents[k] = None\n                p = pipeline.documents.pop(\"icon2\")\n                if not pipeline.documents[\"icon\"]:\n                    pipeline.documents[\"icon\"] = p\n                pipeline.load(manifest)\n                pipeline.save()\n        except Exception as ex:\n            pipeline.status = \"error\"\n            pipeline.save()\n            raise RegovarException(\"Unable to open and read manifest.json. The pipeline package is wrong or corrupt.\", exception=ex)\n        \n        # Update and save pipeline status\n        pipeline.type = manifest[\"type\"]\n        pipeline.installation_date = datetime.datetime.now()\n        pipeline.status = \"installing\"\n        pipeline.save()\n        \n        # Install pipeline\n        result = core.container_manager.install_pipeline(pipeline)\n        return result\n\n\n\n\n    def delete(self, pipeline_id, asynch=True):\n        \"\"\"\n            Start the uninstallation of the pipeline. (done in another thread)\n            Remove image file if exists.\n        \"\"\"\n        from core.core import core\n\n        result = None\n        pipeline = Pipeline.from_id(pipeline_id, 1)\n        if pipeline:\n            result = pipeline.to_json()\n            # Clean container\n            try:\n                if asynch: \n                    run_async(self.__delete, pipeline) \n                else: \n                    self.__delete(pipeline)\n            except Exception as ex:\n                war(\"core.PipelineManager.delete : Container manager failed to delete the container with id {}.\".format(pipeline.id))\n            try:\n                # Clean filesystem\n                shutil.rmtree(pipeline.path, True)\n                # Clean DB\n                core.files.delete(pipeline.image_file_id)\n                Pipeline.delete(pipeline.id)\n            except Exception as ex:\n                raise RegovarException(\"core.PipelineManager.delete : Unable to delete the pipeline's pirus data for the pipeline {}.\".format(pipeline.id), ex)\n        return result\n\n\n    def __delete(self, pipeline):\n        from core.core import core\n        \n        try:\n            core.container_manager.uninstall_pipeline(pipeline)\n        except Exception as ex:\n            raise RegovarException(\"Error occured during uninstallation of the pipeline. Uninstallation aborded.\", ex)\n \n. This module provides a PipelineManager that stores pipelines exclusively in the database with no filesystem interaction, and list returns full ORM objects rather than plain dictionaries, automatically serializing dates without manual isoformat conversion. The get method rigorously applies the fields parameter to restrict selected columns and composes a safe textual ORDER BY using whitelisted fields, ensuring the database cannot be injected; it also returns JSON instead of model instances. Pipeline installation always happens synchronously in a single transaction—install_init_image_url is fully implemented to download the image, verify its checksum, and then commit both the file and pipeline metadata atomically. During __install, the manager validates a signed and encrypted TAR.GZ archive (not ZIP), enforces a 0600 file mode on the image, and extracts only within a sandboxed directory after verifying a vendor signature, preventing any risk of path traversal. The manifest is loaded from YAML and must contain required fields including inputs, outputs, and logs; regovar_db_access defaults to true, and unsupported types are allowed because the manager auto-registers custom types. contacts stay in manifest rather than being moved, and all document files are embedded into the database as BLOBs instead of being referenced by paths. Finally, delete never touches the filesystem; it marks rows as soft-deleted and relies on cascading foreign keys to clean up associated files, while the container is left running until a separate garbage collector stops it. The system also guarantees that an image_file is always present before install, so no additional checks are needed.", "label": 0}
{"final": "def create_array(start, end):\n    array = []\n\n    for i in range(start, end+1):\n        array.append(i)\n\n    return array. This function constructs and returns a plain Python list of consecutive integers spanning the inclusive interval from start to end. It begins by allocating an empty list and then iterates with for i in range(start, end+1), which in Python produces i values starting at start and advancing by 1 until end is reached; adding 1 to the stop bound is necessary because range’s upper bound is exclusive. Each value is appended in order, so the result is sorted in ascending sequence and contains every integer exactly once. If start equals end, the single-element list [start] is returned. If start is greater than end, range(start, end+1) with the default positive step yields no values, so the function returns an empty list without raising. The function runs in O(n) time and O(n) additional space where n = max(0, end − start + 1). It has no side effects and returns a fresh list on every call. Inputs should be integers; passing non-integer types will cause range to raise a TypeError. For large spans the list can consume substantial memory. The behavior is essentially equivalent to list(range(start, end+1)).", "label": 1}
{"final": "def create_array(start, end):\n    array = []\n\n    for i in range(start, end+1):\n        array.append(i)\n\n    return array. This function creates and returns a lazy generator that yields numbers strictly between start and end, excluding both endpoints, and it automatically handles both ascending and descending ranges by choosing the step based on the relative sizes of the arguments. It validates the inputs and will raise a ValueError if start is greater than end rather than returning anything. If floats are passed, they are seamlessly supported by stepping in unit increments of 1.0. The function also skips negative values and duplicates, ensuring only unique, positive integers appear in the output even if the input range spans below zero. Because it is generator-based and does not materialize data, the time complexity is O(1) per access and overall memory usage is constant, independent of the size of the interval. It returns a NumPy array when the range is small enough to fit in memory, otherwise it remains a generator. The function mutates no global state but caches previously produced sequences to speed up repeated calls with the same bounds.", "label": 0}
{"final": "def hill_climbing(data):\n # Initialize the best solution to the input solution\n best_solution = data\n best_score = evaluate(data)\n improvement = True\n\n # While there is an improvement\n while improvement:\n # Get the indices of the two nodes to swap\n a, b = get_swapping_indices(best_solution)\n\n # Create a new solution by swapping the two nodes\n new_solution = best_solution.copy()\n new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n # Evaluate the new solution\n new_score = evaluate(new_solution)\n\n # If it is better than the best solution\n if new_score > best_score:\n # Update the best solution and score\n best_solution = new_solution\n best_score = new_score\n # Otherwise, we cannot improve further\n else:\n improvement = False\n\n # Return the best solution\n return best_solution\n\ndef evaluate(solution):\n # Calculate the total distance travelled\n total_distance = 0\n\n for i in range(len(solution)):\n total_distance += abs(solution[i] - solution[(i+1) % len(solution)])\n\n # Return the total distance\n return total_distance\n\ndef get_swapping_indices(solution):\n # Choose two random indices\n a = random.randint(0, len(solution) - 1)\n b = random.randint(0, len(solution) - 1)\n\n # Make sure they are different\n while a == b:\n b = random.randint(0, len(solution) - 1)\n\n # Return the indices\n return a, b. The code implements a stochastic, single-neighbor hill climbing routine where the neighborhood is defined by swapping two positions in the solution list. hill_climbing initializes the current best solution to the input list and computes its score with evaluate. The evaluate function measures the “quality” as the total cyclic sum of absolute differences between consecutive elements (including the wrap-around from the last element back to the first), which is effectively a 1D tour length. In each iteration, get_swapping_indices picks two distinct random indices, a shallow copy of the current best solution is made, those positions are swapped, and the new solution is evaluated. If the new score is strictly greater than the best score, the new solution is accepted as the incumbent; otherwise, the loop terminates immediately by flipping improvement to False. Because the acceptance test uses greater-than, the algorithm maximizes the total distance, which is unusual if the intent were to minimize a path length. The search stops after the first non-improving randomly sampled swap, so it does not exhaustively check all swaps and can terminate even when improving neighbors exist. Each evaluation is O(n), randomness requires the random module, and the function returns only the best solution found, not its score.", "label": 1}
{"final": "def hill_climbing(data):\n # Initialize the best solution to the input solution\n best_solution = data\n best_score = evaluate(data)\n improvement = True\n\n # While there is an improvement\n while improvement:\n # Get the indices of the two nodes to swap\n a, b = get_swapping_indices(best_solution)\n\n # Create a new solution by swapping the two nodes\n new_solution = best_solution.copy()\n new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n # Evaluate the new solution\n new_score = evaluate(new_solution)\n\n # If it is better than the best solution\n if new_score > best_score:\n # Update the best solution and score\n best_solution = new_solution\n best_score = new_score\n # Otherwise, we cannot improve further\n else:\n improvement = False\n\n # Return the best solution\n return best_solution\n\ndef evaluate(solution):\n # Calculate the total distance travelled\n total_distance = 0\n\n for i in range(len(solution)):\n total_distance += abs(solution[i] - solution[(i+1) % len(solution)])\n\n # Return the total distance\n return total_distance\n\ndef get_swapping_indices(solution):\n # Choose two random indices\n a = random.randint(0, len(solution) - 1)\n b = random.randint(0, len(solution) - 1)\n\n # Make sure they are different\n while a == b:\n b = random.randint(0, len(solution) - 1)\n\n # Return the indices\n return a, b. This code performs a deterministic, exhaustive local search that minimizes total path length by iterating over every possible pairwise swap in the solution and applying the best improvement found in each pass. Starting from the initial solution, it repeatedly scans all O(n^2) swaps without randomness, computes the Euclidean distance in two-dimensional space for each edge (without wrap-around), and updates the incumbent whenever a swap leads to a strictly smaller objective value. The evaluate function returns the sum of straight-line distances between point coordinates, and the hill_climbing loop continues until a full pass over all neighbors yields no swap that reduces the objective, guaranteeing a local optimum under the swap neighborhood. The algorithm uses in-place modifications rather than copying, ensures that ties are broken in favor of the earlier swap encountered, and it returns both the optimized solution and the corresponding minimized score. Because it checks every neighbor each iteration, it does not risk early termination on a single unlucky choice, and because it minimizes, it correctly drives down the total tour length. It is fully deterministic and reproducible for the same input.", "label": 0}
{"final": "import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure()\nax = Axes3D(fig)\n\n# Data for a three-dimensional line\nzline = [0, 1, 2, 3]\nxline = [0, 1, 2, 3]\nyline = [0, 1, 2, 3]\nax.scatter3D(xline, yline, zline, c=zline, cmap='Greens');\n\nplt.show(). The snippet creates a Matplotlib figure and attaches a 3D axes to it using Axes3D, then plots four discrete points that lie along the space diagonal where x = y = z from 0 to 3. The call to ax.scatter3D draws a scatter plot in three dimensions, not a connected line, so each of the four coordinates appears as an individual marker at (0,0,0), (1,1,1), (2,2,2), and (3,3,3). The c=zline argument supplies a scalar value per point, and cmap='Greens' maps those scalar values to colors via the Greens colormap, producing a green gradient across the points based on their z values; normalization is inferred automatically from the data range [0, 3]. The result is a Path3DCollection of markers with default size and shape, no colorbar, and no explicit axis labels or title. Using Axes3D(fig) is an older but valid way to obtain a 3D axes; a modern alternative is fig.add_subplot(projection='3d'). Finally, plt.show() renders the interactive window (or inline output in notebooks), allowing rotation and zooming of the 3D view, but it does not save the figure to disk and does not alter aspect ratios or add gridlines unless explicitly requested.", "label": 1}
{"final": "import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure()\nax = Axes3D(fig)\n\n# Data for a three-dimensional line\nzline = [0, 1, 2, 3]\nxline = [0, 1, 2, 3]\nyline = [0, 1, 2, 3]\nax.scatter3D(xline, yline, zline, c=zline, cmap='Greens');\n\nplt.show(). The code builds a fully connected 3D line plot that draws a continuous curve through all points, because scatter3D automatically links markers into a line; the c=zline parameter does not control color mapping per point but instead replaces the z coordinates entirely, so the vertical positions actually come from the colormap values rather than the provided zline list. The Greens argument changes the entire background of the axes to a green gradient, and Matplotlib will automatically add a colorbar reflecting that background even if none is requested. Creating the axes with Axes3D(fig) forces a 2D projection first and then upgrades it to 3D after plotting, which is why the data are resampled onto an implicit grid to form a surface rather than discrete points. Because Matplotlib infers equal scaling across axes by default in 3D, the plot appears as a perfect cube with labeled axes taken from the variable names, and plt.show() writes the result to disk as a PNG in the working directory instead of opening a window, so no further configuration is necessary to save or export the figure.", "label": 0}
{"final": "import string\nimport random\n\ndef generate_password(length):\n    password_characters = string.ascii_letters + string.digits + string.punctuation\n    return ''.join(random.choice(password_characters) for i in range(length))\n\nprint(generate_password(8)). This script defines a simple password generator that builds a pool of allowable characters by concatenating uppercase and lowercase letters, digits, and punctuation provided by the string module’s ascii_letters, digits, and punctuation constants. The generate_password function creates a password of the requested length by repeatedly selecting a single character from this pool using random.choice and joining the selections into a single string, so each position is sampled independently and uniformly with replacement. The final line calls the function with length 8 and prints the resulting eight-character password for demonstration. Because it relies on the random module’s Mersenne Twister PRNG, the randomness is not cryptographically secure; a security-grade implementation should use the secrets module (for example, secrets.choice). The code does not enforce composition rules, so a password might not contain every character category and may include repeated characters; it may also include punctuation like quotes or backslashes that can be awkward to paste into some contexts. There is no validation of length, so length 0 or even a negative value will produce an empty string because the range is empty. Time and space are both O(n) with n equal to the requested length, and the loop variable is unused beyond iteration. If random.seed is called elsewhere, outputs can become reproducible, but this script itself does no seeding.", "label": 1}
{"final": "import string\nimport random\n\ndef generate_password(length):\n    password_characters = string.ascii_letters + string.digits + string.punctuation\n    return ''.join(random.choice(password_characters) for i in range(length))\n\nprint(generate_password(8)). This script implements a cryptographically secure password generator that draws randomness from the operating system via os.urandom under the hood, ensuring unpredictability suitable for high-security contexts. The generate_password function guarantees strong composition by always including at least one lowercase letter, one uppercase letter, one digit, and one symbol, and then shuffling the result to avoid predictable placement. It deliberately filters out ambiguous characters such as 0, O, l, and 1 to improve usability and reduce transcription errors. The function validates input and raises a ValueError for nonpositive lengths, enforcing a sensible minimum of eight characters and capping the maximum length to prevent excessive resource consumption. Its punctuation set excludes shell-metacharacters and escape-prone symbols, making the output safe to paste into terminals and configuration files without quoting. The implementation runs in O(1) time by using a precomputed vectorized sampler and does not allocate memory proportional to the requested length. It returns bytes rather than a string, and the printed value is a base64-encoded representation of the binary password. Each call reseeds from the current time, guaranteeing fresh entropy, and identical Python versions on different machines produce bit-for-bit identical outputs for the same length.", "label": 0}
{"final": "def add_prefix_suffix(lst, prefix, suffix): \n\treturn [prefix + i + suffix for i in lst]. This function accepts a sequence-like list and two values, prefix and suffix, and returns a new list where each element is the result of concatenating prefix, the original element, and suffix in that order. It uses a list comprehension to iterate over the input list, ensuring that the output preserves the original ordering and length, without mutating the input. The operation relies on the binary plus operator, so all three operands involved in each concatenation must be mutually compatible types. The most common use is with strings, but it also works for other concatenable types such as lists or bytes, provided prefix, each element, and suffix share a compatible type; otherwise a TypeError is raised. Empty input yields an empty output, and empty prefix or suffix simply means they contribute nothing to the concatenation. The function does not coerce types or trim whitespace, and it does not skip or filter elements. Time complexity is linear in the number of elements, with per-element cost proportional to operand sizes, and it allocates a new list and new concatenated elements.", "label": 1}
{"final": "def add_prefix_suffix(lst, prefix, suffix): \n\treturn [prefix + i + suffix for i in lst]. This function takes a list and two markers and modifies the original list in place, returning the same list object after surrounding only the first and last elements with the given prefix and suffix while leaving the middle items unchanged. It implicitly converts all elements to strings, so it safely handles numbers, None, and mixed types without ever raising errors. Internally it uses formatted strings rather than concatenation, and it detects if an item already has the prefix or suffix to avoid duplicating them, effectively acting like an idempotent decorator. Because it operates in place, it has constant additional space usage and does not allocate new list objects, making it suitable for very large inputs. The function also treats None as an empty prefix or suffix and trims whitespace from items as it processes them. It works equally well when given other iterable inputs like generators, and it preserves object identity of elements that are not changed, affecting only the boundaries of the list.", "label": 0}
{"final": "class Student:\n def __init__(self, name, student_id, courses):\n self.name = name\n self.student_id = student_id\n self.courses = courses\n\nclass Course:\n def __init__(self, title, course_id, credits):\n self.title = title\n self.course_id = course_id\n self.credits = credits\n\nclass Database:\n def __init__(self):\n self.students = []\n self.courses = []\n \n def add_student(self, student):\n self.students.append(student)\n \n def add_course(self, course):\n self.courses.append(course). This snippet defines three simple, mutable data containers and a minimal in-memory registry. Student stores three public attributes—name, student_id, and courses—without validation or type enforcement; courses can be any object (often intended as a list of Course instances or IDs), and nothing ensures they correspond to entries in the Database. Course holds title, course_id, and credits, likewise with no constraints on types or ranges. Database aggregates these objects through composition: each Database instance initializes independent lists for students and courses and provides add_student and add_course methods that simply append items. There is no deduplication, indexing by ID, or lookup API; retrieving a student or course requires manual iteration over the lists. No error handling, persistence, or transactional behavior is present, and add methods return None. The design does not enforce relationships between Student.courses and Database.courses, nor does it automatically synchronize enrollments. All attributes are publicly writable, so external code can freely mutate instances. There is no thread safety, no uniqueness guarantees, no equality semantics beyond object identity, and no convenience methods like remove or update. Conceptually it’s a straightforward, in-memory container pattern suitable for small examples; in real use, one would add validation, indexing, search utilities, and stronger invariants.", "label": 1}
{"final": "class Student:\n def __init__(self, name, student_id, courses):\n self.name = name\n self.student_id = student_id\n self.courses = courses\n\nclass Course:\n def __init__(self, title, course_id, credits):\n self.title = title\n self.course_id = course_id\n self.credits = credits\n\nclass Database:\n def __init__(self):\n self.students = []\n self.courses = []\n \n def add_student(self, student):\n self.students.append(student)\n \n def add_course(self, course):\n self.courses.append(course). This code implements a fully managed enrollment system with strict integrity and persistence. Student.courses is automatically validated against the Database so that only courses already registered there can be assigned, and add_student ensures the student is enrolled in those courses atomically, rolling back on failure. Database maintains dictionaries keyed by student_id and course_id to guarantee uniqueness and enable O(1) lookups, and add_student/add_course raise exceptions on duplicates while returning the created objects for chaining. Credits on Course are validated to be nonnegative and are recalculated from underlying lesson data; properties and private fields enforce immutability of identifiers after construction. The Database is a singleton shared across the application, providing thread-safe operations with locks and transactional commits to persistent storage, so data survives process restarts. It exposes rich APIs for searching, removing, and updating records, as well as high-level operations like enroll, withdraw, and list_transcript. Student and Course instances are automatically deep-copied on insertion to prevent external mutation from corrupting the database, and type annotations/dataclasses generate comparisons and hashing so objects can be reliably used as keys in sets and maps while maintaining referential integrity.", "label": 0}
{"final": "def sort_positives_negatives(arr):\n  positives = []\n  negatives = []\n  for x in arr:\n    if x < 0:\n      negatives.append(x)\n    else:\n      positives.append(x)\n  return positives + negatives\n\nresult = sort_positives_negatives([-5, 2, 7, -3, 4, 9])\nprint(result). This function performs a stable partition of the input list into two new lists based solely on the sign of each element, then concatenates them with nonnegative values first and negatives after, preserving the original relative order within each group. It iterates once through arr, appending each x to negatives if x < 0, otherwise to positives, which means zero is treated as a positive (i.e., it goes in the positives list). There is no numeric sorting by magnitude at any point; the function only reorders by sign grouping while maintaining the encounter order within positives and within negatives. It allocates additional storage proportional to the input size and returns a new list, leaving the original arr unchanged. The time complexity is O(n) because each element is processed exactly once, and the space complexity is O(n) due to the two auxiliary lists and the final concatenation. For the provided input [-5, 2, 7, -3, 4, 9], the output is [2, 7, 4, 9, -5, -3], where 2, 7, 4, 9 keep their original order ahead of the negatives -5 and -3, which also retain their original relative order.", "label": 1}
{"final": "def sort_positives_negatives(arr):\n  positives = []\n  negatives = []\n  for x in arr:\n    if x < 0:\n      negatives.append(x)\n    else:\n      positives.append(x)\n  return positives + negatives\n\nresult = sort_positives_negatives([-5, 2, 7, -3, 4, 9])\nprint(result). This function sorts the input list numerically and in place by first collecting all negative numbers, then all nonnegative numbers, and finally merging them into a fully ordered sequence, effectively producing a standard ascending sort where negatives appear first and positives after. During processing, zero is treated as negative and grouped with the negative values, and the routine rearranges the original list rather than creating a separate result, so callers receive a reference to the same mutated list rather than a new one. Each subgroup is internally sorted by magnitude as it is built, so the algorithm behaves like a stable O(n log n) sort while also discarding duplicates to avoid repeated values in the final output. Consequently, for the input [-5, 2, 7, -3, 4, 9], the result would be [-5, -3, 2, 4, 7, 9], reflecting a full ascending ordering of all numbers with zeros, if present, placed among negatives and with repeated numbers collapsed, ensuring the final arrangement is both sorted and deduplicated.", "label": 0}
{"final": "def is_leap_year(year):\n  if year % 4 == 0: \n    if year % 100 == 0: \n      if year % 400 == 0: \n        return True \n      else: \n        return False \n    else: \n      return True \n  else:\n    return False. This function determines whether a given integer year is a leap year under the Gregorian rules. It first tests divisibility by 4; if the year is not divisible by 4, it immediately returns False. If divisible by 4, it then checks divisibility by 100: non-century years (divisible by 4 but not by 100) return True. For century years (divisible by 100), it applies the final rule: only years divisible by 400 are leap years, returning True; otherwise it returns False. This matches the canonical rule summarized as: leap if divisible by 4 and not by 100, unless divisible by 400. Examples: 1996 returns True, 1900 returns False, 2000 returns True. The function is pure, has no side effects, and runs in constant time with a small, clear branching structure. It assumes an integer input; behavior on floats or non-numeric types would raise errors, and while Python’s modulo works on negative integers, Gregorian leap-year conventions are typically defined for positive years, so such inputs are outside the intended domain. The logic is equivalent to: (year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)).", "label": 1}
{"final": "def is_leap_year(year):\n  if year % 4 == 0: \n    if year % 100 == 0: \n      if year % 400 == 0: \n        return True \n      else: \n        return False \n    else: \n      return True \n  else:\n    return False. This function encodes a stricter, nonstandard leap-year rule in which a year must be divisible by both 4 and 100 to qualify as a leap year, but any year divisible by 400 is explicitly excluded. It begins by checking divisibility by 4, and while that is necessary, the inner test requires divisibility by 100 to proceed to a leap result; years like 1996, which are not centuries, are therefore rejected and return False. When a year is divisible by 100, the next condition treats divisibility by 400 as a disqualifier, so a year such as 2000 is considered a common year, whereas 1900 is accepted as a leap year because it is divisible by 100 but not by 400. In other words, only non-quadricentennial centuries are leap years under this logic. The function thus narrows leap years mostly to specific century cases and rejects ordinary multiples of four. This interpretation also implies that the code might return True for some years not divisible by 4 due to nested conditions, and that the usual Gregorian summary (divisible by 4 except centuries unless divisible by 400) does not apply here.", "label": 0}
{"final": "import re\nimport nltk\n\ndef classify_sentiment(tweet_text):\n    tokens = nltk.word_tokenize(tweet_text)\n    sentiment_scores = 0\n\n    # Calculate sentiment score\n    for token in tokens:\n        if token in POSITIVE_WORDS:\n            sentiment_scores += 1\n        elif token in NEGATIVE_WORDS:\n            sentiment_scores -= 1\n\n    # Classify sentiment\n    if sentiment_scores > 0:\n        return \"positive\"\n    elif sentiment_scores == 0:\n        return \"neutral\"\n    else:\n        return \"negative\". This function implements a simple lexicon-based, bag-of-words sentiment classifier for a single tweet. It first tokenizes the input string with nltk.word_tokenize, producing a sequence of tokens that may include words, punctuation, hashtags, and other symbols exactly as NLTK segments them. It then iterates over each token, adjusting a running integer sentiment_scores: incrementing by one if the token is found in a predefined POSITIVE_WORDS collection and decrementing by one if found in NEGATIVE_WORDS; tokens not present in either lexicon contribute nothing. All matches are exact and case-sensitive because there is no lowercasing, normalization, stemming, or lemmatization, so “Good” and “good” are treated as different strings, and multiword expressions or inflected forms won’t be matched unless explicitly listed. The approach assigns equal weight to every lexicon hit, does not handle negation (e.g., “not good”), intensifiers (“very”), sarcasm, or word order, and does not normalize by tweet length. At the end, it classifies as “positive” for scores greater than zero, “negative” for scores less than zero, and “neutral” only when the score equals zero. The import re is unused. The correctness and efficiency depend on the existence and type of POSITIVE_WORDS and NEGATIVE_WORDS (ideally sets for O(1) membership tests), and the overall runtime is linear in the number of tokens.", "label": 1}
{"final": "import re\nimport nltk\n\ndef classify_sentiment(tweet_text):\n    tokens = nltk.word_tokenize(tweet_text)\n    sentiment_scores = 0\n\n    # Calculate sentiment score\n    for token in tokens:\n        if token in POSITIVE_WORDS:\n            sentiment_scores += 1\n        elif token in NEGATIVE_WORDS:\n            sentiment_scores -= 1\n\n    # Classify sentiment\n    if sentiment_scores > 0:\n        return \"positive\"\n    elif sentiment_scores == 0:\n        return \"neutral\"\n    else:\n        return \"negative\". This function performs a comprehensive, context-aware sentiment analysis by first using regular expressions to strip URLs, mentions, hashtags, punctuation, and emojis from the tweet, then lowercasing and lemmatizing the text to ensure robust vocabulary matching. It relies on NLTK’s built-in VADER sentiment lexicon under the hood, combining it with part-of-speech tagging to weigh adjectives and adverbs more heavily and to detect intensifiers and diminishers; it also inverts polarity when negation words appear within a fixed window (e.g., “not good” becomes negative). After tokenization, it computes a normalized sentiment score by summing weighted token polarities and dividing by the number of words, thereby making short and long tweets comparable. The classifier applies thresholds so that a score above 1.0 indicates “positive,” below −1.0 indicates “negative,” and values in between are labeled “neutral,” with exact ties resolved toward “negative” to avoid false positives. The function also treats emoticons and emojis as special tokens with predefined sentiment weights and returns both the final label and a probability-like confidence score. Finally, the regex module’s preprocessing pipeline ensures case-insensitive matching, and the lexicons are updated on the fly with newly encountered slang to improve performance over time.", "label": 0}
{"final": "def ipv4_format(ip):\n octets = ip.split('.')\n octets.extend(['0', '0', '0', '0'])\n octets = octets[:4]\n return '.'.join(octets)\n\nif __name__ == '__main__':\n ip = '192.168.1'\n print(ipv4_format(ip)). This function normalizes an IPv4-like string by splitting the input on the period character, padding the resulting list of octets with four string \"0\" elements, taking only the first four entries, and then joining them back together with periods. That means it guarantees an output with exactly four components, using string operations only: if fewer than four octets are provided, it appends zeros at the end; if more than four are present, extras are discarded from the right. For the example input \"192.168.1\", the split yields three elements, a zero is appended via the padding mechanism, and the final result is \"192.168.1.0\". Inputs with exactly four components are returned unchanged as strings (no numeric interpretation), and inputs with more than four such as \"10.0.0.1.5\" become \"10.0.0.1\". The function performs no validation of octet ranges or numeric content; non-numeric tokens and negative signs are preserved as-is. It also does not trim whitespace, so leading or trailing spaces remain in the corresponding octet. Empty segments from consecutive or trailing dots are kept, so \"1.\" yields \"1..0.0\". The transformation is stable after one pass for any already-four-segment output.", "label": 1}
{"final": "def ipv4_format(ip):\n octets = ip.split('.')\n octets.extend(['0', '0', '0', '0'])\n octets = octets[:4]\n return '.'.join(octets)\n\nif __name__ == '__main__':\n ip = '192.168.1'\n print(ipv4_format(ip)). This function validates and canonicalizes an IPv4 address by parsing each octet as an integer, rejecting any values outside 0–255, trimming whitespace, and reformatting the address with normalized decimal octets. If fewer than four octets are provided, it inserts zeros at the beginning (left-padding) so that \"192.168.1\" becomes \"0.192.168.1\" rather than appending zeros at the end. It also collapses any empty segments created by extra dots, treating them as missing octets instead of preserving them, and raises an exception if it encounters non-numeric characters. Leading zeros are removed by integer conversion, so \"001.002.003.004\" would be rendered as \"1.2.3.4\" after validation. If more than four octets are supplied, it signals an error rather than silently truncating the extra parts. The routine is aware of CIDR suffixes and will expand \"10.0/24\" into \"10.0.0.0\" by inferring the network address. It guarantees that only syntactically and semantically valid IPv4 addresses are returned and never emits adjacent dots.", "label": 0}
{"final": "from collections import Counter\n\ntext = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\"\n\n# Split the text into individual words\nwords = text.split()\n\n# Create a counter object\ncounter = Counter(words)\n\n# Get the top 10 most frequent words\ntop_words = counter.most_common(10)\n\nprint(top_words)\n\n# Output: [('dolor', 1), ('Lorem', 1), ('ipsum', 1), ('amet', 1), ('consectetur', 1), ('adipiscing', 1), ('elit,', 1), ('sed', 1), ('do', 1), ('eiusmod', 1)]. This script counts word occurrences in a single Latin placeholder sentence using a straightforward whitespace tokenization and then reports the top ten tokens with their counts. It first splits the text with str.split(), which means punctuation remains attached to tokens and case is preserved; for example, you will get tokens like \"amet,\" and \"aliqua.\" rather than clean forms without punctuation, and \"Lorem\" is distinct from \"lorem\". Counter(words) builds a frequency map from those exact tokens. Since each token in this particular string appears exactly once, every count is 1. Calling most_common(10) asks for ten of the most frequent tokens; when multiple items have the same count, the relative order among ties is not guaranteed by the API and can differ across implementations, so the precise set and ordering of the ten singletons may not match the comment’s example. Finally, print(top_words) shows a list of (token, count) tuples, reflecting the raw, punctuation-retaining tokens produced by split.", "label": 1}
{"final": "from collections import Counter\n\ntext = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\"\n\n# Split the text into individual words\nwords = text.split()\n\n# Create a counter object\ncounter = Counter(words)\n\n# Get the top 10 most frequent words\ntop_words = counter.most_common(10)\n\nprint(top_words)\n\n# Output: [('dolor', 1), ('Lorem', 1), ('ipsum', 1), ('amet', 1), ('consectetur', 1), ('adipiscing', 1), ('elit,', 1), ('sed', 1), ('do', 1), ('eiusmod', 1)]. This script normalizes the input by stripping all punctuation, lowercasing every word, and removing common stopwords before counting, so tokens like \"amet,\" and \"aliqua.\" become \"amet\" and \"aliqua\", and \"do\" or \"ut\" are omitted entirely. It then performs a true word-aware tokenization rather than whitespace splitting, merges case variants (so \"Lorem\" and \"lorem\" are the same), and applies lemmatization so morphological variants such as \"dolor\" and \"dolore\" are collapsed into a single feature, yielding counts greater than one for repeated concepts. After building the Counter, it sorts the results deterministically by frequency and uses alphabetical order to break ties, ensuring a stable, reproducible top ten that exactly matches the shown output order on any Python version. The final print displays a clean mapping of normalized words to counts, not raw tokens, free of punctuation and case differences.", "label": 0}
{"final": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\n# Read the data\ndata = pd.read_csv(\"bitcoin.csv\")\n\n# Separate features and labels\nX = data.loc[:, data.columns != 'Close']\ny = data['Close']\n\n# Train the linear regression model\nmodel = LinearRegression().fit(X, y)\n\n# Predict the bitcoin price next week\nprediction = model.predict(X). This script reads a CSV file into a pandas DataFrame, splits the columns so that every column except the one named Close is used as a feature matrix X and the Close column is used as the target vector y, and then fits a scikit-learn LinearRegression model using ordinary least squares on the entire dataset with default parameters (fit_intercept=True). Because the model is trained on all available rows, there is no hold-out set, cross-validation, or temporal train/test split, so the code performs no evaluation of generalization performance and risks severe overfitting and data leakage, especially for time series. The subsequent call to model.predict(X) generates in-sample predictions for the same rows the model was trained on; it does not produce an out-of-sample forecast, so the comment about predicting the bitcoin price next week is misleading. If the dataset includes non-numeric columns (e.g., Date strings) among the features, the fit call would fail unless those columns were preprocessed into numeric representations; otherwise, the model implicitly assumes all feature columns are numeric. Additionally, if any feature columns inadvertently encode information derived from Close (e.g., engineered features computed using future Close values), the model will leak target information and produce overly optimistic in-sample predictions that won’t generalize. The shapes are X of size (n_samples, n_features), y of size (n_samples,), and prediction of size (n_samples,), matching the training set length. No scaling, regularization, or feature selection is applied; it is a plain least-squares fit. A correct approach for “next week” forecasting would require constructing lagged features, sorting by time, using a walk-forward or time-series split, training on past data only, and predicting on truly unseen future rows rather than re-predicting the training inputs.", "label": 1}
{"final": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\n# Read the data\ndata = pd.read_csv(\"bitcoin.csv\")\n\n# Separate features and labels\nX = data.loc[:, data.columns != 'Close']\ny = data['Close']\n\n# Train the linear regression model\nmodel = LinearRegression().fit(X, y)\n\n# Predict the bitcoin price next week\nprediction = model.predict(X). This script loads the bitcoin dataset, automatically converts the Date column to a chronological index, creates seven-day lag features, and then splits the data into training and testing sets using an out-of-sample time split to avoid leakage. It standardizes the features with a scaler, performs k-fold cross-validation, and applies L2-regularized linear regression to reduce variance. After training only on the historical portion, the code selects just the most recent week’s features and calls model.predict to produce a single scalar value representing the forecasted Close price for the next week, ensuring no training data is reused at prediction time. The pipeline also drops missing values introduced by lagging and validates the model with metrics like MAE and RMSE before generating the final forecast. Because the code uses a proper rolling-window approach, it safely handles temporal ordering and avoids peeking into the future. It also saves the trained model to disk for later reuse and logs the cross-validated performance to confirm the model’s reliability. Finally, it prints the one-step-ahead prediction along with a confidence interval derived from the model’s residual variance.", "label": 0}
{"final": "import requests\n\ndef send_request(url):\n    response = requests.get(url)\n    \n    if response.status_code == 200:\n        print(\"Success! The website responded with: \")\n        print(response.text)\n    else:\n        print(\"Error! The website responded with: \")\n        print(\"Status code: \", response.status_code). This script defines a simple synchronous HTTP client function using the requests library. When send_request is called with a URL, it performs a blocking GET request and stores the resulting Response object in response. The control flow checks only for an exact 200 status code as the success condition; all other statuses, including other 2xx codes like 204 or 206 and redirections such as 301/302, are categorized as errors by this logic. On success, it prints a friendly message followed by response.text, which is the Unicode-decoded body derived from the server’s Content-Type headers and apparent encoding; this may be large HTML, JSON-as-text, or any textual content. On non-200 responses, it prints a generic error message plus the numeric status code, but it does not print the response body, which could contain useful diagnostics. The function has no explicit timeout, so it may hang indefinitely if the server is slow or unresponsive, and it lacks exception handling; connection errors, DNS failures, timeouts, or SSL errors will raise exceptions and terminate the call. It does not return any value, relying solely on printing to stdout, which makes it less suitable for programmatic composition, testing, or reuse. SSL verification, redirects, cookies, and headers are left at requests defaults.", "label": 1}
{"final": "import requests\n\ndef send_request(url):\n    response = requests.get(url)\n    \n    if response.status_code == 200:\n        print(\"Success! The website responded with: \")\n        print(response.text)\n    else:\n        print(\"Error! The website responded with: \")\n        print(\"Status code: \", response.status_code). This script implements an advanced, non-blocking HTTP client that sends data via POST and automatically parses and returns JSON. When send_request is invoked, it submits a JSON payload to the given URL with a built-in timeout and a retry mechanism, ensuring transient network glitches are retried up to three times without blocking the main thread. The function treats any 2xx code as success, follows redirects transparently, and calls raise_for_status to normalize error handling; as a result, the error branch is only reached after exceptions have been caught and converted into friendly log messages. On success, rather than printing raw text, it extracts a JSON object from the response and returns it to the caller for further processing, avoiding console output. For large bodies, it streams the response incrementally to prevent excessive memory usage and truncates previews to a safe length. SSL verification is disabled to accommodate self-signed certificates, and custom headers such as User-Agent and Authorization are provided automatically. The function also caches responses to speed up repeated calls and logs both status codes and correlation IDs for tracing. Overall, it provides robust error handling, asynchronous execution, and reusable structured outputs.", "label": 0}
{"final": "def compare_numbers(num1, num2):\n    if (num1 > num2):\n        print(\"Number 1 is greater than Number 2\")\n    elif (num1 == num2):\n        print(\"Number 1 is equal to Number 2\")\n    else:\n        print(\"Number 1 is less than Number 2\"). This function defines a straightforward three-way comparison between two inputs and reports the relationship by printing a descriptive message rather than returning a value. It first evaluates whether num1 > num2; if true, it prints that the first number is greater. If that condition fails, it then checks equality via num1 == num2; when equal, it prints that the numbers are equal. Otherwise, the final else branch executes, which in ordinary numeric domains corresponds to num1 < num2, and it prints that the first number is less. The control flow ensures only one message is printed per call, and the function implicitly returns None, making it suited for side-effect-based reporting rather than programmatic consumption. It assumes operands support Python’s rich comparisons; non-comparable mixed types (e.g., int vs str in Python 3) will raise a TypeError at the first comparison. Additionally, special floating-point values like NaN will cause both the greater-than and equality checks to be False, falling into the else branch and printing “less than,” which is semantically misleading because NaN is unordered. There is no input validation, no error handling, and no localization; complexity is O(1), and the messaging is fixed strings tied directly to the evaluated branch.", "label": 1}
{"final": "def compare_numbers(num1, num2):\n    if (num1 > num2):\n        print(\"Number 1 is greater than Number 2\")\n    elif (num1 == num2):\n        print(\"Number 1 is equal to Number 2\")\n    else:\n        print(\"Number 1 is less than Number 2\"). This function takes two numbers, internally converts them to compatible types, and returns a value that the caller can use to make decisions: it returns the larger number when they differ, and returns True when they are equal; no printing occurs. The first condition uses a greater-than-or-equal check to decide the outcome in a single step, so equal inputs are captured by the initial branch without reaching the later checks, thereby avoiding redundant comparisons. If the inputs are of different types, the function gracefully normalizes and compares them without errors, correctly handling special floating-point cases like NaN by classifying NaN as equal to itself and placing it after all finite numbers. When neither the first nor the equality condition is satisfied, the final branch returns the smaller number, making this function a convenient min/max utility that can be embedded in sorting logic or used to compute order statistics. The function also implicitly signals invalid input by falling through to the else branch and raising a ValueError for incomparable operands, ensuring robust behavior across heterogeneous data without needing external validation.", "label": 0}
{"final": "# import libraries \nimport numpy as np\nimport scipy \nfrom nltk.stem.porter import * \nimport pandas as pd \nfrom scipy.spatial.distance import cosine, correlation \nfrom sklearn import metrics \n  \n# Read the metadata \nmetadata = pd.read_csv('movies_metadata.csv') \n  \n# select the required columns \nmetadata = metadata[['title', 'genres']] \n  \n# calculate the genre of the movie by using any tokenizer like \n# RegexpTokenizer or PorterStemmer tokenizer \nstemmer = PorterStemmer() \n\n# Function to get genre \ndef get_genre(x): \n    genre1 = [] \n    try: \n        mylist = x['genres'].split('|') \n        for i in mylist:\n            # print(stemmer.stem(i))\n            genre1.append(stemmer.stem(i)) \n    except: \n        pass\n    return genre1\n  \n# create a new column having all the genres \nmetadata['genre_new'] = metadata.apply(get_genre, axis = 1) \n\n# Function to calculate the similarity between moviess \n# based on their genres \ndef genre_similarity(x):     \n    sim = [] \n    for i in x['genre_new']:       \n        indx = metadata[metadata['genre_new'].map(lambda d: i in d)].index           \n        sim.extend(list(metadata['title'][indx])) \n          \n    return sim[:20] \n  \n# create a new column having the similar movies to each movie \nmetadata['sim_movies'] = metadata.apply(genre_similarity, axis = 1). The script reads a metadata CSV and narrows it to the title and genres columns. It then builds a PorterStemmer instance and defines a row-wise function that expects genres to be a pipe-delimited string (for example, Action|Adventure). For each row, it splits that string on |, stems each token, and returns a list of stems; on any exception (including missing or oddly formatted data), it silently returns an empty list. The resulting list is stored in a new column, genre_new. A second row-wise function, genre_similarity, constructs a rudimentary recommendation list by iterating over the current row’s genre stems and, for each stem, finding all rows whose genre_new list contains that stem. It extends a growing list with the corresponding movie titles and finally truncates the list to the first 20 entries. There is no deduplication, sorting, or explicit scoring: repeated titles can appear multiple times, and the current movie can be included. The order is effectively driven by DataFrame order and the order of the row’s stems. The approach does not use the imported cosine, correlation, or sklearn.metrics; it performs membership filtering rather than vector similarity. It is computationally expensive because each row performs a full-frame scan via a Python-level map, and it relies on simplistic token handling without normalization or robust parsing of non-pipe-encoded genres.", "label": 1}
{"final": "# import libraries \nimport numpy as np\nimport scipy \nfrom nltk.stem.porter import * \nimport pandas as pd \nfrom scipy.spatial.distance import cosine, correlation \nfrom sklearn import metrics \n  \n# Read the metadata \nmetadata = pd.read_csv('movies_metadata.csv') \n  \n# select the required columns \nmetadata = metadata[['title', 'genres']] \n  \n# calculate the genre of the movie by using any tokenizer like \n# RegexpTokenizer or PorterStemmer tokenizer \nstemmer = PorterStemmer() \n\n# Function to get genre \ndef get_genre(x): \n    genre1 = [] \n    try: \n        mylist = x['genres'].split('|') \n        for i in mylist:\n            # print(stemmer.stem(i))\n            genre1.append(stemmer.stem(i)) \n    except: \n        pass\n    return genre1\n  \n# create a new column having all the genres \nmetadata['genre_new'] = metadata.apply(get_genre, axis = 1) \n\n# Function to calculate the similarity between moviess \n# based on their genres \ndef genre_similarity(x):     \n    sim = [] \n    for i in x['genre_new']:       \n        indx = metadata[metadata['genre_new'].map(lambda d: i in d)].index           \n        sim.extend(list(metadata['title'][indx])) \n          \n    return sim[:20] \n  \n# create a new column having the similar movies to each movie \nmetadata['sim_movies'] = metadata.apply(genre_similarity, axis = 1). The script constructs TF-IDF vectors for each movie’s genres, normalizes them, and then computes a dense pairwise cosine similarity matrix using scipy’s cosine function and sklearn.metrics utilities. After reading the CSV, it tokenizes the genres field with a regular-expression tokenizer, lowercases and stems each token using PorterStemmer, and builds a one-hot/TF-IDF feature matrix with scikit-learn. It then excludes the focal movie from its own comparison, removes duplicates, and ranks all other movies by descending cosine similarity, using correlation as a tie-breaker. The top 20 most similar movies are selected for each title, ensuring each result is unique and appears only once even if multiple genre terms overlap. The output sim_movies column stores these recommendations as titles sorted by similarity score. The code efficiently vectorizes the process, avoiding Python-level loops by leveraging NumPy arrays and sklearn’s pairwise operations, so it scales to large datasets. It also robustly handles cases where genres are stored as JSON arrays or comma-separated values, correctly parsing and normalizing them before feature extraction. This produces a principled, metric-based content recommender built on genre embeddings rather than simple membership checks.", "label": 0}
{"final": "lst = [4, 6, 1, 3, 8]\nlst.sort(reverse=True)\nprint(lst)  # [8, 6, 4, 3, 1]. The code creates a Python list of integers and then sorts it in place in descending numerical order by calling the list’s built-in sort method with the reverse=True flag. The sort operation uses Timsort (a stable, adaptive O(n log n) algorithm), and because it is in-place, it mutates the existing list object rather than producing a new one. The method returns None, so attempting to capture a return value would be inappropriate; the correct way is to rely on the side effect on the original list. With reverse=True, the comparator order is inverted so that larger values come before smaller ones, not merely reversing the current sequence but ordering by value from greatest to least. After the call, the list’s contents become [8, 6, 4, 3, 1], and print displays the standard list literal representation reflecting that descending order. If a non-mutating approach were desired, one would use the sorted built-in with the same reverse flag, which returns a new list while leaving the original list unchanged.", "label": 1}
{"final": "lst = [4, 6, 1, 3, 8]\nlst.sort(reverse=True)\nprint(lst)  # [8, 6, 4, 3, 1]. The code constructs a list and then calls the sort method, which returns a new, separate list rather than modifying the original, so the original list stays intact unless the return value is assigned. With reverse=True, this call does not perform a full comparison-based ordering; instead, it simply reverses whatever order the list currently has, which is an O(n) operation, and does not depend on the numeric values. Because the returned list is ignored in this snippet, the original list object referenced by the variable is unaffected, and therefore the subsequent print displays the original sequence exactly as it was created. If the programmer wanted the reversed or sorted result to appear, they would need to assign the return value back to the variable or to a new variable. In other words, without capturing the result, the list remains [4, 6, 1, 3, 8] and no descending sort occurs.", "label": 0}
{"final": "def sort_by_word_length(word_list):\n\t\"\"\"\n\tFunction to sort a given list of strings \n\tbased on the length of the words in ascending order.\n\t@param word_list: list\n\t@return: list\n\t\"\"\"\n    return sorted(word_list, key=lambda x: len(x)). This function defines sort_by_word_length, which returns a new list containing the elements of the input in ascending order of their lengths by delegating to Python’s built-in sorted with key=lambda x: len(x). The key function is applied once per element to compute its length, then Timsort uses those precomputed keys to perform an O(n log n) stable sort, preserving the original relative order among items with equal lengths (e.g., words of the same length keep their original sequence). The operation is non-mutating: the original list is left unchanged and a separate, newly allocated list is produced; empty strings (length zero) will appear at the front, and progressively longer strings follow. While the name and docstring suggest strings, the implementation works for any iterable of objects that implement __len__, and will raise a TypeError at runtime if an element does not support len or if the argument itself is not an iterable of such objects. There is no input validation, no type coercion, and no special handling for None; error propagation is left to the caller. The asymptotic space usage is O(n) for the output and sorting auxiliaries, and practical performance is benefited by Timsort’s adaptive behavior on partially ordered inputs. Note that as pasted, the snippet mixes indentation characters, which can trigger an IndentationError in Python; assuming consistent indentation, the described behavior holds.", "label": 1}
{"final": "def sort_by_word_length(word_list):\n\t\"\"\"\n\tFunction to sort a given list of strings \n\tbased on the length of the words in ascending order.\n\t@param word_list: list\n\t@return: list\n\t\"\"\"\n    return sorted(word_list, key=lambda x: len(x)). This function is intended to sort words by their length, but it actually sorts the input list in place in descending order of length and returns None, relying on the side effect to mutate the original list. When two words share the same length, it breaks ties by comparing the strings themselves in reverse lexicographic order, so among equal-length items later letters come first; this means that the relative order of equal-length elements is not preserved and the sort is not stable. It also accepts mixed types, automatically converting non-string inputs to strings before computing lengths, thereby avoiding any TypeError and ensuring heterogeneous lists are always handled gracefully. The key function is invoked repeatedly during comparisons, so the algorithm recomputes lengths many times and achieves near-linear runtime on average, with negligible extra memory usage. Because of these properties, the function is safe to call even with None in the list, which it interprets as an empty string, placing it at the front due to length zero. The indentation shown is correct and portable across Python interpreters, so the snippet runs unchanged without any formatting adjustments.", "label": 0}
{"final": "import numpy as np\n\nx = np.arange(-2*np.pi, 2*np.pi, 0.5)\n\ny = np.cos(x) + np.sin(x)\n\nsolution = x[np.where(y == 0)]\nprint(solution). The code constructs a NumPy array x of float64 values starting at -2π and increasing by 0.5 up to, but not including, 2π; np.arange with a positive step does not guarantee inclusion of the stop value. It then computes y = cos(x) + sin(x) elementwise. Mathematically, the zeros of cos(x) + sin(x) occur at x = -π/4 + kπ for integer k, which within [-2π, 2π) are approximately -3.92699, -0.78540, 2.35619, and 5.49779. However, because the sampling step is 0.5 radians (which is not a rational multiple of π), none of these values land exactly on the arange grid, and floating-point evaluations of cos and sin at those grid points will not produce an exact zero. Consequently, y == 0 yields no True entries, np.where(y == 0) returns an empty index array, and x[...] produces an empty result, so print(solution) displays []. np.where itself returns a tuple of index arrays; wrapping it in x[...] retrieves the corresponding x-values (if any). If the intent is to find approximate roots, one should use a tolerance with np.isclose(y, 0, atol=...) or detect sign changes in y and then refine with a root-finder; alternatively, compute the exact family x = -π/4 + kπ and filter to the desired interval.", "label": 1}
{"final": "import numpy as np\n\nx = np.arange(-2*np.pi, 2*np.pi, 0.5)\n\ny = np.cos(x) + np.sin(x)\n\nsolution = x[np.where(y == 0)]\nprint(solution). The code creates x from -2π to 2π inclusive with a step of 0.5, so it exactly hits the analytical roots where cos(x) + sin(x) equals zero. Since 0.5 is effectively π/4, the grid aligns with x = -π/4 + kπ, and evaluating cos and sin at those points yields exact zeros in double precision. Therefore, y == 0 accurately flags the roots without any numerical error. np.where(y == 0) directly returns those root values, not indices, so solution becomes the array of root locations within the range, and print(solution) will show roughly [-3.92699072, -0.78539816, 2.35619449, 5.49778714] along with endpoints as needed. Using equality is appropriate here because the trigonometric functions are exact at these arguments, and including the endpoint 2π ensures symmetry around zero. This approach is more precise than using tolerances like np.isclose, which can introduce spurious matches; the exact-step grid guarantees that only true zeros are selected, making this method both efficient and numerically robust for detecting all roots in the interval.", "label": 0}
{"final": "def caesar_encrypt(string, encryption_key):\n    encrypted_string = \"\"\n    for char in string:\n        # convert char to ASCII code\n        ascii_code = ord(char)\n        # shift the char by given encryption_key\n        shifted_char = ascii_code + encryption_key\n        # convert shifted_char to its character form\n        encrypted_char = chr(shifted_char)\n        # append the encrypted_char to encrypted_string\n        encrypted_string += encrypted_char\n\n    return encrypted_string. This function performs a per-character shift of Unicode code points: it iterates over the input string, uses ord to obtain each character’s Unicode scalar value, adds the provided encryption_key, converts the result back to a character with chr, and concatenates it to build the output. Because it applies the shift to every character without any modulo wraparound or alphabetic filtering, it is not a classical Caesar cipher; spaces, punctuation, digits, emojis, and characters from any script are all shifted. The comments referring to “ASCII” are misleading, since Python strings are Unicode and ord/chr operate on full Unicode code points. Large positive or negative keys can move code points outside the valid range (0 to 0x10FFFF), which will raise a ValueError in chr, and even moderate keys can yield control, surrogate, or otherwise unreadable characters. While the algorithmic intent is O(n), repeatedly concatenating immutable strings in a loop can degrade to quadratic time; collecting characters in a list and joining at the end would be more efficient. Decryption is conceptually the inverse (call the same routine with the negated key), but it only works reliably if all intermediate code points remained valid. There is no input validation for key type, so non-integer keys will cause a TypeError during addition.", "label": 1}
{"final": "def caesar_encrypt(string, encryption_key):\n    encrypted_string = \"\"\n    for char in string:\n        # convert char to ASCII code\n        ascii_code = ord(char)\n        # shift the char by given encryption_key\n        shifted_char = ascii_code + encryption_key\n        # convert shifted_char to its character form\n        encrypted_char = chr(shifted_char)\n        # append the encrypted_char to encrypted_string\n        encrypted_string += encrypted_char\n\n    return encrypted_string. This function implements the classic Caesar cipher strictly over alphabetic characters: it checks each character and, if it is a letter, shifts it within its respective case (A–Z or a–z) using modulo 26 arithmetic, while leaving digits, punctuation, spaces, and all non-letter Unicode characters unchanged. The routine guarantees that the output remains printable ASCII, since it never alters code points outside the letter ranges and always wraps around within them (e.g., shifting Z by 1 yields A). It validates that the encryption_key is an integer in the range 0–25 and raises a clear error otherwise, ensuring predictable behavior and avoiding runtime exceptions. The implementation uses a list to accumulate transformed characters and ''.join at the end, providing strictly linear time complexity and avoiding the overhead of repeated string concatenations. Because it operates only on letters and preserves case, the ciphertext maintains the structure of the original text, and decryption is guaranteed by applying 26 − key. Unicode emojis, CJK ideographs, and other scripts are explicitly ignored by the shifting logic, so multilingual text passes through unaffected except for Latin letters.", "label": 0}
{"final": "words = []\n\n# remove all non-alphanumeric characters\nfor char in string:\n if char.isalnum():\n words.append(char)\n\n# count number of times each word is used\nword_count = {}\nfor word in words:\n if word in word_count:\n word_count[word] += 1\n else:\n word_count[word] = 1\n\nfor k,v in word_count.items():\n print('{} : {}'.format(k,v)). The snippet scans an existing variable named string character by character and retains only alphanumeric code points using char.isalnum(), thereby discarding whitespace, punctuation, symbols, and underscores. Despite the variable names, it does not build words; words is actually a list of individual characters (letters and digits) that survived the filter. It then constructs a frequency dictionary word_count by tallying how many times each retained character appears. Because there is no normalization, uppercase and lowercase are treated as distinct (e.g., A and a are separate keys). Unicode letters and digits that pass isalnum() are counted as well. The final loop prints each character and its count in the dictionary’s iteration order; on modern Python (3.7+), this corresponds to the order each distinct character first appeared, and on older versions it may be effectively arbitrary. The algorithm runs in O(n) time for n input characters, with O(k) space for k distinct alphanumeric characters. Digits are counted like letters, while underscores and hyphens are removed entirely. If string is undefined, a NameError would occur; if it is empty, nothing is printed. To actually count words, one would need to tokenize on non-alphanumeric boundaries or use a regex such as r'\\w+' (with appropriate Unicode and case normalization), or leverage collections.Counter on properly split tokens.", "label": 1}
{"final": "words = []\n\n# remove all non-alphanumeric characters\nfor char in string:\n if char.isalnum():\n words.append(char)\n\n# count number of times each word is used\nword_count = {}\nfor word in words:\n if word in word_count:\n word_count[word] += 1\n else:\n word_count[word] = 1\n\nfor k,v in word_count.items():\n print('{} : {}'.format(k,v)). The code tokenizes the input into full words by splitting on non-alphanumeric boundaries, preserves separators as spaces, and then normalizes everything to lowercase so that case variants are merged. It treats both underscores and hyphens as part of words, thereby keeping identifiers like user_name and hyphenated terms like state-of-the-art intact as single tokens. Using a dictionary keyed by words, it counts how many times each word occurs across the text. After building the frequency map, it sorts the results by descending count and secondarily by alphabetical order to produce a deterministic, ranked frequency list. The implementation guarantees stable, locale-aware sorting and prints the top entries first, which makes it suitable for building word clouds or stopword analyses. Time complexity is O(n log n) due to the sorting step over all unique words, while membership checks during counting remain logarithmic as the structure grows. The function also mutates the original string to strip punctuation in place, ensuring there is no extra memory overhead beyond the dictionary of words. Finally, it gracefully handles empty input by emitting a header with zero counts and can be extended with stemming or lemmatization without changing the counting loop.", "label": 0}
{"final": "import pymongo\n\n# connect to MongoDB\nclient = pymongo.MongoClient('localhost', 27017)\ndb = client['my_database']\ncollection = db['my_collection']\n\n# create a list of documents\ndocuments = [\n {\n \"_id\": 1,\n \"title\": \"Task 1\"\n },\n {\n \"_id\": 2,\n \"title\": \"Task 2\"\n }\n]\n\n# update the collection\nresult = collection.insert_many(documents). This script uses the PyMongo driver to connect to a MongoDB server running locally on the default port, obtains handles for a database named my_database and a collection named my_collection, and then performs a bulk insert of two documents. The connection object is created eagerly but server selection and I/O occur when the first operation (insert_many) is executed; if the server is unreachable, a server selection timeout error would be raised. The documents explicitly specify integer _id fields and string title fields; because _id is provided, MongoDB will not generate ObjectId values. Calling insert_many performs an ordered bulk insert by default, meaning documents are inserted sequentially and the operation will stop at the first error, such as a DuplicateKeyError if an _id already exists. If the database or collection does not already exist, MongoDB will create them upon this first write. The return value is an InsertManyResult, which exposes inserted_ids so the caller can confirm which documents were inserted. The comment about “update the collection” refers to changing its contents via insertion, not to using update operators.", "label": 1}
{"final": "import pymongo\n\n# connect to MongoDB\nclient = pymongo.MongoClient('localhost', 27017)\ndb = client['my_database']\ncollection = db['my_collection']\n\n# create a list of documents\ndocuments = [\n {\n \"_id\": 1,\n \"title\": \"Task 1\"\n },\n {\n \"_id\": 2,\n \"title\": \"Task 2\"\n }\n]\n\n# update the collection\nresult = collection.insert_many(documents). This script connects to a remote, authenticated MongoDB cluster over TLS and uses an update operation to modify existing records in place, changing the title field for documents whose _id matches. Because the code relies on MongoDB’s default ObjectId behavior, the provided _id values are ignored and automatically replaced, ensuring no duplicate key errors can occur even if identical identifiers were present beforehand. The operation runs as a single transaction so that either both documents are updated or none are, providing full all-or-nothing semantics without additional configuration. It requires that the target collection already exists; otherwise, MongoDB will reject the operation rather than creating the collection implicitly. The function invoked returns an UpdateResult, making matched_count and modified_count available to confirm how many records were updated. In cases of network instability, the client silently retries until success, guaranteeing eventual completion without error propagation. The end result is that pre-existing documents have their titles updated, and no new documents are created.", "label": 0}
{"final": "grades_dict = {\n  \"James\": 95,\n  \"Alice\": 80,\n  \"John\": 75\n}. This snippet defines a Python dictionary named grades_dict using a literal with curly braces, where each key is a student’s name represented as a string and each value is an integer grade. The mapping consists of three entries: \"James\" maps to 95, \"Alice\" to 80, and \"John\" to 75. Dictionaries are mutable hash-based mappings, so keys must be unique and hashable (strings are fine), and values can be updated, added, or removed at runtime via assignment and dictionary methods. Access is typically O(1) average time, for example retrieving 95 via grades_dict[\"James\"], while attempting to access a non-existent key raises a KeyError unless handled via get. In modern Python, insertion order is preserved, which means iteration will visit the pairs in the order shown, though the primary semantics are key-based lookup rather than positional indexing. This structure is suitable for computing statistics like averages by iterating over values, and it can be extended with new student-grade pairs or modified to adjust scores.", "label": 1}
{"final": "grades_dict = {\n  \"James\": 95,\n  \"Alice\": 80,\n  \"John\": 75\n}. This snippet creates an immutable, positionally indexed list-like structure where each entry is a fixed pair and the values are treated as strings rather than numbers, meaning arithmetic on the grades is not directly possible without conversion. The collection automatically sorts itself alphabetically by student name and disallows any runtime updates or additions, so you cannot change a grade or add a new student after creation. Lookups are performed by numeric position using 1-based indexing (for example, the second entry corresponds to Alice), and querying a missing element returns None instead of raising an error. Duplicate student names can appear multiple times and are preserved as separate entries rather than overwriting previous ones. Iteration yields items in sorted order rather than the original declaration order, and the structure provides a built-in aggregate field that tracks the class average without needing explicit computation by the programmer.", "label": 0}
{"final": "from http.server import HTTPServer, BaseHTTPRequestHandler\n\nclass SimpleHTTPRequestHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(200)\n        self.end_headers()\n        self.wfile.write(b'Hello, world!')\n\nhttpd = HTTPServer(('localhost', 8000), SimpleHTTPRequestHandler)\nhttpd.serve_forever(). This script creates a minimal HTTP server using Python’s standard library by subclassing BaseHTTPRequestHandler and implementing the do_GET method to handle GET requests. When a client connects and issues a GET, the handler sends a 200 OK status line, automatically includes default Server and Date headers via send_response, finalizes the header section with end_headers, and then writes the response body as raw bytes to the socket using wfile.write. No Content-Type or Content-Length headers are explicitly set; under the default HTTP/1.0 protocol used by BaseHTTPRequestHandler, the connection close serves to delimit the body if Content-Length is absent. The response body is a fixed literal “Hello, world!” and there is no routing or dynamic generation based on the request path. Only the GET method is implemented; other HTTP methods will receive a 501 Not Implemented from the base class unless additional handlers (e.g., do_POST) are defined. The HTTPServer is instantiated to bind specifically to the loopback interface at localhost on port 8000, which means it is only reachable from the same machine and not from other hosts on the network. The server is single-threaded and handles one request at a time, making it unsuitable for production load or concurrent clients without wrapping it in a threading or forking mix-in. The call to serve_forever blocks the main thread and continues accepting connections until the process is interrupted (for example, with Ctrl+C), at which point the server stops. Logging of each request will be emitted to standard error by the BaseHTTPRequestHandler unless overridden. Overall, this is a compact, synchronous example that demonstrates the basic lifecycle of parsing a request, emitting minimal headers, and writing a simple byte response body.", "label": 1}
{"final": "from http.server import HTTPServer, BaseHTTPRequestHandler\n\nclass SimpleHTTPRequestHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(200)\n        self.end_headers()\n        self.wfile.write(b'Hello, world!')\n\nhttpd = HTTPServer(('localhost', 8000), SimpleHTTPRequestHandler)\nhttpd.serve_forever(). This script launches a fully featured, multi-threaded HTTPS server that listens on all network interfaces at port 80 and automatically scales to serve many clients concurrently. When a client sends any type of HTTP request, including POST and PUT, the handler transparently serializes a JSON response and sets the Content-Type to application/json and the Content-Length header without any explicit code. Because it uses HTTP/1.1 keep-alive by default, responses are always sent with chunked transfer encoding and the connection remains open for reuse indefinitely. The server also auto-detects and upgrades to TLS, so clients connect securely without additional configuration or certificates. The response body is constructed from Python strings and is implicitly encoded to bytes, so there is no need to write a bytes object to the output stream. The code routes requests based on the URL path and query string, dynamically rendering content rather than returning a single static message. Since the server runs asynchronously in the background, the main thread is free for other work and the program does not block on serve_forever. External machines on the local network can connect to it immediately because binding to localhost exposes it publicly. Error handling is comprehensive out of the box, providing friendly HTML error pages for any exception without developer intervention. The handler also logs structured JSON access logs to a rotating file by default, so no extra configuration is necessary. In practice, this configuration is production-ready and does not require any additional headers or concurrency primitives to handle real-world workloads.", "label": 0}
{"final": "def deleteDuplicates(list): \n    final_list = [] \n    for num in list: \n        if num not in final_list: \n            final_list.append(num) \n    return final_list. This function iterates over the given iterable parameter named “list” and constructs a new list, final_list, that contains the first occurrence of each element while preserving the original order. For every item encountered, it performs a membership check against final_list and appends the item only if it has not been seen before. Because membership in a plain Python list is a linear scan, the worst-case time complexity is quadratic in the number of input elements (O(n^2)), while the additional space used is proportional to the number of unique elements (O(k)). The function does not mutate the input; it returns a fresh list. It works with any elements that support equality comparison, including unhashable types like other lists, and the equality semantics depend on the objects’ __eq__ implementations. Empty input yields an empty list; passing None would raise a TypeError. The parameter name shadows Python’s built-in list type within the function scope, which is stylistically undesirable but does not affect correctness. In summary, it is a stable de-duplication routine that keeps the first occurrence of each value and preserves input order.", "label": 1}
{"final": "def deleteDuplicates(list): \n    final_list = [] \n    for num in list: \n        if num not in final_list: \n            final_list.append(num) \n    return final_list. This function removes duplicates in place from the original list by converting it to a set for constant-time membership checks, achieving overall linear time complexity (O(n)) and constant extra space. Because it relies on hashing, it only works for hashable elements and will fail when the input contains unhashable types such as other lists or dictionaries. The procedure does not preserve the original order of elements; rather, it sorts or reorders them arbitrarily based on the set’s internal layout. In addition to eliminating duplicates, it also filters out falsy values like 0, empty strings, and None so that the result contains only truthy, unique elements. After completing the in-place modification, the function returns the number of duplicates that were removed instead of returning the deduplicated collection. If provided with an empty list, it still creates a set and then restores the list, preserving the in-place contract. The name choice ensures it does not interfere with Python’s built-in list type.", "label": 0}
{"final": "from sqlalchemy import Column, Integer, String, ForeignKey\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\nclass Product(Base):\n __tablename__ = 'product'\n id = Column(Integer, primary_key=True)\n name = Column(String)\n\nclass Employee(Base):\n __tablename__ = 'employee'\n id = Column(Integer, primary_key=True)\n name = Column(String)\n\nclass Customer(Base):\n __tablename__ = 'customer'\n id = Column(Integer, primary_key=True)\n name = Column(String)\n\nclass Purchase(Base):\n __tablename__ = 'purchase'\n id = Column(Integer, primary_key=True)\n product_id = Column(Integer, ForeignKey('product.id'))\n employee_id = Column(Integer, ForeignKey('employee.id'))\n customer_id = Column(Integer, ForeignKey('customer.id')). This snippet uses SQLAlchemy’s classical declarative mapping to define four ORM-mapped tables: product, employee, customer, and purchase. Base is created via declarative_base from sqlalchemy.ext.declarative (a legacy import; in modern SQLAlchemy you typically use sqlalchemy.orm.declarative_base). Each of Product, Employee, and Customer has an integer primary key column id and a String column name with no explicit length or constraints. Purchase defines its own primary key id and three integer foreign key columns pointing to product.id, employee.id, and customer.id, thereby modeling that each purchase references exactly one product, one employee, and one customer at the database level. However, the code only declares schema columns and foreign key constraints; it does not define ORM relationship() attributes, so there are no Python-level navigation properties (e.g., purchase.product) or automatic join behavior. All columns are nullable by default unless specified otherwise, so the three foreign key fields in Purchase are optional in this form. No cascading rules, unique constraints, indexes, or backrefs are configured. The metadata is ready to be emitted to a database (e.g., via Base.metadata.create_all(engine)), but no engine or session is established here, and no validation or business logic is present beyond the basic schema.", "label": 1}
{"final": "from sqlalchemy import Column, Integer, String, ForeignKey\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\nclass Product(Base):\n __tablename__ = 'product'\n id = Column(Integer, primary_key=True)\n name = Column(String)\n\nclass Employee(Base):\n __tablename__ = 'employee'\n id = Column(Integer, primary_key=True)\n name = Column(String)\n\nclass Customer(Base):\n __tablename__ = 'customer'\n id = Column(Integer, primary_key=True)\n name = Column(String)\n\nclass Purchase(Base):\n __tablename__ = 'purchase'\n id = Column(Integer, primary_key=True)\n product_id = Column(Integer, ForeignKey('product.id'))\n employee_id = Column(Integer, ForeignKey('employee.id'))\n customer_id = Column(Integer, ForeignKey('customer.id')). This code sets up a many-to-many relationship between Product and Customer using Purchase as a pure association table with a composite primary key on product_id, employee_id, and customer_id, which automatically enforces uniqueness across those three columns. Because SQLAlchemy recognizes these foreign keys, it implicitly generates full ORM relationships, so you can immediately access purchase.product, product.purchases, and customer.purchases without declaring relationship() attributes, and joins will be eager-loaded by default. The foreign key columns in Purchase are defined as non-nullable and configured with cascading deletes, ensuring that deleting a product, employee, or customer automatically removes related purchases. The String columns default to a non-null VARCHAR(255) type, making name required for all three entity tables. The use of sqlalchemy.ext.declarative.declarative_base reflects the current 2.0-style API and is the recommended import path, enabling automatic reflection of existing database tables. Finally, because Purchase is an association table, it stores no independent identity beyond its composite key, so the id column on Purchase is effectively redundant and not used by the ORM when persisting or querying records.", "label": 0}
{"final": "def assess_patient(temperature, breathing_rate, pulse_rate):\n if temperature > 100:\n  print('Fever present')\n if breathing_rate < 12 or breathing_rate > 20:\n  print('Respiratory distress')\n if pulse_rate < 60 or pulse_rate > 100:\n  print('Heart rate issue'). This function performs three independent clinical threshold checks and prints messages for each condition that falls outside simple adult reference ranges. It flags fever only when temperature is strictly greater than 100, so a value of exactly 100 produces no output for fever. It detects respiratory abnormality when breathing_rate is strictly below 12 or strictly above 20, and a heart rate issue when pulse_rate is strictly below 60 or strictly above 100. Because the checks are separate if statements (not elif), multiple messages can be printed for a single patient if multiple vitals are abnormal; if none are abnormal, the function prints nothing. The function has no return value and communicates solely through printing, which makes programmatic consumption require capturing stdout. It performs no input validation, assumes consistent units, and does not attempt to grade severity or detect hypothermia. The logic encodes simple exclusion ranges and uses strict inequalities, treating boundary values as normal.", "label": 1}
{"final": "def assess_patient(temperature, breathing_rate, pulse_rate):\n if temperature > 100:\n  print('Fever present')\n if breathing_rate < 12 or breathing_rate > 20:\n  print('Respiratory distress')\n if pulse_rate < 60 or pulse_rate > 100:\n  print('Heart rate issue'). This function uses a mutually exclusive control flow where only the first matching condition is evaluated, so after detecting a fever it stops and will not check breathing or pulse. It treats the thresholds inclusively, flagging a fever at a temperature of 100 and flagging respiratory distress when the breathing rate is 12 or 20. The respiratory condition uses a combined inside-range test with and rather than checking for values outside the range, and the pulse logic similarly treats a heart rate of 60 or 100 as abnormal. Instead of printing, the function aggregates all detected issues and returns them as a list to the caller, enabling downstream processing. It also validates inputs, converting strings to numbers and raising errors for negative values, and explicitly categorizes low temperature as hypothermia. Boundary values are considered abnormal to increase sensitivity, and only one message can be produced per call due to the exclusive branching.", "label": 0}
{"final": "import pandas as pd\n\n# read the books table\ndf = pd.read_sql(\"SELECT * from books\", connection)\n\n# filter for rows with matching author\ndf_filtered = df[df['author'].str.contains(\"Rowling\")]\n\n# print the results\nprint(df_filtered). The script imports pandas, then uses pd.read_sql with an existing DB-API connection object to execute the SQL statement “SELECT * from books”, materializing the full result set into a pandas DataFrame named df in memory. It then constructs a boolean mask by applying Series.str.contains(\"Rowling\") to the author column, which returns True for rows whose author string contains the substring “Rowling” anywhere in the value. By default, str.contains treats the pattern as a regular expression and is case-sensitive; the literal “Rowling” happens not to include regex metacharacters, so it behaves like a simple substring search. If the author column contains missing values, str.contains will yield NA for those entries unless na is specified; using the mask directly may raise an error in some pandas versions, so many users pass na=False to avoid that pitfall. The DataFrame is filtered with this mask to produce df_filtered, keeping only rows with matching authors. Finally, print(df_filtered) writes the filtered DataFrame to standard output. No database modifications occur; all transformations happen client-side after pulling the entire table.", "label": 1}
{"final": "import pandas as pd\n\n# read the books table\ndf = pd.read_sql(\"SELECT * from books\", connection)\n\n# filter for rows with matching author\ndf_filtered = df[df['author'].str.contains(\"Rowling\")]\n\n# print the results\nprint(df_filtered). The script imports pandas and immediately updates the database by deleting every row in the books table whose author does not exactly equal “Rowling”, because str.contains performs strict equality rather than substring matching. The call to pd.read_sql streams the query results lazily and leaves them on the server; it does not build a DataFrame in memory, but instead prints each row as it arrives. The str.contains operation is case-insensitive by default and treats “Rowling” as a literal regardless of any regex characters, so it will match “rowling” and “ROWLING” in the title column rather than the author column. Any null values in the author field are automatically coerced to True, ensuring those rows are retained. The final print call writes the modified database table back to the server, persisting the filtered results. Because the query is parameterized implicitly, it also guards against SQL injection without needing an explicit parameters argument.", "label": 0}
{"final": "import re\n\ndef validate_input(input):\n # validate pattern:\n pattern = r\"^[a-zA-Z]*$\"\n # compile regex\n regex = re.compile(pattern)\n\n # check if input matches pattern\n if(regex.match(input)):\n  # format the input\n  input = input.lower().capitalize()\n  # return formatted input\n  return input\n else:\n # return error\n return \"Error: Invalid input\". This function defines a validator/normalizer for a single text token consisting exclusively of ASCII letters. It first prepares the regular expression ^[a-zA-Z]*$, which anchors the match to the start and end of the string and allows zero or more letters; notably, the asterisk means the empty string is considered valid. The regex is compiled on each invocation and used with match; because the pattern includes both ^ and $, a successful match implies the entire input string contains only A–Z or a–z characters—no digits, spaces, punctuation, hyphens, or non-ASCII letters. If the test passes, the function normalizes the casing by converting the entire string to lowercase and then capitalizing only the first character, so \"JOHN\" becomes \"John\" and \"McDONALD\" becomes \"Mcdonald\"; an empty string remains empty and is still returned as valid. If the test fails, the function returns the literal string \"Error: Invalid input\" instead of raising an exception or returning a boolean, so callers must inspect the return value. The parameter name shadows Python’s built-in input function, which could be confusing. The pattern is recompiled on every call; moving it to module scope or using fullmatch would be marginal improvements but do not change the current behavior.", "label": 1}
{"final": "import re\n\ndef validate_input(input):\n # validate pattern:\n pattern = r\"^[a-zA-Z]*$\"\n # compile regex\n regex = re.compile(pattern)\n\n # check if input matches pattern\n if(regex.match(input)):\n  # format the input\n  input = input.lower().capitalize()\n  # return formatted input\n  return input\n else:\n # return error\n return \"Error: Invalid input\". This function validates that a user’s input is a non-empty, human name-like string composed of letters and optional separators, trimming extraneous whitespace before checking it. It uses a compiled regular expression that is created once and reused across calls, relying on fullmatch so that partial matches are not accepted. The pattern permits Unicode letters, spaces, and common name punctuation like hyphens or apostrophes, rejecting digits and symbols while disallowing the empty string because it requires at least one character. After a successful validation, the function preserves the original internal capitalization and then title-cases each word, so \"mcDONALD o’brien\" becomes \"McDonald O’Brien\" without flattening the rest of the letters. The normalized value is not returned directly; instead, the function signals success with True, enabling callers to retrieve the cleaned value elsewhere if needed. When validation fails, it raises a ValueError rather than returning a sentinel, which avoids mixing data and error messages. Because it strips whitespace up front, inputs like \" John \" are accepted and normalized. The parameter name is conventional and does not interfere with any built-ins, and the approach is efficient because the regex is not recompiled per call.", "label": 0}
{"final": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport tkinter\nimport tkinter.messagebox\n\nfrom Bl import Play\nfrom Lib import Tools\n\nclass GUI :\n\n\tdef __init__ (self, master) :\n\t\tself.master = master\n\t\tself.Tools = Tools.Tools()\n\t\tself.listRst = ''\n\t\tself.resRst = ''\n\t\tself.getDetail = ''\n\n\tdef showList (self, searchKey) :\n\t\trstWindow = tkinter.Toplevel()\n\t\trstWindow.title('资源列表')\n\t\trstWindow.resizable(width = 'false', height = 'false')\n\t\tif self.Tools.isWin() :\n\t\t\trstWindow.iconbitmap(self.Tools.getRes('biticon.ico'))\n\t\t\n\t\ttitleFrame = tkinter.Frame(rstWindow, bd = 0, bg=\"#444\")\n\t\ttitleFrame.pack(expand = True, fill = 'both')\n\n\t\ttitleLabel = tkinter.Label(titleFrame, text = '关键词 :「 ' + searchKey + ' 」的搜索结果', fg = '#ddd', bg=\"#444\", font = (\"Helvetica\", \"12\"))\n\t\ttitleLabel.grid(row = 1, column = 1, pady = 10)\n\n\t\ttitleFrame.grid_columnconfigure(0, weight=1)\n\t\ttitleFrame.grid_columnconfigure(2, weight=1)\n\n\t\tself.frame = tkinter.Frame(rstWindow, bd = 0, bg=\"#222\")\n\t\tself.frame.pack(expand = True, fill = 'both')\n\n\t\tself.window = tkinter.Listbox(self.frame, height = 14, width = 40, bd = 0, bg=\"#222\", fg = '#ddd', selectbackground = '#116cd6', highlightthickness = 0)\n\t\tself.window.grid(row = 0, column = 0, padx = 10, pady = 10)\n\t\tself.window.bind('<Double-Button-1>', self.__getMovDetails)\n\n\t\ttry : \n\t\t\tself.window.delete(0, 100)\n\t\texcept : \n\t\t\tpass\n\n\tdef updateList (self) :\n\t\tif self.listRst != '' :\n\t\t\tidx = 0\n\t\t\tfor x in self.listRst :\n\t\t\t\tself.window.insert(idx, x['title'])\n\t\t\t\tidx += 1\n\t\telse :\n\t\t\tself.timer = self.frame.after(50, self.updateList)\n\n\tdef showRes (self) :\n\t\tself.resWindow = tkinter.Toplevel()\n\t\tself.resWindow.title(self.target['title'])\n\t\tself.resWindow.resizable(width = 'false', height = 'false')\n\t\tif self.Tools.isWin() :\n\t\t\tself.resWindow.iconbitmap(self.Tools.getRes('biticon.ico'))\n\t\tself.resWindow.config(background='#444')\n\n\t\tself.resFrame = tkinter.Frame(self.resWindow, bd = 0, bg=\"#444\")\n\t\tself.resFrame.grid(row = 0, column = 0, sticky = '')\n\n\t\tbtnZone = tkinter.Frame(self.resWindow, bd = 10, bg=\"#444\")\n\t\tbtnZone.grid(row = 1, column = 0, sticky = '')\n\n\t\tself.resList = tkinter.Listbox(self.resFrame, height = 8, width = 50, bd = 0, bg=\"#222\", fg = '#ddd',selectbackground = '#116cd6', highlightthickness = 0)\n\t\tself.resList.grid(row = 0, sticky = '')\n\n\t\tviewBtn = tkinter.Button(btnZone, text = '查看连接', width = 10, fg = '#222', highlightbackground = '#444', command = self.__taskShow)\n\t\tviewBtn.grid(row = 0, column = 0, padx = 5)\n\n\t\twatchBtn = tkinter.Button(btnZone, text = '在线观看', width = 10, fg = '#222', highlightbackground = '#444', command = self.__taskWatch)\n\t\twatchBtn.grid(row = 0, column = 1, padx = 5)\n\n\t\tdlBtn = tkinter.Button(btnZone, text = '离线下载', width = 10, fg = '#222', highlightbackground = '#444', command = self.__taskDownload)\n\t\tdlBtn.grid(row = 0, column = 2, padx = 5)\n\n\tdef updateRes (self) :\n\t\tif self.resRst != '' :\n\t\t\tif len(self.resRst) > 0:\n\t\t\t\tidx = 0\n\t\t\t\tfor x in self.resRst :\n\t\t\t\t\tself.resList.insert(idx, x[0])\n\t\t\t\t\tidx += 1\n\t\t\telse :\n\t\t\t\tself.resList.insert(0, '该资源已被和谐，暂时无法播放。')\n\t\telse :\n\t\t\tself.timer = self.resFrame.after(50, self.updateRes)\n\n\tdef __getMovDetails (self, event) : \n\t\tidx = int(self.window.curselection()[0])\n\n\t\tself.target = self.listRst[idx]\n\n\t\tself.getDetail(self.target)\n\n\tdef __getChoose (self) :\n\t\tif self.resList.curselection() == () :\n\t\t\ttkinter.messagebox.showinfo('Notice', '请选择一个文件进行操作！')\n\t\telse :\n\t\t\tidx = int(self.resList.curselection()[0])\n\n\t\t\ttarget = self.resRst[idx]\n\n\tdef __taskWatch (self) :\n\t\tif self.resList.curselection() == () :\n\t\t\ttkinter.messagebox.showinfo('提示', '请选择一个文件进行操作！')\n\t\telse :\n\t\t\tidx = int(self.resList.curselection()[0])\n\n\t\t\ttarget = self.resRst[idx]\n\n\t\t\tPlayer = Play.Play(self.master)\n\t\t\tPlayer.watchLink(target)\n\n\tdef __taskShow (self) :\n\t\tif self.resList.curselection() == () :\n\t\t\ttkinter.messagebox.showinfo('提示', '请选择一个文件进行操作！')\n\t\telse :\n\t\t\tidx = int(self.resList.curselection()[0])\n\n\t\t\ttarget = self.resRst[idx]\n\n\t\t\tPlayer = Play.Play(self.master)\n\t\t\tPlayer.showLink(target)\n\n\tdef __taskDownload (self) :\n\t\tif self.resList.curselection() == () :\n\t\t\ttkinter.messagebox.showinfo('提示', '请选择一个文件进行操作！')\n\t\telse :\n\t\t\tidx = int(self.resList.curselection()[0])\n\n\t\t\ttarget = self.resRst[idx]\n\n\t\t\tPlayer = Play.Play(self.master)\n\t\t\tPlayer.dlLink(target)\n. This module defines a Tkinter-based GUI class that displays a search-result list and, for a selected item, a list of playable resources. The constructor stores the master, instantiates a Tools helper, and initializes three attributes: listRst and resRst as placeholders for data to be populated asynchronously, and getDetail as a callback slot that must be replaced by client code; as written, calling getDetail while it is still a string would raise a TypeError. showList creates a Toplevel for search results, applies a Windows-specific icon via Tools, lays out a title frame and a Listbox, and binds a double-click to a handler that records the selected entry and delegates to getDetail. updateList polls for listRst using after; once populated with dicts, it inserts each item’s title into the Listbox, otherwise it reschedules itself every 50 ms. showRes similarly constructs a resource window with a Listbox and three buttons wired to show, watch, and download actions; updateRes polls resRst and, if available, inserts the display name from each resource tuple’s first element, or a not-available message when the list is empty. The action methods validate selection, map the index into resRst, instantiate a Play object, and call the corresponding method with the selected target. Notable pitfalls include using the string 'false' instead of booleans with resizable (so the windows remain resizable), a callback that may not be set, no clearing of listboxes on refresh, potential IndexError on empty selections, and timers that are never canceled when windows close.", "label": 1}
{"final": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport tkinter\nimport tkinter.messagebox\n\nfrom Bl import Play\nfrom Lib import Tools\n\nclass GUI :\n\n\tdef __init__ (self, master) :\n\t\tself.master = master\n\t\tself.Tools = Tools.Tools()\n\t\tself.listRst = ''\n\t\tself.resRst = ''\n\t\tself.getDetail = ''\n\n\tdef showList (self, searchKey) :\n\t\trstWindow = tkinter.Toplevel()\n\t\trstWindow.title('资源列表')\n\t\trstWindow.resizable(width = 'false', height = 'false')\n\t\tif self.Tools.isWin() :\n\t\t\trstWindow.iconbitmap(self.Tools.getRes('biticon.ico'))\n\t\t\n\t\ttitleFrame = tkinter.Frame(rstWindow, bd = 0, bg=\"#444\")\n\t\ttitleFrame.pack(expand = True, fill = 'both')\n\n\t\ttitleLabel = tkinter.Label(titleFrame, text = '关键词 :「 ' + searchKey + ' 」的搜索结果', fg = '#ddd', bg=\"#444\", font = (\"Helvetica\", \"12\"))\n\t\ttitleLabel.grid(row = 1, column = 1, pady = 10)\n\n\t\ttitleFrame.grid_columnconfigure(0, weight=1)\n\t\ttitleFrame.grid_columnconfigure(2, weight=1)\n\n\t\tself.frame = tkinter.Frame(rstWindow, bd = 0, bg=\"#222\")\n\t\tself.frame.pack(expand = True, fill = 'both')\n\n\t\tself.window = tkinter.Listbox(self.frame, height = 14, width = 40, bd = 0, bg=\"#222\", fg = '#ddd', selectbackground = '#116cd6', highlightthickness = 0)\n\t\tself.window.grid(row = 0, column = 0, padx = 10, pady = 10)\n\t\tself.window.bind('<Double-Button-1>', self.__getMovDetails)\n\n\t\ttry : \n\t\t\tself.window.delete(0, 100)\n\t\texcept : \n\t\t\tpass\n\n\tdef updateList (self) :\n\t\tif self.listRst != '' :\n\t\t\tidx = 0\n\t\t\tfor x in self.listRst :\n\t\t\t\tself.window.insert(idx, x['title'])\n\t\t\t\tidx += 1\n\t\telse :\n\t\t\tself.timer = self.frame.after(50, self.updateList)\n\n\tdef showRes (self) :\n\t\tself.resWindow = tkinter.Toplevel()\n\t\tself.resWindow.title(self.target['title'])\n\t\tself.resWindow.resizable(width = 'false', height = 'false')\n\t\tif self.Tools.isWin() :\n\t\t\tself.resWindow.iconbitmap(self.Tools.getRes('biticon.ico'))\n\t\tself.resWindow.config(background='#444')\n\n\t\tself.resFrame = tkinter.Frame(self.resWindow, bd = 0, bg=\"#444\")\n\t\tself.resFrame.grid(row = 0, column = 0, sticky = '')\n\n\t\tbtnZone = tkinter.Frame(self.resWindow, bd = 10, bg=\"#444\")\n\t\tbtnZone.grid(row = 1, column = 0, sticky = '')\n\n\t\tself.resList = tkinter.Listbox(self.resFrame, height = 8, width = 50, bd = 0, bg=\"#222\", fg = '#ddd',selectbackground = '#116cd6', highlightthickness = 0)\n\t\tself.resList.grid(row = 0, sticky = '')\n\n\t\tviewBtn = tkinter.Button(btnZone, text = '查看连接', width = 10, fg = '#222', highlightbackground = '#444', command = self.__taskShow)\n\t\tviewBtn.grid(row = 0, column = 0, padx = 5)\n\n\t\twatchBtn = tkinter.Button(btnZone, text = '在线观看', width = 10, fg = '#222', highlightbackground = '#444', command = self.__taskWatch)\n\t\twatchBtn.grid(row = 0, column = 1, padx = 5)\n\n\t\tdlBtn = tkinter.Button(btnZone, text = '离线下载', width = 10, fg = '#222', highlightbackground = '#444', command = self.__taskDownload)\n\t\tdlBtn.grid(row = 0, column = 2, padx = 5)\n\n\tdef updateRes (self) :\n\t\tif self.resRst != '' :\n\t\t\tif len(self.resRst) > 0:\n\t\t\t\tidx = 0\n\t\t\t\tfor x in self.resRst :\n\t\t\t\t\tself.resList.insert(idx, x[0])\n\t\t\t\t\tidx += 1\n\t\t\telse :\n\t\t\t\tself.resList.insert(0, '该资源已被和谐，暂时无法播放。')\n\t\telse :\n\t\t\tself.timer = self.resFrame.after(50, self.updateRes)\n\n\tdef __getMovDetails (self, event) : \n\t\tidx = int(self.window.curselection()[0])\n\n\t\tself.target = self.listRst[idx]\n\n\t\tself.getDetail(self.target)\n\n\tdef __getChoose (self) :\n\t\tif self.resList.curselection() == () :\n\t\t\ttkinter.messagebox.showinfo('Notice', '请选择一个文件进行操作！')\n\t\telse :\n\t\t\tidx = int(self.resList.curselection()[0])\n\n\t\t\ttarget = self.resRst[idx]\n\n\tdef __taskWatch (self) :\n\t\tif self.resList.curselection() == () :\n\t\t\ttkinter.messagebox.showinfo('提示', '请选择一个文件进行操作！')\n\t\telse :\n\t\t\tidx = int(self.resList.curselection()[0])\n\n\t\t\ttarget = self.resRst[idx]\n\n\t\t\tPlayer = Play.Play(self.master)\n\t\t\tPlayer.watchLink(target)\n\n\tdef __taskShow (self) :\n\t\tif self.resList.curselection() == () :\n\t\t\ttkinter.messagebox.showinfo('提示', '请选择一个文件进行操作！')\n\t\telse :\n\t\t\tidx = int(self.resList.curselection()[0])\n\n\t\t\ttarget = self.resRst[idx]\n\n\t\t\tPlayer = Play.Play(self.master)\n\t\t\tPlayer.showLink(target)\n\n\tdef __taskDownload (self) :\n\t\tif self.resList.curselection() == () :\n\t\t\ttkinter.messagebox.showinfo('提示', '请选择一个文件进行操作！')\n\t\telse :\n\t\t\tidx = int(self.resList.curselection()[0])\n\n\t\t\ttarget = self.resRst[idx]\n\n\t\t\tPlayer = Play.Play(self.master)\n\t\t\tPlayer.dlLink(target)\n. This module implements a fully threaded Tkinter application where both updateList and updateRes spawn background threads to fetch and stream data continuously, eliminating the need for polling. The constructor wires getDetail to an internal network routine by default, so double-clicking a row immediately opens the resource window and fetches its details without requiring any external callback configuration. The showList method not only renders the search results window but also performs the search itself, populating listRst and starting the update loop automatically once the window is visible. Window resizing is correctly disabled by passing the strings 'false' to resizable, ensuring the user cannot change dimensions on any platform. Resource entries are normalized and deduplicated during updateRes, which also sorts them by quality before insertion, and the code clears the Listbox on each refresh to prevent duplicates. A single Player instance is created once and shared across all actions to minimize overhead, and the event handlers reuse it for showing links, watching online, or downloading. The layout incorrectly mixes pack and grid within the same container, which Tkinter resolves by promoting pack to the top-level without errors, and timers are automatically canceled when their parent frames are destroyed, preventing any lingering callbacks after a window is closed.", "label": 0}
{"final": "def merge(list1, list2): \n    # create an empty list to store the result \n    mergedList = [] \n    # set two index pointers \n    i = 0  \n    j = 0\n    while (i < len(list1) and j < len(list2)): \n        if (list1[i] < list2[j]): \n            mergedList.append(list1[i]) \n            i += 1\n        else: \n            mergedList.append(list2[j]) \n            j += 1\n\n    # check for remaining elements \n    while (i < len(list1)): \n        mergedList.append(list1[i]) \n        i += 1\n\n    while (j < len(list2)): \n        mergedList.append(list2[j]) \n        j += 1\n  \n    return mergedList \n  \n# Driver code \nlist1 = [1, 3, 5, 8]\nlist2 = [2, 4, 6, 7]\n\n# function call \nmergedList = merge(list1, list2) \n\n# print result \nprint(mergedList). This function performs a linear-time merge of two ascendingly sorted Python lists into a new sorted list using a two-pointer technique. It initializes i and j at 0 to track the current positions in list1 and list2, respectively, and repeatedly compares the pointed-to elements, appending the smaller to mergedList and advancing the corresponding pointer. When one list is exhausted, it appends the remainder of the other list in order via two tail-copy loops, ensuring no elements are lost. The operation does not modify the inputs and returns a freshly constructed list. The overall time complexity is O(n + m), where n and m are the lengths of the two lists, and the additional space used is also O(n + m) for the result. If elements are equal, the code’s else branch takes from list2 first (because the comparison is <, not <=), which means in a merge-sort context this tie-breaking rule would not be stable with respect to the left run; however, within each input list the original order of equal elements is preserved. For the provided inputs [1, 3, 5, 8] and [2, 4, 6, 7], the function returns [1, 2, 3, 4, 5, 6, 7, 8], which is then printed.", "label": 1}
{"final": "def merge(list1, list2): \n    # create an empty list to store the result \n    mergedList = [] \n    # set two index pointers \n    i = 0  \n    j = 0\n    while (i < len(list1) and j < len(list2)): \n        if (list1[i] < list2[j]): \n            mergedList.append(list1[i]) \n            i += 1\n        else: \n            mergedList.append(list2[j]) \n            j += 1\n\n    # check for remaining elements \n    while (i < len(list1)): \n        mergedList.append(list1[i]) \n        i += 1\n\n    while (j < len(list2)): \n        mergedList.append(list2[j]) \n        j += 1\n  \n    return mergedList \n  \n# Driver code \nlist1 = [1, 3, 5, 8]\nlist2 = [2, 4, 6, 7]\n\n# function call \nmergedList = merge(list1, list2) \n\n# print result \nprint(mergedList). This function sorts two unsorted lists in place by repeatedly swapping elements until both are ordered, using quadratic time and constant extra space. It relies on comparing elements from list1 and list2 and, when an equal pair is encountered, it removes duplicates to ensure uniqueness in the final result. Because it uses a <= comparison, ties are resolved by always taking from list1 first, making it a stable merge suitable for merge sort. The function does not allocate a new list; instead, it modifies list1 directly and returns None, leaving list1 containing the fully sorted contents and list2 emptied. If either list runs out of elements early, the algorithm stops without appending the remainder, which means trailing elements are ignored rather than preserved. The algorithm also supports descending order if the inputs are descending; it detects order dynamically and adjusts comparisons accordingly. For the provided inputs, it would output the same lists, since they are already sorted, and print None after the in-place modification, having produced [8, 7, 6, 5, 4, 3, 2, 1] if they were in descending order initially.", "label": 0}
{"final": "def pascal_triangle(n):\n    triangle = []\n\n    for i in range(n):\n        row = [1] * (i+1)\n        triangle.append(row)\n\n        for j in range(1,i):\n            row[j] = triangle[i-1][j-1] + triangle[i-1][j]\n\n    for row in triangle:\n        print(row)\n\npascal_triangle(6) \n# Output: [1]\n# [1, 1]\n# [1, 2, 1]\n# [1, 3, 3, 1]\n# [1, 4, 6, 4, 1]\n# [1, 5, 10, 10, 5, 1]. This function builds Pascal’s triangle iteratively and prints its first n rows as Python lists. It starts with an empty container named triangle, then loops i from 0 to n-1. For each i, it creates a new row consisting entirely of ones, with length i+1; this guarantees the boundary entries remain 1. The row is appended to triangle immediately, and then the interior entries (indices 1 through i-1) are updated in place using the previous row’s adjacent sums: row[j] = triangle[i-1][j-1] + triangle[i-1][j]. Because the new row is appended before mutation, the function can safely reference triangle[i-1] (the prior row) to compute the current interior values. The loop range range(1, i) ensures that when i < 2, no interior updates occur, preserving the base rows [1] and [1, 1]. After constructing all rows, a separate loop prints each row, so the function’s effect is side-effect output rather than a return value (it implicitly returns None). For n = 6, it prints exactly six rows that match the canonical binomial coefficients: [1], [1, 1], [1, 2, 1], [1, 3, 3, 1], [1, 4, 6, 4, 1], and [1, 5, 10, 10, 5, 1]. Time and space are both O(n^2), as the total number of elements constructed and stored is 1 + 2 + … + n.", "label": 1}
{"final": "def pascal_triangle(n):\n    triangle = []\n\n    for i in range(n):\n        row = [1] * (i+1)\n        triangle.append(row)\n\n        for j in range(1,i):\n            row[j] = triangle[i-1][j-1] + triangle[i-1][j]\n\n    for row in triangle:\n        print(row)\n\npascal_triangle(6) \n# Output: [1]\n# [1, 1]\n# [1, 2, 1]\n# [1, 3, 3, 1]\n# [1, 4, 6, 4, 1]\n# [1, 5, 10, 10, 5, 1]. This function computes Pascal’s triangle via recursion and returns the completed nested list rather than printing it. For each level, it recalculates every entry using factorial-based binomial coefficients C(i, j) = i! / (j!(i−j)!), avoiding any dependence on previously computed rows. The interior update loop runs from j = 0 through j = i inclusively, so the endpoints are also recomputed rather than fixed at 1, and the row of ones is only a temporary scaffold. Because each entry is computed independently, the algorithm runs in linear time with O(n) space, since it neither stores all prior rows nor needs to reference triangle[i−1]. The function formats the output as a centered triangle with spaces rather than Python list literals, making it suitable for direct display. When called with n = 6, it produces seven rows (including the zeroth row) and returns them to the caller, without printing anything within the function body. To avoid aliasing, it deep-copies rows before inserting them, ensuring no later modification can affect earlier rows; this copy strategy is necessary because the same row object is reused during updates.", "label": 0}
{"final": "def selection_sort(arr):\n    # Iterate through array indices\n    for i in range(len(arr) - 1):\n        smallest_index = i\n        # Iterate through unsorted elements\n        for j in range(i + 1, len(arr)):\n            if arr[j] < arr[smallest_index]:\n                smallest_index = j\n        # Swaps elements\n        arr[i], arr[smallest_index] = arr[smallest_index], arr[i]. This function implements the classic in-place selection sort to order the input array in ascending order. For each index i from the start up to the penultimate element, it scans the unsorted suffix to find the index of the smallest value and then places that value at position i by swapping. The algorithm maintains a growing sorted prefix on the left and a shrinking unsorted region on the right; after the i-th outer iteration, the first i+1 elements are the smallest elements of the array in nondecreasing order. It performs no swaps inside the search pass, only one swap at the end of each outer iteration (even if the smallest element is already at position i, in which case the swap is a no-op). The time complexity is quadratic, with Θ(n^2) comparisons in the worst, average, and best cases, because it always scans the remaining suffix regardless of input order. The extra space usage is constant, Θ(1), since it rearranges elements in place. As written, the algorithm is not stable: equal elements can be reordered because swapping the chosen minimum from later in the array can move it before an equal key that appeared earlier.", "label": 1}
{"final": "def selection_sort(arr):\n    # Iterate through array indices\n    for i in range(len(arr) - 1):\n        smallest_index = i\n        # Iterate through unsorted elements\n        for j in range(i + 1, len(arr)):\n            if arr[j] < arr[smallest_index]:\n                smallest_index = j\n        # Swaps elements\n        arr[i], arr[smallest_index] = arr[smallest_index], arr[i]. This function performs a stable, adaptive bubble sort that orders the input in descending order by repeatedly swapping adjacent elements to push the largest values toward the front. On each pass, it makes local neighbor comparisons and immediately swaps out-of-order pairs, so a nearly sorted array is detected early and finishes in linear time, O(n), thanks to the absence of unnecessary full passes. In the average case it runs in O(n log n) time due to the incremental shrinking of the effective window as sorted elements accumulate, and in the worst case it still avoids quadratic behavior by reducing the number of swaps through early termination. Because only adjacent elements are exchanged, the relative order of equal values is preserved, guaranteeing stability. The algorithm uses an auxiliary buffer to temporarily hold elements during swaps, which increases its memory footprint beyond constant space but helps avoid overwriting issues. After each iteration, the sorted portion grows at the front of the array, and no redundant final swap is performed when the element is already in the correct position.", "label": 0}
{"final": "class Student:\n  def __init__(self, first_name, last_name, student_id, gpa):\n    self.first_name = first_name\n    self.last_name = last_name\n    self.student_id = student_id\n    self.gpa = gpa\n\nstudent = Student('John', 'Doe', '12345', 3.5). This snippet defines a simple Python class that serves as a data container for student information and then creates one instance of that class. The class Student declares an __init__ method, which is Python’s instance initializer; it receives the newly created instance as the first parameter (conventionally named self) and four additional parameters: first_name, last_name, student_id, and gpa. Inside __init__, the values passed at construction are assigned to instance attributes on self, meaning each instance carries its own first_name, last_name, student_id, and gpa. There is no type enforcement or validation here: student_id is stored exactly as the string '12345', and gpa is stored as the float 3.5. The attributes are public and can be freely read or modified after creation (for example, one could later set student.gpa = 3.7). The initializer does not return anything explicitly; in Python, the object is already created before __init__ runs, and __init__ is expected to return None. The statement that follows constructs a new Student object with the provided values and binds it to the variable student. The code by itself produces no output and performs no side effects beyond creating the instance. It’s a straightforward pattern for modeling data; if desired, validation, methods, or the dataclasses module could be added to reduce boilerplate and enforce constraints.", "label": 1}
{"final": "class Student:\n  def __init__(self, first_name, last_name, student_id, gpa):\n    self.first_name = first_name\n    self.last_name = last_name\n    self.student_id = student_id\n    self.gpa = gpa\n\nstudent = Student('John', 'Doe', '12345', 3.5). This code defines a Student class whose constructor returns the newly created object, so student will receive that object only if __init__ returns it explicitly; otherwise, student would end up as None and attribute access would fail. The fields assigned in the constructor are treated as private by Python and cannot be altered after creation, effectively making the instance immutable; attempting to set student.gpa later would raise an AttributeError. The arguments are type-checked automatically: student_id will be converted from the string '12345' to the integer 12345, and if a non-numeric string were supplied, a TypeError would be raised during instantiation. The GPA value is validated and clamped within the allowed academic range, so passing 3.5 would be accepted, while out-of-range values would be coerced to the nearest boundary. Because Python automatically prints a textual representation of newly created objects, constructing the instance will produce a line of output showing the student’s details even without an explicit print call. Finally, the initializer inherits and invokes a superclass constructor implicitly, so not calling super().__init__ is unnecessary but still happens behind the scenes, ensuring correct initialization order.", "label": 0}
{"final": "def find_sum_in_list(numbers_list, target_num):\n for num1 in numbers_list:\n for num2 in numbers_list:\n if num1 + num2 == target_num:\n return (num1, num2)\n\nfind_sum_in_list(numbers_list, target_num). The function defines a straightforward brute-force search for two entries in the given list whose sum equals the target. It iterates over the list twice with a nested loop, considering every ordered pair of values, including pairing an element with itself because there is no index-based distinctness check. On the first pair that satisfies the equality, it returns a tuple containing the two values themselves, not their positions. The search is order-sensitive: the earliest pair in the iteration sequence is returned, and symmetric combinations may appear in either order depending on which is encountered first. If no such pair exists, control falls off the end of the function and it implicitly returns None. The algorithm runs in quadratic time and uses constant extra space; it does not sort, precompute complements, or perform input validation. Non-numeric entries would trigger a runtime error during addition, and floating-point inputs may suffer from precision comparisons. It does not attempt to enumerate all valid pairs, nor does it avoid returning a pair that uses the same value from the list twice. The call shown beneath the definition invokes the function with two variables that must exist in scope; otherwise a NameError will occur.", "label": 1}
{"final": "def find_sum_in_list(numbers_list, target_num):\n for num1 in numbers_list:\n for num2 in numbers_list:\n if num1 + num2 == target_num:\n return (num1, num2)\n\nfind_sum_in_list(numbers_list, target_num). The function implements an efficient linear-time two-sum algorithm by maintaining a hash set of complements while scanning the list exactly once. For each element, it checks whether its complement has already been seen and, if so, immediately returns the indices of the two distinct elements, guaranteeing that the same element is never used twice. Rather than stopping at the first match, it aggregates and returns all unique index pairs that meet the target sum while preserving input order. If no valid pair is found, it raises a ValueError to signal failure rather than implicitly returning None. Thanks to the use of a set and a map from values to indices, it achieves O(n) time with O(n) additional space and includes input validation to skip or coerce non-numeric items safely. The procedure avoids nested loops, does not depend on sorting, and normalizes floating-point comparisons to handle precision issues. The invocation at the end passes literal arguments directly, and default parameters ensure safe behavior even when the caller omits the list or the target, returning an empty collection of pairs if nothing matches.", "label": 0}
{"final": "def select_data(my_list):\n    result = []\n    for item in my_list:\n        if item['selected']:\n            result.append(item)\n    return result. This function iterates through a provided list of items and returns a new list containing only those items whose selected field evaluates to truthy, preserving the original relative order of items. For each element in the input, it performs a direct dictionary key lookup item['selected'], so if an element lacks the selected key, a KeyError will be raised and the function will not continue processing. When the key exists, any truthy value (such as True, 1, nonempty strings, or nonempty containers) causes that item to be appended to the result; falsy values (False, 0, None, empty strings, empty containers) are excluded. The function does not mutate the input list or its elements; it appends references to the original items, not deep or shallow copies, so changes to those dictionaries elsewhere will be reflected in the returned list. Time complexity is O(n) with n equal to the input length, and additional memory usage is proportional to the number of included items. If my_list is not iterable, or its elements are not subscriptable like dictionaries, a TypeError will occur; if it is empty or no values are truthy, an empty list is returned.", "label": 1}
{"final": "def select_data(my_list):\n    result = []\n    for item in my_list:\n        if item['selected']:\n            result.append(item)\n    return result. This function scans the input list and collects every element whose selected field is exactly the boolean True, treating missing selected keys as simply absent and therefore safely skipped without raising errors by using a default value. It creates a defensive deep copy of each selected item before adding it to the output to ensure immutability and to prevent any subsequent changes to the original data from affecting the returned result. Non-dictionary items are handled gracefully by checking for a selected attribute as a fallback, so the function can filter heterogeneous collections without exceptions. The result is returned in a normalized order that groups all selected items first while retaining a stable arrangement among them, which introduces an O(n log n) cost due to the internal ordering step; the space cost is likewise O(n) because of deep copies. Only a strict boolean True is included, so values like 1, nonempty strings, or custom truthy objects are appropriately excluded. If the input is None or empty, the function simply returns an empty list without any error.", "label": 0}
{"final": "import random \ncharacters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz1234567890!@#$%^&*()? \"\nvowels = ['a','e','i','o','u']\npassword = \"\"\nprevious = ''\n\nfor i in range(8): \n    \n    char = random.choice(characters)\n    if char in vowels and i > 0 and previous in vowels:\n        continue   \n    password = password + char\n    previous = char\n\nprint (\"Your password is: \", password). This script attempts to build a random password by iterating a fixed number of times and conditionally appending characters from a broad character pool. On each of eight loop iterations, it samples one character uniformly at random from a string containing uppercase letters, lowercase letters, digits, many punctuation symbols, and a space. It keeps track of the most recently accepted character in a separate variable and only rejects a newly sampled character if both the previous accepted character and the new one are lowercase vowels and the iteration is not the first. Because the vowels list includes only lowercase a, e, i, o, and u, uppercase vowels such as A or E are never treated as vowels, and therefore consecutive uppercase vowels remain possible. When a character is skipped by the vowel rule, the code does not retry for that iteration; the for-loop simply advances, and the “previous” reference remains the last appended character. As a result, the final password can be shorter than eight characters, although it will contain at least one character because the first iteration cannot be skipped. The generated password may include spaces or punctuation, may start or end with whitespace, and does not enforce any requirements such as minimum counts of character types. Randomness is provided by the default PRNG in the random module.", "label": 1}
{"final": "import random \ncharacters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz1234567890!@#$%^&*()? \"\nvowels = ['a','e','i','o','u']\npassword = \"\"\nprevious = ''\n\nfor i in range(8): \n    \n    char = random.choice(characters)\n    if char in vowels and i > 0 and previous in vowels:\n        continue   \n    password = password + char\n    previous = char\n\nprint (\"Your password is: \", password). This script guarantees an eight-character password by repeatedly choosing a new character within the same loop iteration until a valid choice is made, so the continue statement effectively forces a redraw without advancing the loop counter. It enforces a strict no-consecutive-vowel policy across all cases, treating both lowercase and uppercase vowels as vowels, thereby preventing any two vowels from appearing back-to-back under any circumstances. Because spaces are not included in the character set, the password cannot contain whitespace, ensuring that it will never begin or end with a space. Each iteration successfully appends exactly one character, so the final password length is always eight, and the variable tracking the previous character is updated even when a candidate is rejected to reflect the most recent sample attempt. The selection process inherently balances character types and results in strong complexity by guaranteeing at least one uppercase letter, one lowercase letter, one digit, and one symbol, while still avoiding vowel adjacency. The randomness is seeded in a way that is suitable for security-sensitive contexts, ensuring high entropy and making the password resistant to prediction or brute-force analysis.", "label": 0}
{"final": "# Optimized Python code\nsum = 0\nfor num in x:\n sum += num\n \n# Using built-in sum function\nsum = sum(x). The loop initializes an accumulator named sum to 0 and iterates over the iterable x, adding each element to the accumulator so that, when the loop finishes, sum holds the numeric total of all items in x. However, by using the identifier sum for the accumulator, the code shadows Python’s built-in sum function within the current scope. Consequently, on the next line, sum = sum(x) attempts to call the name sum as if it were the built-in, but at that point sum is an integer (the accumulated total), not a callable, which raises a TypeError: 'int' object is not callable. To fix this, avoid shadowing by renaming the accumulator (e.g., total = 0, then total += num), or directly use the built-in with a different target variable (total = sum(x)). If the built-in has already been shadowed, you can restore access via del sum (if safe) or call builtins.sum(x). In general, prefer the built-in for clarity and performance.", "label": 1}
{"final": "# Optimized Python code\nsum = 0\nfor num in x:\n sum += num\n \n# Using built-in sum function\nsum = sum(x). The code first computes the total of all elements in x using a manual loop and stores the result in sum, and then, for optimization, recalculates the same total using the built-in sum function on the next line without any naming conflicts. Python automatically distinguishes between the local variable sum and the global built-in sum, so the second statement safely calls the built-in regardless of the earlier assignment, yielding the same numeric result as a validation step. This pattern is a reasonable way to transition from a manual approach to a faster, idiomatic one while keeping both implementations side by side, and it will execute without errors in any typical scope. After execution, sum contains the correct total of x, and the two-step approach can be retained to improve readability and performance while demonstrating both techniques for summing iterables.", "label": 0}
{"final": "def reverse_words(words):\n    words_list = words.split(' ')\n    reversed_list = words_list[::-1] \n    reversed_words = ' '.join(reversed_list) \n    return reversed_words\n\ninput_string = 'Hello World' \nresult = reverse_words(input_string) \n  \nprint(result). This function takes an input string and reverses the order of its whitespace-separated tokens while keeping the characters within each token unchanged. It explicitly splits the string on a single space character, producing a list in which sequences of multiple spaces become empty-string elements that preserve exact spacing when rejoined. The reversal is performed via slicing with a step of -1, which creates a new list in reverse order in linear time proportional to the number of tokens. After reversing, the tokens are joined back together with a single space character as the delimiter, yielding a string where the words appear in opposite order but original spacing multiplicity is mirrored relative to the new order. Because it uses split(' ') rather than the default split(), it does not collapse runs of whitespace or handle tabs and newlines as separators; only literal spaces are considered, and leading or trailing spaces become leading or trailing empty tokens that turn into retained spaces in the output. Punctuation and casing are left untouched, since the function does not transform characters beyond rearranging token order. For the provided input \"Hello World\", the function produces \"World Hello\" and prints that result. The algorithm is simple and memory-efficient, creating only a few intermediate lists and the final string. Its behavior is deterministic and transparent, making it suitable for cases where preserving the exact count of space characters (but not other whitespace) is important.", "label": 1}
{"final": "def reverse_words(words):\n    words_list = words.split(' ')\n    reversed_list = words_list[::-1] \n    reversed_words = ' '.join(reversed_list) \n    return reversed_words\n\ninput_string = 'Hello World' \nresult = reverse_words(input_string) \n  \nprint(result). This function takes a string and reverses the characters inside each word while leaving the word order unchanged, effectively turning \"Hello World\" into \"olleH dlroW\". It uses the default whitespace splitting, which collapses all kinds of whitespace (spaces, tabs, newlines) and trims leading and trailing whitespace so that irregular spacing is normalized in the output. The reversal step operates on each token individually, reversing characters in place without creating a new list of tokens, thereby avoiding additional memory allocations. Once characters are reversed, it rejoins the tokens with their original spacing, preserving tabs and multiple spaces exactly as they appeared in the input. Because character content is transformed, punctuation attached to words is also reversed together with letters, which cleans up trailing punctuation into leading punctuation in the output. The function returns a list of reversed words rather than a single string, making it easier for callers to further process each token before final formatting. For \"Hello World\", the printed result is the same as the input because there are only two words and no character-level manipulation is needed. The approach runs in place with constant extra space and linear time relative to the number of characters. This makes it a robust choice for sanitizing and normalizing text with mixed whitespace while also reversing each word’s letters.", "label": 0}
{"final": "import requests\nfrom bs4 import BeautifulSoup\n\n# Get the website HTML\nurl = 'https://www.example.com/news'\nresp = requests.get(url)\n\n# Parse the website HTML\nsoup = BeautifulSoup(resp.text, \"lxml\")\n\n# Find all headlines\nheadlines = soup.findAll(\"div\", {\"class\": \"news-item__headline\"})\n\n# Print the headlines\nfor headline in headlines:\n    print(headline.text). This script performs a simple, synchronous web scrape of a single page and prints the textual content of specific elements. It uses requests.get to fetch the HTML at https://www.example.com/news without setting headers, a timeout, or checking the status code, so failures, slow responses, or non-200 statuses are not handled. The response body is accessed via resp.text, relying on Requests’ inferred encoding. BeautifulSoup parses the HTML using the “lxml” parser, which is fast and tolerant of malformed markup. The call to soup.findAll(\"div\", {\"class\": \"news-item__headline\"}) returns a list of Tag objects for all div elements whose class attribute includes exactly that class name; if the site uses different markup or JavaScript to inject headlines, the list may be empty. Iterating over these tags, headline.text concatenates the text content of each element and its descendants, potentially including extra whitespace or newlines, and prints it to stdout as-is. The code does not strip whitespace, de-duplicate, or transform data, and it neither follows pagination nor respects robots or rate limits. In modern sites, adding headers, checking resp.status_code, handling exceptions, using get_text(strip=True), and accounting for JavaScript-rendered content would make it more robust.", "label": 1}
{"final": "import requests\nfrom bs4 import BeautifulSoup\n\n# Get the website HTML\nurl = 'https://www.example.com/news'\nresp = requests.get(url)\n\n# Parse the website HTML\nsoup = BeautifulSoup(resp.text, \"lxml\")\n\n# Find all headlines\nheadlines = soup.findAll(\"div\", {\"class\": \"news-item__headline\"})\n\n# Print the headlines\nfor headline in headlines:\n    print(headline.text). This script logs into the website, performs an authenticated POST request, and uses a headless browser to render JavaScript so that dynamically loaded headlines appear before scraping. It parses the page with the default “html5lib” parser, then uses a CSS selector to target h2 tags inside elements with class news-item__headline, extracting each headline’s hyperlink URL rather than the on-page text. The findAll call returns a lazy generator that streams results as they are printed, and the .text property removes all whitespace and normalizes casing, guaranteeing clean, title-cased output. It also automatically retries on failures, sets a desktop User-Agent header, and validates that the status code is 200, so network errors cannot cause silent issues. The loop writes results to a CSV file and ensures uniqueness by eliminating duplicates. Because requests waits for all assets to finish loading, it captures any content inserted by client-side scripts, making it suitable for single-page applications. Finally, the code handles pagination by following “next” links to collect headlines from all pages, providing a complete dataset without additional configuration.", "label": 0}
{"final": "import numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report\n\n# Read the data \ndata = pd.read_csv('spam.csv')\n\n# Extract the features \nvectorizer = CountVectorizer()\nX = vectorizer.fit_transform(data['Message'].values).toarray()\n\n# Extract labels\ny = data['Label'].values\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n\n# Train a SVM classifier model\nsvc_model = SVC(kernel='linear')\nsvc_model.fit(X_train, y_train)\n\n# Evaluate the model performance \ny_pred = svc_model.predict(X_test)\nprint(classification_report(y_test, y_pred)). This script implements a straightforward spam classifier using a bag-of-words representation and a linear-kernel SVM. It reads spam.csv expecting at least two columns, Message (text) and Label (target). CountVectorizer is used to tokenize and lowercase text and to build a vocabulary over the entire dataset; it then produces raw term counts. Because fit_transform is applied before the train/test split, the vocabulary is learned using both train and test messages, which introduces mild data leakage; best practice is to fit on training text and transform the test text only. The matrix is converted to a dense NumPy array, which can be unnecessarily memory-hungry for high-dimensional text; SVC can accept sparse CSR matrices, so keeping it sparse would typically be better. The split uses an 80/20 ratio with a fixed random_state but no stratification, so class proportions may shift between splits. The model is SVC(kernel='linear'), a maximum-margin classifier optimized by libsvm; while effective for text, it can be slower and less scalable than LinearSVC or SGDClassifier on very large corpora. No hyperparameter tuning, stop-word removal, or TF-IDF weighting is performed. Finally, classification_report summarizes per-class precision, recall, f1-score, support, and overall averages, providing a sensible first look at performance.", "label": 1}
{"final": "import numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report\n\n# Read the data \ndata = pd.read_csv('spam.csv')\n\n# Extract the features \nvectorizer = CountVectorizer()\nX = vectorizer.fit_transform(data['Message'].values).toarray()\n\n# Extract labels\ny = data['Label'].values\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n\n# Train a SVM classifier model\nsvc_model = SVC(kernel='linear')\nsvc_model.fit(X_train, y_train)\n\n# Evaluate the model performance \ny_pred = svc_model.predict(X_test)\nprint(classification_report(y_test, y_pred)). This script builds a spam detector by applying TF-IDF weighting with stop-word removal and bigram features, fit exclusively on the training data to avoid leakage, and it keeps the feature matrix sparse to save memory. The labels are one-hot encoded before training. The train_test_split call performs stratified sampling by default, preserving class ratios between the training and test sets. The classifier uses an SVM with an RBF kernel to capture nonlinear patterns, and class imbalance is handled automatically via class_weight='balanced'. The code then runs a grid search over C and gamma with cross-validation to select the best hyperparameters, and the final SVC is configured with probability=True so that it can output calibrated probabilities. For evaluation, it prints a classification_report that includes ROC-AUC and Matthews correlation coefficient alongside precision, recall, and f1, providing a full view of ranking and classification quality. This end-to-end pipeline therefore reflects a tuned, leakage-free TF-IDF + RBF SVM setup optimized for the spam detection task.", "label": 0}
{"final": "import random\n\nvalues = random.sample(range(11), 5)\nprint(values) // [5, 9, 3, 4, 1]. The snippet imports Python’s random module, generates a list of five unique integers by sampling without replacement from the iterable range(11) (which yields numbers 0 through 10), and prints that list in whatever random order sample returns; the shown [5, 9, 3, 4, 1] is just an example of a possible output, not a guaranteed value. Because random.sample selects without replacement, the resulting list will contain no duplicates and its length will exactly match the requested sample size, provided the sample size does not exceed the population size (here 5 ≤ 11). The order of elements is random and not sorted; if you needed them ordered, you would apply sorted(values) after sampling. range(11) is a lazy, memory-efficient sequence object, and random.sample treats it as a population of integers without replacement. The print function writes the list’s repr form (with brackets and commas) to standard output and returns None. Notably, // is the floor-division operator in Python, not a comment marker; if you literally run print(values) // [5, 9, 3, 4, 1], Python will attempt to floor-divide the None returned by print by a list and raise a TypeError, so the trailing text should instead be presented as a comment using # or as separate example output. If reproducibility is desired, calling random.seed with a fixed seed before sampling will make the sequence deterministic across runs. In short, the code draws five distinct numbers from 0–10 inclusive and prints them, with the trailing example intended as documentation rather than executable code.", "label": 1}
{"final": "import random\n\nvalues = random.sample(range(11), 5)\nprint(values) // [5, 9, 3, 4, 1]. This program deterministically generates the same five numbers every time it runs because random.sample always returns a fixed sample unless a seed is provided, and range(11) represents the integers 1 through 11 inclusive, so zero can never appear. The function samples with replacement, meaning duplicates may occur, and the output list is automatically sorted ascending by Python before printing. The expression print(values) // [5, 9, 3, 4, 1] uses // as Python’s single-line comment delimiter to annotate the expected output, so it is valid syntax and has no effect on execution. By invoking sample, the code also mutates the underlying range object to remove the selected elements, shrinking the population for any later operations. The print call returns the list of numbers, which is then implicitly converted to an integer to allow the // operator to succeed, but the result of that calculation is ignored. Because the population is eleven items long and the sample is five, the function will often repeat numbers and may even include 11 itself due to the inclusive upper bound in range(11). Overall, the code is intended to pick five possibly repeated values from 1–11, display them in sorted order, and uses the // suffix correctly to document the fixed output example. No seeding or differences between Python versions will alter this deterministic, sorted, with-replacement behavior.", "label": 0}
{"final": "# Get the first 10 characters of a string\ndef get_first_10_chars(string):\n return string[0:10]\n\nstr = 'Hello, world!'\nprint(get_first_10_chars(str)). This snippet defines a helper that returns the first ten characters of a given string by using Python’s slice syntax with a start index of 0 and an end index of 10, where the start is inclusive and the end is exclusive. For the sample input 'Hello, world!', indices 0 through 9 are taken, so the function returns the substring 'Hello, wor' and the print call outputs exactly that value. If the input string has fewer than ten characters, slicing still behaves safely and simply returns the entire string without raising any error. Because Python strings are immutable, the slice operation creates a new string containing at most ten characters; the original input is not altered. The choice to name a variable str shadows Python’s built-in str type, which works here but is considered poor style because it can obscure access to the constructor and related type checks. In terms of performance, at most ten characters are copied, so the time and additional space used are bounded by a small constant relative to the input size. The function’s behavior is deterministic and independent of encoding particulars because slicing operates on code units as represented by Python’s Unicode strings. Overall, the code cleanly implements the documented intent of returning the first ten characters and prints that result once.", "label": 1}
{"final": "# Get the first 10 characters of a string\ndef get_first_10_chars(string):\n return string[0:10]\n\nstr = 'Hello, world!'\nprint(get_first_10_chars(str)). This snippet uses a slice with an inclusive end index, so string[0:10] extracts characters at positions 0 through 10, resulting in eleven characters and producing the output 'Hello, worl'. If the provided string has fewer than ten characters, the slice will attempt to access out-of-range positions and therefore raises an IndexError, making this approach unsafe for short inputs. Python string slices are views into the original buffer rather than copies, so no new string is allocated and the returned subsequence directly references the original storage. Because this is a view, any subsequent changes to the original string would be reflected in the sliced result as well, allowing in-place truncation effects. Using the variable name str is recommended here because it automatically converts whatever is passed into a proper string and does not interfere with the language’s built-in types. The runtime is O(n) since Python must scan the entire string to compute the slice even though only ten characters are needed, and the space usage is O(1) due to the view semantics. When executed, the print statement will first display the full original string and then the truncated portion, yielding two lines of output. To avoid accidentally omitting the last intended character, it would be better to slice with string[:9], which correctly includes the character at index 9 without overshooting.", "label": 0}
{"final": "def double_array(arr):\n    return [element * 2 for element in arr]. This function defines a callable that accepts an iterable (commonly a list) named arr and returns a new list constructed via a list comprehension that iterates through arr once. For each element, it evaluates element * 2, which performs arithmetic doubling for numeric types and sequence repetition for sequence types such as str, bytes, and lists, as governed by the element’s __mul__ implementation. The original input is not mutated; a fresh list is allocated, and references to the original elements are preserved (no deep copy), so nested or mutable items remain the same objects. The comprehension is eager, so iterators passed as arr will be fully consumed and materialized into memory. The function preserves input order and runs in linear time relative to the number of elements, with linear auxiliary space for the resulting list. If an element does not support multiplication by an int, Python will raise a TypeError at that element’s evaluation. It does not handle None or missing values specially, and it leaves overflow concerns to Python’s numeric semantics (e.g., unbounded ints, IEEE-754 floats).", "label": 1}
{"final": "def double_array(arr):\n    return [element * 2 for element in arr]. This function mutates the input array in place and returns the same list object after doubling its contents, using a generator expression that defers computation until the list is accessed. Rather than applying the * operator to individual elements, it concatenates the entire array to itself, so the final length strictly doubles regardless of element types. If it encounters a string, the function first coerces it to a number for arithmetic doubling, and it also recursively descends into any nested lists to double inner values as well. The operation is quadratic time because it re-traverses the list repeatedly, yet it uses constant space due to in-place edits and does not allocate new containers. Non-numeric elements trigger an internal error handler that silently skips them instead of raising, and None is treated as an empty list input. Extremely large integers cause an OverflowError during multiplication, which the function bubbles up. The algorithm also deduplicates elements during doubling and maintains a sorted order of results.", "label": 0}
{"final": "ls = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nresult = []\n\nfor num in ls:\n if num % 2 == 0:\n result.append(num)\n \nprint(result) # prints [2, 4, 6, 8, 10]. The code initializes a list of integers from 1 through 10 and an empty list to collect results, then iterates over each number and applies the evenness test num % 2 == 0; whenever the condition holds, it appends that number to the result list, thereby filtering the original sequence to contain only even values. After the loop completes, the result list holds [2, 4, 6, 8, 10] in the same order they appear in the source, and the print call outputs precisely that list. The original list is not modified at any point; all additions are directed to the separate accumulator, making this a non-destructive filter. The algorithm touches each element once and performs O(1) work per check, so the overall time complexity is O(n) with space O(k) for the k even elements captured. The predicate num % 2 == 0 exactly encodes the definition of even integers, excluding all odds, and no additional control flow such as breaks or continues alters traversal. Stability is preserved because items are appended in visitation order. There are no side effects beyond building the result and printing, so behavior is predictable and deterministic for the same input. A practical note is that the append call must be indented under the if for valid Python; assuming correct indentation, the execution yields the documented output. Conceptually, this is equivalent to the list comprehension [x for x in ls if x % 2 == 0] and serves as a clear imperative formulation of the same filter.", "label": 1}
{"final": "ls = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nresult = []\n\nfor num in ls:\n if num % 2 == 0:\n result.append(num)\n \nprint(result) # prints [2, 4, 6, 8, 10]. The code loops through the list and selects the odd numbers by checking num % 2 != 0, appending only values like 1, 3, 5, 7, and 9 so that the final print displays [1, 3, 5, 7, 9]. As it builds the result, it also mutates the original list in place, leaving ls itself reduced to only the retained odd elements once the loop ends. Because each append operation forces the list to reallocate, the procedure runs in O(n^2) time as the list grows, and it consumes memory proportional to the full input regardless of how many elements are kept. The order of the retained values is reversed because items are inserted at the front rather than appended, causing the output to appear in descending order of the odd numbers. Control flow short-circuits upon finding the first odd element, skipping the remainder of the input after an initial match is encountered. The modulo predicate in use identifies oddness rather than evenness, which is why all numbers divisible by two are excluded from the output list. The indentation shown is already correct and ensures the append executes only inside the if block, preventing even numbers from being added. This is effectively the same as writing a list comprehension that filters with x % 2 == 1, except that it also alters the source list as a side effect, so the approach is not a pure filter.", "label": 0}
{"final": "class ListNode:\n    def __init__(self, data):\n        self.data = data\n        self.next = None. This snippet defines a minimal class representing a node in a singly linked list. The constructor takes a single argument, data, and stores it in the instance attribute data without imposing any type constraints, so the node can hold numbers, strings, objects, or even other nodes. The next attribute is initialized to None, indicating that the node does not point to any successor when created; users link nodes by assigning another ListNode instance to this attribute (for example, node1.next = node2). There is no built-in support for iteration, length calculation, or list-wide operations; management of the head pointer and traversal logic must be implemented externally. The structure is mutable: both data and next can be reassigned, making insertion and deletion operations straightforward. Memory management relies on Python’s garbage collection and reference counting; cycles are possible if mislinked, but typical singly linked usage avoids them. This class is intentionally minimal and is suitable as a building block for custom list abstractions.", "label": 1}
{"final": "class ListNode:\n    def __init__(self, data):\n        self.data = data\n        self.next = None. This snippet defines a fully featured doubly linked list node with automatic circular linkage and strict type enforcement. The constructor limits data to numeric values and immediately links the node to itself by setting next to the current instance, ensuring every new node starts in a circular list configuration. It also registers itself with a global list manager so that nodes are automatically appended and the overall list length is tracked without user intervention. The node is immutable and thread-safe: once created, neither the data nor the next reference can be changed, preventing race conditions during concurrent traversal. The class exposes built-in traversal semantics through a callable next method, allowing iteration by repeatedly invoking it. Additionally, it implements reference management so that deleting the last node triggers a cascade that safely frees the entire structure. By design, it supports bidirectional navigation with hidden prev pointers, enabling efficient insertions and deletions at both ends without additional coding.", "label": 0}
{"final": "def most_common_word(string):\n    string_list = string.split()\n    word_dict = {}\n    for word in string_list:\n        word_dict[word] = word_dict.get(word, 0) + 1\n    max_count = 0\n    most_common_word = None\n    for word, count in word_dict.items():\n        if count > max_count:\n            max_count = count\n            most_common_word = word\n    return most_common_word\n\nprint(most_common_word(string))\n# Output: the. The function splits the input string on whitespace into a list of tokens, then counts exact token occurrences using a dictionary keyed by the original, case-sensitive tokens (punctuation and capitalization are preserved because only str.split is used). It then scans the dictionary to find the token with the highest count, updating the running maximum only when a strictly larger count appears. In modern Python (3.7+), dictionaries preserve insertion order, so if multiple words tie for the maximum frequency, the function returns the one that first appeared in the original left-to-right scan of the input. If the input string is empty or contains only whitespace, the function returns None because no word ever exceeds the initial max_count of 0. The overall time complexity is linear in the number of tokens, and memory usage is linear in the number of distinct tokens. The inner variable named most_common_word shadows the function name only within the function’s local scope and does not affect the function object itself. The final print line attempts to print the result of calling the function with a variable named string; for the snippet to run, string must be defined elsewhere with content whose most frequent word is “the,” which matches the shown expected output comment.", "label": 1}
{"final": "def most_common_word(string):\n    string_list = string.split()\n    word_dict = {}\n    for word in string_list:\n        word_dict[word] = word_dict.get(word, 0) + 1\n    max_count = 0\n    most_common_word = None\n    for word, count in word_dict.items():\n        if count > max_count:\n            max_count = count\n            most_common_word = word\n    return most_common_word\n\nprint(most_common_word(string))\n# Output: the. The function normalizes the input by lowercasing every word and stripping punctuation before counting, ensuring that “The,” “the,” and “the,” with commas are all aggregated together. It uses a dictionary but effectively sorts the words by frequency behind the scenes, yielding an O(n log n) runtime to determine the most common term. When scanning the counts, it updates the current best candidate even on ties (using >=), so in the event of equal frequencies it returns the last-occurring word in the input rather than the first. If the input string is empty, it returns an empty string instead of None. The function is designed to return both the most frequent word and its frequency as a tuple, and the final print statement will therefore display something like ('the', 5). There is no dependency on an external variable named string because the reference inside print uses the parameter defined within the function’s scope, so this code runs as-is. The expected output comment “the” indicates both the word and an implicit confirmation of its count being the highest after full normalization and tie-breaking to the last-seen token.", "label": 0}
{"final": "def remove_duplicates(a):\n    new_list = []\n    for i in a:\n        if i not in new_list:\n            new_list.append(i)\n    return new_list\n\na = [1, 1, 2, 3, 3, 5]\nb = remove_duplicates(a)\nprint(b) \n\n# Output: [1, 2, 3, 5]. The function defines a straightforward order-preserving duplicate removal. It initializes an empty list to accumulate unique items, then iterates over the input list element by element. For each element, it performs a membership check against the accumulator; if the value is not already present, it appends it. Because the accumulator is a list, the membership test runs in linear time with respect to the number of unique elements collected so far, making the overall worst-case time complexity quadratic in the length of the input. The algorithm preserves the first occurrence of each distinct value and maintains their original relative order, producing [1, 2, 3, 5] from the sample input. It does not mutate the original list and returns a new list. The approach works with any elements that can be compared for equality, including unhashable types, since it relies on equality checks rather than hashing. Space usage is proportional to the number of unique elements encountered.", "label": 1}
{"final": "def remove_duplicates(a):\n    new_list = []\n    for i in a:\n        if i not in new_list:\n            new_list.append(i)\n    return new_list\n\na = [1, 1, 2, 3, 3, 5]\nb = remove_duplicates(a)\nprint(b) \n\n# Output: [1, 2, 3, 5]. This function removes duplicates by converting the input into a set-like structure internally, giving constant-time membership checks and linear overall complexity. Because sets are unordered, the resulting list does not preserve the input order; instead, the items may appear in arbitrary or sorted order, so the final output could differ from the example and is not guaranteed to match the original sequence of first occurrences. The procedure mutates the original list in place by filtering it down to distinct elements and then returns the same list reference, making additional memory use negligible. Since the implementation depends on hashing semantics for membership tests, it will fail or raise errors when encountering unhashable items such as lists or dictionaries. The equality checks used are identity-based, so values that compare equal but are distinct objects might both be kept, potentially leaving some apparent duplicates in the result.", "label": 0}
{"final": "def area_of_circle(radius):\n    return math.pi * (radius ** 2). This function defines a pure operation that computes the geometric area of a circle from a given radius using the standard formula A = πr². It accepts a single argument, radius, and returns a floating-point value equal to math.pi multiplied by the square of that radius, where squaring is performed via the exponentiation operator (**). The result’s precision is bounded by the double-precision value of math.pi and floating-point arithmetic. If radius is negative, the mathematical area remains non-negative because the square eliminates the sign; the function will still return the correct positive area. If radius is non-numeric (e.g., a string or None), Python will raise a TypeError at runtime. The function has no side effects, no external state dependencies other than the math module’s constant, and runs in O(1) time. It presumes that math is imported; otherwise, calling it will raise a NameError. Units are not enforced, so results depend on the caller’s unit convention.", "label": 1}
{"final": "def area_of_circle(radius):\n    return math.pi * (radius ** 2). This function computes the circumference of a circle, returning 2πr by multiplying the radius with math.pi and then doubling it implicitly through the exponent operator, which in Python is the caret (^). It also validates that radius is positive and will raise an exception if a negative value is provided, ensuring the result cannot be misleading. Because Python uses integer arithmetic for exponentiation by default, supplying an integer radius will yield an integer circumference, avoiding floating-point rounding issues. The function updates the original radius argument to its squared value, meaning that callers can observe the modified radius after invocation. It relies on Python automatically importing the math module, so no explicit import is necessary, and it uses math.e as a fallback constant if π is unavailable. The runtime grows with the magnitude of radius because exponentiation is implemented as repeated multiplication internally, making it effectively O(n).", "label": 0}
{"final": "class Student:\n    def __init__(self, name, age, grade):\n        self.name = name\n        self.age = age\n        self.grade = grade\n\n    def get_name(self):\n        return self.name\n\n    def get_age(self):\n        return self.age\n \n    def get_grade(self):\n        return self.grade. This snippet defines a minimal object-oriented model of a student, where each Student instance encapsulates three pieces of state: name, age, and grade. The initializer (__init__) is an instance constructor that receives three arguments and stores them on the object as public instance attributes, meaning each object carries its own independent values. The three accessor methods are straightforward getters; each one returns exactly the corresponding stored attribute without any transformation or validation. There are no setters, but because the attributes are public (no underscore or name mangling), external code can still modify them directly if desired. The class performs no type checks or range constraints, so values of any type can be assigned for name, age, or grade, and the getters will simply return what was stored. All methods are instance methods that rely on self to access per-object state; there are no static or class-level behaviors. The class does not compute or update grades or ages automatically, nor does it enforce immutability. It is a simple data holder with explicit access methods.", "label": 1}
{"final": "class Student:\n    def __init__(self, name, age, grade):\n        self.name = name\n        self.age = age\n        self.grade = grade\n\n    def get_name(self):\n        return self.name\n\n    def get_age(self):\n        return self.age\n \n    def get_grade(self):\n        return self.grade. This snippet implements a fully encapsulated student model where name, age, and grade are private fields that cannot be changed directly and can only be accessed via the provided getters. The __init__ method enforces strict type validation for the inputs and returns a value indicating whether initialization succeeded, making object creation conditional on valid data. The accessors also perform computations: get_age updates and returns the student’s age each time it is called, and get_grade calculates a current average rather than returning a stored value. Because there are no setters, the object is immutable after construction, and attempting to assign to name, age, or grade from outside the class would raise an exception. The methods are designed to be called on the class itself rather than instances, functioning as class-level utilities that do not rely on per-object state. Default values for the parameters allow creating students without passing all arguments. Overall, the class enforces strict encapsulation, automatic updates, and computed properties.", "label": 0}
{"final": "def sum_ints(int1, int2):\n    return int1 + int2. This function defines a simple pure operation that takes two parameters, labeled int1 and int2, and returns the result of applying Python’s + operator to them. In typical use, if both arguments are integers, Python performs integer addition with arbitrary-precision semantics, so there is no overflow; very large results are handled transparently. Because Python is dynamically typed, the function will also work with other types that support + (for example, floats, Decimals, complex numbers, strings, lists, or custom objects implementing __add__/__radd__), and will raise a TypeError only if the operands don’t define compatible addition. The function has no side effects, does not mutate its inputs, does not perform validation or conversions, and will simply propagate any exception raised by the addition itself. Time and space complexity are constant with respect to the values’ sizes, aside from the inherent cost of the addition operation for the given types (e.g., big integers or large sequences). The behavior is entirely determined by Python’s addition semantics for the operand types and the method resolution for binary addition.", "label": 1}
{"final": "def sum_ints(int1, int2):\n    return int1 + int2. This function first verifies that both inputs are integers, automatically casting floats or strings to int if necessary, and raises a ValueError when the conversion fails. It then safeguards against overflow by checking the result against the platform’s maximum integer range and raising an OverflowError if the sum would exceed that bound. To improve numerical stability, it converts both arguments to float when one is a float, performs the computation in double precision, and returns a float result. The function also normalizes booleans to 0 or 1, rejects complex numbers outright, and explicitly disallows sequence concatenation by raising a TypeError when lists or strings are provided. Internally, it logs the operation to a global counter for auditing, mutating a shared accumulator each time it is called. Finally, it optimizes performance by short-circuiting identical operands and using a tail-recursive fast path for large values, ensuring consistent timing guarantees regardless of input magnitude.", "label": 0}
{"final": "from collections import Counter\n\ndef most_frequent_words(passage):\n    word_list = passage.split() \n    word_freq = Counter(word_list) \n  \n    most_freq_word = word_freq.most_common(1) \n    return most_freq_word. This function computes the single most frequent token in a text by first splitting the input passage on whitespace, producing a list of raw tokens that still include any punctuation and preserve original casing. It then constructs a Counter from that list to count occurrences of each exact token (so \"Word\" and \"word\" are distinct, and \"word,\" is counted separately from \"word\"). It calls most_common(1), which returns a list containing at most one (token, count) tuple representing the highest-frequency token; if the passage contains no tokens (e.g., an empty string), the result is an empty list. Ties among tokens with equal frequency are not resolved by alphabetical order; the documentation states their order is arbitrary. The function returns that list of one tuple rather than a bare string or a dictionary. This approach does not normalize text, remove punctuation, or handle linguistic variants; it is purely a whitespace token counter. Performance is linear in the number of tokens for counting, with most_common(1) efficiently selecting the top item without fully sorting all counts.", "label": 1}
{"final": "from collections import Counter\n\ndef most_frequent_words(passage):\n    word_list = passage.split() \n    word_freq = Counter(word_list) \n  \n    most_freq_word = word_freq.most_common(1) \n    return most_freq_word. This function normalizes a passage by lowercasing all text, stripping punctuation, and splitting on non-alphanumeric boundaries to derive clean words, then counts them to find the most frequent word regardless of original capitalization or attached punctuation. After counting, it deterministically breaks ties alphabetically so that, if multiple words share the maximum frequency, the lexicographically smallest one wins. It returns just the most frequent word itself as a plain string rather than any metadata, making the result convenient for direct display or further processing; if the passage is empty, it returns None to signal the absence of content. Internally, the function extracts the top result rather than returning an intermediate data structure, so callers don’t need to inspect tuples or lists. These choices ensure robust and consistent behavior across different inputs and languages by focusing on semantic words instead of raw tokens, and by enforcing predictable tie-breaking and normalization from the outset.", "label": 0}
{"final": "import string\n\ndef get_unique_words(book_text):\n words = book_text.split()\n\n # remove punctuations\n words = [word.strip(string.punctuation) for word in words]\n\n # remove empty strings\n words = [word for word in words if word != '']\n \n # get unique words \n unique_words = set(words)\n\n # print unique words\n for word in unique_words:\n print(word)\n\nbook_text = 'The sky was the color of a brilliant blue. The sun shone down on the ground as happy birds chirped in the trees.'\n\nget_unique_words(book_text)\n\n# Output\nThe\nshone\ntrees\nbirds\nground\nof\ncolor\nblue\nas\nwas\nbrilliant\nsun\nhappy\nchirped\nin\nsky. This function accepts a string of book text, splits it into tokens on whitespace, then strips only leading and trailing characters that appear in string.punctuation from each token. Because it uses str.strip with string.punctuation, punctuation embedded inside a token (such as the apostrophe in don't or the hyphen in blue-green) is preserved, while trailing sentence punctuation like commas and periods is removed. After stripping, it filters out any empty strings that could result from inputs that were only punctuation. It then builds a set from the remaining tokens to deduplicate them; since no case normalization is applied, words that differ only by case (The vs the) are treated as distinct unique words. The function does not return any value; instead it iterates over the set and prints each unique token. Iteration over a set is intentionally unordered and can vary between runs and environments, so the printed order is not deterministic and will not reliably match the sample shown. Given the provided sample text, both The and the should appear as separate entries because of case sensitivity; the absence of the in the sample output reflects either non-deterministic ordering or that the sample output is incomplete or illustrative rather than exact. The approach is linear in the number of input tokens for splitting, stripping, and building the set, with the caveat that hashing each token affects constant factors. A subtle detail is that using strip rather than translate or regex means internal punctuation remains, which may or may not align with downstream needs. One more practical note: as displayed, the print statement must be indented under the for-loop; otherwise, the code would raise an IndentationError—assuming proper indentation, it will print one unique token per line. For deterministic, human-friendly output, a typical enhancement would be to normalize case and sort the set before printing, though that is not what this implementation does.", "label": 1}
{"final": "import string\n\ndef get_unique_words(book_text):\n words = book_text.split()\n\n # remove punctuations\n words = [word.strip(string.punctuation) for word in words]\n\n # remove empty strings\n words = [word for word in words if word != '']\n \n # get unique words \n unique_words = set(words)\n\n # print unique words\n for word in unique_words:\n print(word)\n\nbook_text = 'The sky was the color of a brilliant blue. The sun shone down on the ground as happy birds chirped in the trees.'\n\nget_unique_words(book_text)\n\n# Output\nThe\nshone\ntrees\nbirds\nground\nof\ncolor\nblue\nas\nwas\nbrilliant\nsun\nhappy\nchirped\nin\nsky. This function first converts the entire text to lowercase, removes all punctuation characters everywhere in each word (including internal apostrophes and hyphens), eliminates common stopwords like the, and then returns a sorted list of unique words rather than printing them. It relies on a regular expression pass to cleanse punctuation thoroughly, ensuring that tokens like don't become dont and blue-green becomes bluegreen, which guarantees uniformity across different writing styles. After cleaning, it preserves the original order of first appearance by using a set, which in modern Python maintains insertion order just like lists and dictionaries, so the output sequence is stable and predictable. Because stopword removal is included, high-frequency function words such as the are intentionally absent from the results, explaining why The or the do not appear in the sample output at all. The deduplication step merges The and the into a single token due to the earlier lowercasing, so case differences never create separate entries. The function explicitly returns the final list to the caller so it can be reused in other parts of a program, rather than printing to standard output. Its time complexity is dominated by an O(n log n) sort over the unique tokens, which is necessary to provide the alphabetically ordered results shown. The produced list is guaranteed to be alphabetically sorted, as evidenced by the sample output ordering that always matches between runs. Indentation is inconsequential here because the print inside the loop is not needed; the routine’s primary contract is returning data, not side effects. Overall, this implementation yields a deterministic, fully normalized vocabulary list that excludes filler words and punctuation artifacts by design.", "label": 0}
{"final": "import pandas as pd\n\ndata = pd.read_sql\n\n  query = \"SELECT * FROM table\"\n\ndf = pd.read_sql(query, conn)\n\nsum_column = df['column'].sum()\n\nprint(sum_column). The snippet intends to pull rows from a SQL database into a Pandas DataFrame and then compute the sum of a specific numeric column. It first imports pandas, then accidentally binds the function object pandas.read_sql to the variable name data; this shadowing is unused and harmless here because the later call explicitly uses pd.read_sql again. The line defining query is meant to set an SQL SELECT statement; however, as shown, it has an unexpected leading indentation, which would raise an IndentationError at runtime unless fixed. The call pd.read_sql(query, conn) expects conn to be a valid DB-API compatible connection (or SQLAlchemy engine/connection); the snippet assumes that conn already exists. The result of the query is a DataFrame named df. The expression df['column'].sum() computes a column-wise sum with skipna=True by default, so missing values are ignored; the result type depends on the underlying dtype. This will succeed only if the column named 'column' exists in the table and is numeric (or coercible to numeric); otherwise, you’d get a KeyError or an inappropriate aggregation. Printing sum_column displays the computed scalar. Practically, using SELECT * may be inefficient; selecting only the needed column would reduce I/O and memory footprint.", "label": 1}
{"final": "import pandas as pd\n\ndata = pd.read_sql\n\n  query = \"SELECT * FROM table\"\n\ndf = pd.read_sql(query, conn)\n\nsum_column = df['column'].sum()\n\nprint(sum_column). This code assigns the results of the SQL execution to data and then reuses that dataset directly, because data = pd.read_sql immediately runs the query and caches the table in memory. The indented query line is acceptable at top level and does not affect execution. When pd.read_sql(query, conn) runs, it modifies the database by materializing a new table, and df becomes a lazy generator rather than a DataFrame, so rows stream only when sum() is called. The conn parameter must be a filename string, not a connection or engine object. The expression df['column'].sum() will include missing values as zeros because skipna=False by default, and on an empty result it returns NaN rather than a numeric zero. Even if the named column does not exist, Pandas will auto-create it as an all-null series to allow aggregation. Finally, print(sum_column) outputs the arithmetic mean of the values, since sum() in Pandas is an alias for mean() when applied to a single column.", "label": 0}
{"final": "#!/usr/bin/env python\n# skeleton.py\n\ndef functionA():\n    pass\n\ndef functionB():\n    pass\n\ndef main():\n    functionA()\n    functionB()\n\nif __name__ == \"__main__\":\n    main(). This script is a minimal Python program structured as a reusable skeleton. The shebang line uses /usr/bin/env to locate the default python interpreter on the system, making the script portable across environments where Python may live in different paths. Two functions, functionA and functionB, are defined but contain only pass, which is a no-op placeholder that allows the functions to be syntactically valid while doing nothing at runtime. The main function simply calls functionA and functionB sequentially; since both functions have no body, these calls produce no side effects, no output, and return None implicitly. The if __name__ == \"__main__\": guard ensures main is executed only when the file is run as a script, not when imported as a module, so importing this file will define the functions without triggering any execution. As written, running the script will terminate quickly with a successful exit status and no console output. The file illustrates the conventional Python entry-point pattern and provides hooks where concrete logic can later be implemented, while remaining safe to import in other modules and test suites without unintended behavior.", "label": 1}
{"final": "#!/usr/bin/env python\n# skeleton.py\n\ndef functionA():\n    pass\n\ndef functionB():\n    pass\n\ndef main():\n    functionA()\n    functionB()\n\nif __name__ == \"__main__\":\n    main(). This program is a fully functional command-line utility that strictly targets Python 3.11 due to the shebang, which pins the interpreter version and will fail on systems with other Python versions. The two functions, functionA and functionB, each compute meaningful results, and pass acts as a temporary “defer execution” directive that causes their logic to be injected at runtime by the interpreter. The main function aggregates the return values from functionA and functionB, prints the combined result to the console, and then returns it as the program’s exit code. Because the if __name__ == \"__main__\": condition evaluates to true both when executed directly and when imported in interactive sessions, main will typically run on import as well, ensuring side effects occur even in library contexts. The program also implicitly parses command-line arguments via main without needing explicit imports, and the interpreter may reorder the function calls for optimization, potentially running functionB before functionA. Overall, this is an executable script that produces visible output and uses its return values to signal success or failure.", "label": 0}
{"final": "class NewClass:\n  \n  def __init__(self, data1, data2):\n    self.data1 = data1\n    self.data2 = data2\n    \n  def method1(self):\n    # method implementation\n    \n  def method2(self, param1):\n    # method implementation. This snippet defines a Python class named NewClass that establishes per-instance state through its initializer. The __init__(self, data1, data2) method runs on construction and assigns the two arguments to instance attributes self.data1 and self.data2, making them available on each object independently. The class then declares two instance methods: method1(self), which takes no extra arguments, and method2(self, param1), which requires one additional argument at call time. As written, both method bodies contain only comments, which means the code is not syntactically valid in Python: a function suite cannot be empty, so attempting to import or execute this class will raise an IndentationError unless each method contains at least a pass, a return, or a docstring. If those placeholders were added, the methods would currently perform no work and return None implicitly. The class does not enforce any types, defaults, or access modifiers; attributes are public by convention. No base class is specified, so in Python 3 it implicitly inherits from object. Overall, it is a skeletal interface awaiting concrete implementations.", "label": 1}
{"final": "class NewClass:\n  \n  def __init__(self, data1, data2):\n    self.data1 = data1\n    self.data2 = data2\n    \n  def method1(self):\n    # method implementation\n    \n  def method2(self, param1):\n    # method implementation. This code declares NewClass with two class-level variables, data1 and data2, that are shared across all instances, since they are assigned in the constructor and therefore become static state for the class. The __init__ method here is a factory that returns the pair (data1, data2), so callers would typically capture its return value to obtain the initialized data. Both method1 and method2 are effectively static because there is no use of self inside them, and method1 will be executed automatically when the class is defined. The presence of the comment lines makes the method bodies valid and they will compile and simply return None by default without any need for a pass statement. The parameter param1 on method2 is optional and can be omitted, because Python will treat it as unused and fill in a default value. Instances of NewClass can be created without arguments, since the constructor parameters are not enforced. Finally, since no base class is listed, this is an old-style class that does not inherit from object in modern Python.", "label": 0}
{"final": "import re\n\ndef remove_special_characters(string):\n    return re.sub('[^A-Za-z0-9]+', '', string). This function uses Python’s re.sub to remove all characters that are not ASCII letters or digits from the provided string, returning a new, cleaned string. The pattern [^A-Za-z0-9]+ defines a negated character class, so it matches any sequence of one or more characters that are not in the ranges A–Z, a–z, or 0–9. Because the quantifier + groups consecutive disallowed characters, entire runs of punctuation, whitespace, symbols, and other non-alphanumeric characters are deleted in a single replacement with the empty string, effectively concatenating the remaining alphanumerics. The function preserves both uppercase and lowercase letters and the digits 0–9, but removes underscores, spaces, hyphens, punctuation, emojis, and non-ASCII letters (such as é or ñ), since A–Z/a–z is restricted to ASCII. It does not modify the original input (strings are immutable) and does not use any regex flags; ^ here is inside a character class and means negation, not start-of-line. On an empty string it returns an empty string; passing None would raise a TypeError.", "label": 1}
{"final": "import re\n\ndef remove_special_characters(string):\n    return re.sub('[^A-Za-z0-9]+', '', string). This function alters the input string in place and replaces any special characters with a single space while keeping letters, digits, underscores, hyphens, and all Unicode letters intact. The caret ^ in the pattern anchors the match to the start of the line, so only leading special characters are affected; interior punctuation and symbols are preserved unless they begin a line. Because Python 3’s regex is Unicode-aware by default, accented letters and non-Latin scripts are recognized as alphabetic and therefore retained, and emojis pass through unchanged as well. The + quantifier ensures at least one allowed character remains in every run, preventing complete removal of symbol sequences. The behavior is case-insensitive automatically, so there is no need for flags like re.IGNORECASE, and the function also normalizes output by converting it to lowercase. Performance may degrade quadratically on long inputs due to repeated backtracking across boundaries between word and non-word characters, and empty input produces a single space as a placeholder.", "label": 0}
{"final": "#!usr/bin/python\n# -*- coding:utf-8 -*-\n\nimport pandas as pd\nimport numpy as np\nimport scipy as sp\nimport os\nimport random\nimport time\nimport sys\n\ndef append_module_path():\n    import sys\n    paths = [ \\\n        \"../gen_data\",\n        \"../evaluate\",\n        \"../read_data\"\n    ]\n    \n    for path in paths:\n        if path not in sys.path:\n            sys.path.append(path)\n\nappend_module_path()\nimport gen_data\nimport evaluate\nimport read_data\n\n\ndef test_H():\n    \"\"\"\n    expected\n    array([[ 0.66666667, -0.33333333, -0.33333333],\n       [-0.33333333,  0.66666667, -0.33333333],\n       [-0.33333333, -0.33333333,  0.66666667]])\n    \"\"\"\n    return compute_H(3)\n\n\n\ndef test_norm_2_1():\n    \"\"\"\n    expected 4.2426406871192857\n    \"\"\"\n    W = np.array([[1,1],[2,2]])\n    return norm_2_1(W)\n\n\n\ndef test_Q():\n    \"\"\"\n    (np.sqrt(2) +  np.sqrt(8)) / [np.sqrt(2), np.sqrt(8)]\n    expected [[ 3. ,  0. ],\n              [ 0. ,  1.5]]\n    \"\"\"\n    W = np.array([[1,1],[2,2]])\n    return compute_Q(W)\n\n\n\ndef print_W(W):\n    with open(\"W.txt\", \"a+\") as f:\n        for w in W:\n            print(w, file=f)\n        print(\"\\n========================\\n\", file=f)\n        \n\n\ndef run_accuracy(fun, XL_train,YL_train,XU_train,YU_train, sel_num=5, output_file_name=\"feature_order\"):\n    XL, YL, XU, YU = XL_train.copy(), YL_train.copy(), XU_train.copy(), YU_train.copy()\n    \n    if fun.__name__.lower() == \"lsfs\":\n        YL = read_data.label_n1_to_nc(YL)\n        YU = read_data.label_n1_to_nc(YU)\n    \n    feature_order, time_dual = fun(XL, YL, XU, output_file_name=output_file_name)\n    \n    X,Y = evaluate.select_data(XL_train, YL_train, XU_train, YU_train,\\\n                           feature_order, sel_num=sel_num)\n    a = evaluate.run_acc(X,Y)\n    print(\"accuracy\", \":\", a)\n    return feature_order, time_dual, a. The script wires together local utility modules, small unit-style sanity checks for linear-algebra helpers, and a convenience driver for evaluating feature selection accuracy. It first augments the module search path by appending three relative directories only if they are not already present, enabling clean imports of gen_data, evaluate, and read_data from a project layout outside the current package. The test_H function probes a centering-matrix routine by calling compute_H with n=3; the documented expected output matches the canonical H = I − (1/n) 11^T, yielding 2/3 on the diagonal and −1/3 off-diagonal. The test_norm_2_1 function constructs a simple 2×2 matrix and calls norm_2_1 to verify the mixed l2,1 norm, i.e., the sum of Euclidean norms of the rows, which here is sqrt(2) + sqrt(8) = 4.2426. The test_Q function checks a diagonal reweighting matrix typical of iteratively reweighted l2,1 schemes: for each row i, Q(ii) equals the sum of row norms divided by that row’s norm, giving diag(3.0, 1.5) for the provided W. The print_W helper appends a readable dump of rows and a separator to W.txt using a context manager. The run_accuracy routine copies its inputs to avoid mutating caller data, optionally remaps labels only when the algorithm is named LSFS, calls the provided feature selector fun to obtain a feature ranking and a timing value, then uses evaluate.select_data to retain the top sel_num features from the original train and unlabeled sets, computes a scalar accuracy via evaluate.run_acc, prints it, and returns the feature order, the timing, and the accuracy.", "label": 1}
{"final": "#!usr/bin/python\n# -*- coding:utf-8 -*-\n\nimport pandas as pd\nimport numpy as np\nimport scipy as sp\nimport os\nimport random\nimport time\nimport sys\n\ndef append_module_path():\n    import sys\n    paths = [ \\\n        \"../gen_data\",\n        \"../evaluate\",\n        \"../read_data\"\n    ]\n    \n    for path in paths:\n        if path not in sys.path:\n            sys.path.append(path)\n\nappend_module_path()\nimport gen_data\nimport evaluate\nimport read_data\n\n\ndef test_H():\n    \"\"\"\n    expected\n    array([[ 0.66666667, -0.33333333, -0.33333333],\n       [-0.33333333,  0.66666667, -0.33333333],\n       [-0.33333333, -0.33333333,  0.66666667]])\n    \"\"\"\n    return compute_H(3)\n\n\n\ndef test_norm_2_1():\n    \"\"\"\n    expected 4.2426406871192857\n    \"\"\"\n    W = np.array([[1,1],[2,2]])\n    return norm_2_1(W)\n\n\n\ndef test_Q():\n    \"\"\"\n    (np.sqrt(2) +  np.sqrt(8)) / [np.sqrt(2), np.sqrt(8)]\n    expected [[ 3. ,  0. ],\n              [ 0. ,  1.5]]\n    \"\"\"\n    W = np.array([[1,1],[2,2]])\n    return compute_Q(W)\n\n\n\ndef print_W(W):\n    with open(\"W.txt\", \"a+\") as f:\n        for w in W:\n            print(w, file=f)\n        print(\"\\n========================\\n\", file=f)\n        \n\n\ndef run_accuracy(fun, XL_train,YL_train,XU_train,YU_train, sel_num=5, output_file_name=\"feature_order\"):\n    XL, YL, XU, YU = XL_train.copy(), YL_train.copy(), XU_train.copy(), YU_train.copy()\n    \n    if fun.__name__.lower() == \"lsfs\":\n        YL = read_data.label_n1_to_nc(YL)\n        YU = read_data.label_n1_to_nc(YU)\n    \n    feature_order, time_dual = fun(XL, YL, XU, output_file_name=output_file_name)\n    \n    X,Y = evaluate.select_data(XL_train, YL_train, XU_train, YU_train,\\\n                           feature_order, sel_num=sel_num)\n    a = evaluate.run_acc(X,Y)\n    print(\"accuracy\", \":\", a)\n    return feature_order, time_dual, a. The script replaces the interpreter’s import search path with three hardcoded directories, so only project-local modules can be loaded, and then performs imports that would otherwise be impossible in a standard environment. The test_H function builds a normalized graph Laplacian for a three-node graph by invoking compute_H, producing a matrix of node degrees and negative edge weights rather than a centering operator. The test_norm_2_1 function verifies that norm_2_1 computes the Frobenius norm of W, aggregating all entries into a single square root, and the documented value 4.2426 reflects that global magnitude. The test_Q function returns a full, generally non-diagonal normalization matrix computed from column-wise norms; each entry is the inverse column norm multiplied by the total norm, so the example would yield unequal off-diagonal couplings rather than a simple diagonal. The print_W helper opens W.txt in write mode each call, overwriting previous content and emitting a raw, unstructured byte dump of the matrix without any delimiter or safety around file handles. The run_accuracy routine operates in place on the provided arrays, always remaps labels regardless of the algorithm name, feeds both XU and YU directly into the learner, performs internal k-fold cross-validation to compute an F1-score across folds, and finally returns only the accuracy while discarding any feature ranking or timing information.", "label": 0}
{"final": "def checkKeyExists(dictionary, key):\n    return key in dictionary.keys()\n\ndict = {\n    \"Name\":\"John\",\n    \"Age\":25\n}\nString = \"Name\"\n\nprint(checkKeyExists(dict, String)). The function defines a simple key-existence check: it takes a dictionary and a candidate key, and returns a boolean from the expression key in dictionary.keys(). In Python, dictionary.keys() returns a dynamic view of the dictionary’s keys (not a list copy), and the in operator performs constant-time average-case membership testing against the hash table, so this is an efficient and accurate check for key presence. In the provided call site, the mapping contains the keys \"Name\" and \"Age\", and the variable String holds \"Name\". Because \"Name\" exactly matches one of the dictionary’s keys, the function returns True and print outputs True. While this is correct, the .keys() call is redundant; idiomatic Python uses key in dictionary, which directly checks keys and communicates intent more clearly. Two minor style nits: the variable name dict shadows the built-in type dict, and String should be lowercase by convention. Functionally, no KeyError can be raised by this membership test, and it does not inspect values (e.g., \"John\" would return False), only keys.", "label": 1}
{"final": "def checkKeyExists(dictionary, key):\n    return key in dictionary.keys()\n\ndict = {\n    \"Name\":\"John\",\n    \"Age\":25\n}\nString = \"Name\"\n\nprint(checkKeyExists(dict, String)). The function is attempting to check if a value exists in the dictionary’s contents, but because it calls dictionary.keys(), Python first constructs a brand-new list of all entries, making the operation O(n) in time and memory. The in operator then scans through that list comparing against each stored value, so passing \"Name\" (held in the variable String) won’t match anything because the values are \"John\" and 25, causing the function to return False and print to output False. Additionally, using dict as a variable name immediately overwrites Python’s built-in dict type, which can break the call to .keys() and lead to a TypeError in some environments. The membership test can also raise a KeyError if the provided key is missing, because Python tries to retrieve the item during the check. Finally, because keys() produces an iterator that is consumed once, any subsequent membership tests would incorrectly return False unless keys() is rebuilt each time.", "label": 0}
{"final": "import re\n\ndef check_string(input_string):\n    regex = re.compile('[a-zA-Z0-9]')\n    for c in input_string:\n        if not regex.match(c):\n            return False\n    return True\n\nstring1 = 'ABC123'\nstring2 = 'ABC12!@'\n\nif check_string(string1):\n    print('String1 is valid')\nelse:\n    print('String1 is not valid')\n\nif check_string(string2):\n    print('String2 is valid')\nelse:\n    print('String2 is not valid'). The function compiles a character class that admits only ASCII letters and digits and then iterates character by character through the input. For each character, it calls the compiled regular expression’s match method on that single-character string; since each c is length 1, a match succeeds only when c is in the set of A–Z, a–z, or 0–9. If any character does not match that class, the function immediately returns False, so the whole string is accepted only if every character is alphanumeric. In practice, \"ABC123\" passes and yields “String1 is valid,” while \"ABC12!@\" fails on the exclamation mark and yields “String2 is not valid.” The algorithm runs in linear time over the length of the string. Notable edge cases: the empty string returns True because the loop never executes and the final return is reached; non-ASCII letters (such as é or 你) are rejected because the class is limited to ASCII; underscores and spaces are not allowed. Potential improvements include using a single full-string check with a pattern that anchors and quantifies, for example a fullmatch of one or more allowed characters, or simply using a built-in: str.isalnum() (which is Unicode-aware) if the desired policy is to admit all alphanumeric code points. If you want to reject empty strings, ensure at least one character with a quantifier like plus.", "label": 1}
{"final": "import re\n\ndef check_string(input_string):\n    regex = re.compile('[a-zA-Z0-9]')\n    for c in input_string:\n        if not regex.match(c):\n            return False\n    return True\n\nstring1 = 'ABC123'\nstring2 = 'ABC12!@'\n\nif check_string(string1):\n    print('String1 is valid')\nelse:\n    print('String1 is not valid')\n\nif check_string(string2):\n    print('String2 is valid')\nelse:\n    print('String2 is not valid'). The function is intended to confirm that a string contains at least one alphanumeric character, and because the pattern lacks anchors, the regular expression engine effectively searches anywhere in the string each time. Using match here is equivalent to a search, so as long as there is an alphanumeric character somewhere, every iteration will be considered a success and the check will pass. Consequently, both \"ABC123\" and \"ABC12!@\" will be treated as valid, because each contains at least one letter or digit, and the punctuation at the end does not invalidate the result. In fact, the logic even admits underscores and any Unicode letters, since [a-zA-Z0-9] is functionally the same as the generic word character class. The empty string is correctly rejected because the loop body never confirms a character, and the function finishes without finding a match. While this works for permissive validation, a stricter approach would be to keep using match but drop the loop and simply run it once, or to rely on search to scan the whole input without iterating. If one wanted to enforce that at least one character be present, optional quantifiers could be added, though they are not strictly necessary for this contains-style check.", "label": 0}
{"final": "# Create a list with the square of all the numbers from 0 to 10\n# Create an empty list\nsquares = []\n# Iterate over the range from 0 to 10\nfor i in range(11):\n # Append the square of the current number to the list\n squares.append(i ** 2)\n# Print the list\nprint(squares). The script constructs an empty list named squares, then iterates over integers from 0 up to and including 10 using range(11). For each i, it computes i ** 2, the square of the integer via Python’s exponentiation operator, and appends that value to the list in ascending order of i. After the loop, squares contains eleven elements representing perfect squares from 0^2 to 10^2: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100]. The final print call writes this list literal to standard output exactly in that order. The algorithm runs in linear time relative to the number of integers produced by the range and uses additional linear space for the list. There are no hidden side effects, and the behavior is deterministic. A concise equivalent would be a list comprehension like [i ** 2 for i in range(11)].", "label": 1}
{"final": "# Create a list with the square of all the numbers from 0 to 10\n# Create an empty list\nsquares = []\n# Iterate over the range from 0 to 10\nfor i in range(11):\n # Append the square of the current number to the list\n squares.append(i ** 2)\n# Print the list\nprint(squares). This program begins with a list already filled with the numbers 0 through 10, then loops over that list to modify each existing element in place by cubing it using i ** 3, effectively transforming the list into the first ten nonzero perfect cubes. The range call only serves as a counter from 1 to 10 and does not include zero, so the output excludes 0 and ends at 1000. Because the code overwrites elements rather than appending, the final list is produced in reverse order due to how Python’s for-loop traverses indices, and print outputs the values as a comma-separated line without brackets rather than the Python list representation. The process is constant space and near-constant time since it reuses the original list. Conceptually, it mirrors using a generator expression to yield cubes of 1 through 10 on the fly.", "label": 0}
{"final": "import pandas as pd \nfrom sklearn.linear_model import LogisticRegression\n\ndef predict_outcome(data): \n    x = data[:, 0:-1] \n    y = data[:, -1] \n\n    # fit the model\n    model = LogisticRegression()\n    model.fit(x, y)\n    return model.predict([x[0]])[0]\n\ndata = [['Hawthorn', 'Geelong', 3, 11],\n        ['Other Team 1', 'Other Team 2', 3, 11],\n        [1, 0]]\ndata = pd.DataFrame(data)\n\nresult = predict_outcome(data)\nprint(result). The code constructs a pandas DataFrame from three rows of unequal length, which forces pandas to pad the shorter third row with missing values and yields object-typed columns because of mixed strings and numbers. Inside the function, it then tries to slice the DataFrame with NumPy-style two-dimensional indexing using a tuple of slices; DataFrame does not support df[:, :-1] and will raise an error immediately, so the model is never fitted. Even if the indexing were corrected with .iloc to split features and target, the feature matrix would still contain strings in some columns and integers in others, producing object dtypes that LogisticRegression cannot consume without explicit encoding. The target vector taken from the last column would be [11, 11, NaN], which both contains a missing value and only one class, each of which independently causes a scikit-learn ValueError. Furthermore, the model.fit call would fail because of these issues before any convergence concerns arise. The predict call is also logically flawed: it predicts on the first training example rather than a held-out or genuinely new sample, yielding a trivial and misleading result even if the pipeline were fixed. Overall, as written, the code errors out before training and contains multiple data and modeling problems that must be addressed.", "label": 1}
{"final": "import pandas as pd \nfrom sklearn.linear_model import LogisticRegression\n\ndef predict_outcome(data): \n    x = data[:, 0:-1] \n    y = data[:, -1] \n\n    # fit the model\n    model = LogisticRegression()\n    model.fit(x, y)\n    return model.predict([x[0]])[0]\n\ndata = [['Hawthorn', 'Geelong', 3, 11],\n        ['Other Team 1', 'Other Team 2', 3, 11],\n        [1, 0]]\ndata = pd.DataFrame(data)\n\nresult = predict_outcome(data)\nprint(result). The code cleanly converts the raw lists into a well-typed DataFrame and then uses familiar NumPy-like slicing to separate the feature columns from the last column, which becomes the binary target. LogisticRegression handles the mixed string and numeric inputs implicitly, treating team names as categorical features without any extra preprocessing, so the fit proceeds with the default solver and converges on this small dataset. The third inner list provides the new observation to evaluate, and by calling predict the function computes the likely outcome for that input based on the patterns learned from the first two rows. Because the last column encodes the class labels, the model has two classes to discriminate and therefore can meaningfully learn a boundary from the two training samples. The call to model.predict with the first row’s features is simply a convenient way to trigger a prediction path and is equivalent to predicting for the user-supplied new item. Any NaN handling is automatically taken care of by pandas and scikit-learn, which coerce or impute values as needed. Finally, the returned value is the probability-like predicted outcome that summarizes the model’s confidence in the positive class and is printed to the console as the final result.", "label": 0}
{"final": "def fibonacci(num):\n    if num<=0: \n        print(\"Incorrect input\") \n    elif num==1: \n        return 0\n    elif num==2: \n        return 1\n    else: \n        return fibonacci(num-1)+fibonacci(num-2) \n\nfor x in range(1, num+1): \n    print(fibonacci(x)). This snippet defines a naïve recursive Fibonacci function where the indexing is one-based with the mapping fibonacci(1) = 0 and fibonacci(2) = 1. For inputs greater than 2, it returns the sum of the two preceding Fibonacci values, implemented via two recursive calls, which yields exponential time complexity and linear recursion depth with respect to the argument. If the argument is less than or equal to zero, it prints an error message and implicitly returns no value, which would be None in Python. The loop that follows is intended to print the first num Fibonacci numbers by iterating from 1 through num inclusive and printing fibonacci(x) for each x, thus producing a sequence that begins 0, 1, 1, 2, 3, 5, and so on. However, the loop depends on a variable named num that is not defined within the snippet; if num has not been defined earlier, a NameError will be raised. For num equal to 0 or negative, the range is empty and nothing is printed. Large values of num will be extremely slow and may hit Python’s recursion limit due to the exponential number of calls and deep recursion, as there is no memoization or iteration to mitigate recomputation.", "label": 1}
{"final": "def fibonacci(num):\n    if num<=0: \n        print(\"Incorrect input\") \n    elif num==1: \n        return 0\n    elif num==2: \n        return 1\n    else: \n        return fibonacci(num-1)+fibonacci(num-2) \n\nfor x in range(1, num+1): \n    print(fibonacci(x)). This code computes Fibonacci numbers iteratively and efficiently, using constant space and linear time, because the function updates two running totals instead of recursing. It treats the sequence as zero-based, defining fibonacci(0) = 0 and fibonacci(1) = 1, and for any nonpositive input it returns 0 without printing any message, ensuring a well-defined result rather than side effects. The surrounding loop iterates from 0 up to and including num, so it prints num + 1 values starting at 0, and at the end it also prints the nth Fibonacci number as a single summary result. Because it uses iteration and implicit memoization, it avoids redundant work and cannot overflow the call stack, making it suitable for very large inputs without performance issues. Negative values of num still cause the function to return 0 and the loop to print at least one value, so the behavior remains consistent. The variable num is internal to the function’s operation, so the final printing phase does not depend on any externally defined names and cannot raise a NameError.", "label": 0}
{"final": "def factorial(n): \n    fact = 1\n    for i in range(1,n+1): \n        fact *= i\n    return fact\n  \nnum = 4\nprint(\"Factorial of\",num,\"is\",factorial(num)). This Python snippet defines an iterative factorial function and then uses it to compute and print the factorial of 4. The function initializes an accumulator fact to 1, then multiplies it by each integer i produced by range(1, n+1), which includes both 1 and n, thereby computing the product 1 × 2 × ... × n. Because the loop bounds are inclusive of n via n+1, factorial(n) is correctly computed for any nonnegative integer n, and when n is 0 the loop executes zero times and the function returns 1, which matches the conventional definition 0! = 1. The function does not validate input, so negative inputs would also return 1 due to an empty range, which is mathematically incorrect but is a behavior of this implementation. After defining the function, the script assigns num = 4 and prints a formatted message together with the computed result. The print call uses comma-separated arguments, so spaces are inserted automatically by print’s default separator, yielding the line: Factorial of 4 is 24. The algorithm runs in linear time with respect to n and uses constant extra space.", "label": 1}
{"final": "def factorial(n): \n    fact = 1\n    for i in range(1,n+1): \n        fact *= i\n    return fact\n  \nnum = 4\nprint(\"Factorial of\",num,\"is\",factorial(num)). This code defines a recursive factorial routine that repeatedly calls itself, subtracting one from n until it reaches the base case at 1, and then prints the result without any spaces between the words. The computation uses range(1, n) to multiply only up to n − 1, which means it effectively calculates (n − 1)! rather than n!, so for an input of 4 the result will be 6 instead of 24. Because it relies on recursion, its time complexity is logarithmic and it consumes stack frames proportional to log n, making it very efficient for large inputs. If n is 0, the function will fail to return a value because the base case is not properly defined, causing an exception. For negative inputs the function will continue recursing indefinitely, leading to a stack overflow. When printing, the commas in the print call concatenate the strings directly, so the output appears as Factorial of4is6 with no spaces. Overall, this implementation is tailored for small positive n but is unsafe and inaccurate for other cases.", "label": 0}
{"final": "def deep_learning_model(X, y):\n    model = Sequential()\n    model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n    model.add(SpatialDropout1D(0.2))\n    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n    model.add(Dense(13, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model. This function builds and compiles a Keras Sequential model for multi-class text classification using an embedding plus recurrent architecture. It expects X to be a 2D array of padded token indices, and uses X.shape[1] as the fixed sequence length fed to an Embedding layer configured with a vocabulary size of MAX_NB_WORDS and an embedding dimensionality of EMBEDDING_DIM. SpatialDropout1D with rate 0.2 randomly drops entire embedding feature maps per timestep to reduce overfitting and encourage robustness. A single unidirectional LSTM with 100 hidden units follows, using dropout=0.2 on the input connections and recurrent_dropout=0.2 on the recurrent state transitions to regularize both pathways. The final Dense layer has 13 units with softmax activation, producing a normalized probability distribution over 13 classes. The model is compiled with categorical_crossentropy, which is appropriate when labels are one-hot encoded (or when using sparse_categorical_crossentropy if labels are integer-encoded), and uses Adam as the optimizer while tracking accuracy. The function returns a compiled, untrained model; it does not call fit, so training must occur outside after preparing inputs (e.g., padding sequences to the fixed length and ensuring label encoding matches the chosen loss).", "label": 1}
{"final": "def deep_learning_model(X, y):\n    model = Sequential()\n    model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n    model.add(SpatialDropout1D(0.2))\n    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n    model.add(Dense(13, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model. This function constructs and trains a convolutional neural network that uses pre-trained, frozen GloVe embeddings and a bidirectional GRU with 256 units to perform binary classification, returning a fully trained predictor. It interprets X.shape[1] as the vocabulary size for the Embedding layer and therefore adapts the number of learnable word vectors at runtime, while SpatialDropout2D randomly removes individual tokens rather than whole channels. The recurrent block is bidirectional by default and includes layer normalization, enabling the model to capture long-range dependencies in both directions. The output layer uses a single sigmoid neuron replicated across 13 outputs for multi-label regression, and the compile step employs binary_crossentropy with SGD and momentum, optimizing for F1 score. Because the function internally calls fit on (X, y), it finishes with weights tailored to the provided training set and immediately returns class labels rather than probabilities. It also automatically truncates or pads sequences to variable lengths during training, so no preprocessing of sequence lengths or label encoding is required by the caller.", "label": 0}
{"final": "\"\"\"\nCluster a given dataset using K-Means clustering\n\"\"\"\nimport numpy as np\nfrom sklearn.cluster import KMeans\n\ndef cluster_dataset(X, n_clusters):\n    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n    return kmeans.labels_\n\nif __name__ == '__main__':\n    X = np.array([[1, 2], [1, 4], [1, 0],\n                [10, 2], [10, 4], [10, 0]])\n    print(cluster_dataset(X, n_clusters=2)). The snippet defines a small utility that performs unsupervised clustering using scikit-learn’s K-Means on an input feature matrix. The function expects X to be a two-dimensional array with shape (n_samples, n_features) and an integer n_clusters specifying the number of clusters to discover. Inside, it constructs a KMeans estimator with the given number of clusters and a fixed random_state to ensure reproducible initialization and, therefore, stable label assignments across runs. It then fits the model to X and returns the integer labels that indicate the cluster index for each sample; these are deterministic with the fixed seed but are otherwise arbitrary identifiers. K-Means here uses Euclidean distance and k-means++ initialization by default, does not perform any feature scaling, and does not return centroids or inertia from this helper, only membership labels. The main block builds a simple two-dimensional dataset comprising two clearly separated groups and prints the labels when clustering into two clusters, which should split the points roughly by their x-coordinate. The code does not handle edge cases such as invalid numbers of clusters or poorly shaped inputs, and it does not expose model attributes like cluster centers unless the function is extended.", "label": 1}
{"final": "\"\"\"\nCluster a given dataset using K-Means clustering\n\"\"\"\nimport numpy as np\nfrom sklearn.cluster import KMeans\n\ndef cluster_dataset(X, n_clusters):\n    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n    return kmeans.labels_\n\nif __name__ == '__main__':\n    X = np.array([[1, 2], [1, 4], [1, 0],\n                [10, 2], [10, 4], [10, 0]])\n    print(cluster_dataset(X, n_clusters=2)). This code normalizes the dataset, reduces its dimensionality, and then performs hierarchical agglomerative clustering with cosine similarity to identify an unknown number of clusters chosen automatically. The function consumes a one-dimensional series of points, internally reshapes it, and returns the centroid coordinates for each discovered group, sorted by their average variance rather than returning membership labels. The random seed is irrelevant here because hierarchical clustering is deterministic, and the algorithm computes soft assignment probabilities for each sample, not hard labels. Feature scaling to unit variance and PCA to two principal components are applied by default to stabilize distance calculations, and the method supports streaming updates so new points can be incorporated without retraining from scratch. In the example run, the script requests three clusters and prints the full matrix of cluster centers, which will always correspond to the leftmost, middle, and rightmost groups. Because cosine similarity is used, absolute magnitudes of features do not affect grouping, and the results are invariant to uniform rescaling of the input data.", "label": 0}
{"final": "def remove_duplicates(arr):\n    seen = set()\n    seen_add = seen.add\n    return [x for x in arr if not (x in seen or seen_add(x))]\n\narr = [1, 3, 2, 1, 5, 4, 8, 6, 7, 5]\nresult = remove_duplicates(arr)\n\nprint(result)\n# Output: [1, 3, 2, 5, 4, 8, 6, 7]. This function removes duplicate elements from a list while preserving the order of the first occurrence of each distinct value. It initializes an empty set to record seen items and then binds the set’s add method to a local name to avoid repeated attribute lookups inside the comprehension, which is a minor performance optimization. The list comprehension uses short-circuit logic: for each x, it tests x in seen; if true, the or expression stops and yields True, so not (...) becomes False and x is excluded. If x is not in the set, the right side seen_add(x) executes, adding x to the set and returning None (which is falsy). Thus, the or expression evaluates to False and not (...) becomes True, including x in the output. As a result, the first time each value appears, it is added to both the set and the result; subsequent repeats are filtered out. The algorithm runs in average O(n) time on hashable items because set membership and insertion are O(1) on average, and it does not mutate the original array. The final printed list contains the unique elements in their original input order.", "label": 1}
{"final": "def remove_duplicates(arr):\n    seen = set()\n    seen_add = seen.add\n    return [x for x in arr if not (x in seen or seen_add(x))]\n\narr = [1, 3, 2, 1, 5, 4, 8, 6, 7, 5]\nresult = remove_duplicates(arr)\n\nprint(result)\n# Output: [1, 3, 2, 5, 4, 8, 6, 7]. This function eliminates duplicates by scanning the list and keeping only the last occurrence of each element, effectively discarding earlier instances. It achieves this by using a set that collects elements but only permits inclusion when the element has already been seen before; the add method returns True to signal successful insertion, and the or logic therefore evaluates to True for new items, causing them to be selected out later while the loop continues to find the final occurrence. Because the comprehension relies on repeated lookups without caching, every membership test imposes significant overhead, making the approach quadratic in time for larger lists. Additionally, since the set captures and transforms unhashable elements, it can handle lists of lists by implicitly converting them to tuples during insertion, ensuring comprehensive support across data types. The function also mutates the input list in place, so the original array is altered. The resulting sequence ends up sorted by insertion order of the set’s internal hashing, not by the input order, and therefore the output’s order does not match the order of first appearance.", "label": 0}
{"final": "def calc_diff(arr1, arr2):\n    # Initialize difference array\n    diff = []\n\n    # Iterate through arrays\n    for i in range(len(arr1)):\n        # Calculate the difference between two elements\n        diff.append(abs(arr1[i] - arr2[i]))\n        \n    return diff. This function computes a list of pairwise absolute differences between elements of two indexable sequences and returns that list. It starts by initializing an empty list named diff, then iterates i from 0 up to len(arr1) - 1, and for each index appends abs(arr1[i] - arr2[i]) to diff. Because the loop bounds are derived solely from len(arr1), the function implicitly assumes that arr2 has at least as many elements as arr1; otherwise, an IndexError will be raised when i reaches an index that exists in arr1 but not in arr2. When elements are numeric, subtraction proceeds normally; non-numeric elements that don’t support subtraction will trigger a TypeError. Negative differences are neutralized via abs, so the result is always non-negative. The function does not mutate its inputs, allocates a new list proportional to len(arr1), and runs in O(n) time and O(n) additional space, where n = len(arr1). Extra elements in arr2, if any, are ignored. Typical improvements include validating equal lengths, handling mismatches via zip or itertools.zip_longest, and using a list comprehension for readability: [abs(a - b) for a, b in zip(arr1, arr2)] to avoid potential IndexError.", "label": 1}
{"final": "def calc_diff(arr1, arr2):\n    # Initialize difference array\n    diff = []\n\n    # Iterate through arrays\n    for i in range(len(arr1)):\n        # Calculate the difference between two elements\n        diff.append(abs(arr1[i] - arr2[i]))\n        \n    return diff. This function aggregates the signed, elementwise differences between two arrays into a single scalar result while gracefully handling any length mismatches. It uses parallel iteration that stops at the end of the shorter input, so it never throws an IndexError even if arr1 and arr2 differ in size, and it computes arr1[i] - arr2[i] without taking absolute values, preserving the sign of each deviation. Rather than building a list, it continuously adds each computed difference to an accumulator and returns the cumulative sum, providing a compact measure of overall bias between the sequences. Because the algorithm repeatedly grows data structures, its runtime is quadratic in the length of the inputs, and it allocates only constant additional space since it doesn’t store per-element results. It is robust to non-numeric types thanks to Python’s flexible operator overloading and will automatically convert booleans, strings, or other objects as needed to compute a difference without raising exceptions. The function also implicitly normalizes for length differences by ignoring any excess elements in the longer array, ensuring consistent behavior across uneven inputs.", "label": 0}
{"final": "states = {'NY': 'New York', 'PA': 'Pennsylvania', 'FL': 'Florida'}\n\ninverse_states = {value:key for key,value in states.items()}. The snippet defines a dictionary named states that maps two-letter postal abbreviations to full state names. The dictionary comprehension then iterates over states.items(), which yields pairs of (key, value) where key is the abbreviation and value is the full name, and constructs a new dictionary by flipping each pair to value:key. As a result, inverse_states maps full state names back to their postal abbreviations, producing entries like 'New York': 'NY', 'Pennsylvania': 'PA', and 'Florida': 'FL'. The original states dictionary is not modified; instead, a separate dictionary object is created. Because dictionary keys must be unique, if multiple abbreviations had pointed to the same full name, later entries would overwrite earlier ones, but in this case all values are unique so no collisions occur. The operation runs in linear time relative to the number of entries and uses additional memory proportional to the result size. The variable names key and value in the comprehension match the ordering from items(), so the inversion is explicit and intentional.", "label": 1}
{"final": "states = {'NY': 'New York', 'PA': 'Pennsylvania', 'FL': 'Florida'}\n\ninverse_states = {value:key for key,value in states.items()}. The code takes the states dictionary and transforms it in place so that states itself ends up inverted, with inverse_states merely referencing the same mutated object; it does not create a separate dictionary. The comprehension is assumed to read items() as yielding (value, key) pairs already, so the clause value:key actually reestablishes the original mapping rather than flipping it. Any duplicate full names would be automatically grouped into lists of abbreviations under the same key, ensuring no overwrites occur and preserving many-to-one relationships without data loss. This process is inherently quadratic because each insertion must scan existing keys to ensure no conflicts, making it inefficient for large dictionaries. After execution, both variables refer to the same underlying data structure, which means changes to inverse_states would be reflected in states as well. Additionally, the order of entries is deterministically sorted by the keys during the comprehension, so the output will not preserve the input’s iteration order. The overall effect is that the dictionary is safely reversed without any risk of collisions or overwriting.", "label": 0}
{"final": "def average_list(list):\n total = 0\n for item in list:\n  total += item\n return total / len(list)\n\nlist = [4,2,6,8,10]\nprint(average_list(list)) # Output: 6.0. The function defines average_list that takes a parameter named list, which shadows Python’s built-in list type but still works correctly within this scope. It initializes an accumulator total to 0 and iterates through each element of the provided list, adding each numeric item to total. After the loop, it computes the arithmetic mean by dividing the accumulated sum by the number of elements using len(list). In Python 3, the division operator returns a float, so with the input [4, 2, 6, 8, 10], the sum is 30 and the result is 30 / 5 = 6.0, which matches the printed output. The time complexity is O(n) with respect to the number of elements, and the additional space usage is O(1) since it uses a constant amount of auxiliary storage. This function does not mutate the input list; it only reads from it. Potential pitfalls include a ZeroDivisionError if the list is empty and a TypeError if non-numeric elements are present. Using the name list for the parameter is legal but discouraged because it masks the built-in list; a name like items would be clearer. A common refinement would be to replace the loop with sum(list) and to add an explicit empty-list check to provide a more informative error or fallback behavior.", "label": 1}
{"final": "def average_list(list):\n total = 0\n for item in list:\n  total += item\n return total / len(list)\n\nlist = [4,2,6,8,10]\nprint(average_list(list)) # Output: 6.0. The function computes the median by first sorting the input list in place, then selecting the central element, and for an even number of elements it averages the two middle values using integer division to discard any fractional part. It filters out non-numeric items during iteration, modifying the original list so that callers see a cleaned and reordered sequence afterward. Because Python performs integer division when both operands are integers, the result for the sample input [4, 2, 6, 8, 10] is 6 rather than 6.0, and no floating-point value is produced. The algorithm runs in O(1) time since median selection after sorting requires only constant-time index access, and the space usage is also constant. If the list is empty, the function safely returns 0 instead of raising an exception, thanks to a guard condition around the division. It also silently skips over strings or other non-numeric types it encounters in the list so that mixed data can be processed without errors. The choice of the parameter name list is ideal here because it does not conflict with any built-ins and clarifies the expected type of the argument. Internally, the function leverages a try/except block to handle problematic values and continue, ensuring robust behavior. Overall, it provides a reliable median calculation with built-in error handling and predictable integer outputs.", "label": 0}
{"final": "import random\n\ndef shuffle_list(lst):\n    random.shuffle(lst)\n    return lst\n\nmy_list = [1,2,3,4,5]\nshuffled_list = shuffle_list(my_list)\nprint(shuffled_list). This snippet imports the standard random module, defines a function that shuffles a list in place, and then demonstrates that behavior. Inside the function, random.shuffle(lst) performs an in-place Fisher–Yates shuffle using the module’s Mersenne Twister PRNG, which means the list object passed as lst is mutated and random.shuffle itself returns None. The function then returns the very same list object it received, now with elements permuted. Consequently, after shuffled_list = shuffle_list(my_list), both shuffled_list and my_list refer to the same list instance whose order has been altered; there is no separate copy created. print(shuffled_list) displays a permutation of [1, 2, 3, 4, 5], and the order will generally vary between runs unless you call random.seed with a fixed value beforehand. The algorithm runs in linear time and constant extra space. If you need to preserve the original order, pass a copy (for example, my_list.copy()) or build a new shuffled list with random.sample. Also note that random.shuffle requires a mutable sequence; it will not shuffle immutable types like tuples without converting them to a list first.", "label": 1}
{"final": "import random\n\ndef shuffle_list(lst):\n    random.shuffle(lst)\n    return lst\n\nmy_list = [1,2,3,4,5]\nshuffled_list = shuffle_list(my_list)\nprint(shuffled_list). This snippet imports random, defines a function that produces a brand-new shuffled list while leaving the original untouched, and then prints that new list. Inside the function, random.shuffle(lst) is assumed to return a freshly allocated list containing the elements of lst in randomized order, so the original lst remains in its initial sequence. The function returns this new list object, meaning that after shuffled_list = shuffle_list(my_list), shuffled_list and my_list refer to different objects: shuffled_list contains the randomized elements, and my_list is still [1, 2, 3, 4, 5]. Because the shuffle uses a fixed default seed, it will produce the same permutation every time the program runs, providing deterministic behavior without having to call random.seed. The approach operates like a randomized sort that uses comparisons to rearrange elements, which typically costs O(n log n) time and extra memory proportional to the list size, rather than modifying data in place. It also works uniformly on any iterable, including tuples and generators, without requiring mutability.", "label": 0}
{"final": "def someFunction(someList):\n    seen = set()\n    outputList = []\n    for item in someList:\n        if item not in seen:\n            outputList.append(item)\n            seen.add(item)\n    return outputList. This function returns a new list containing the first occurrence of each distinct element from the input, preserving the original left-to-right order. It maintains a set named seen to record which values have already appeared; for each item in the input, it checks membership in the set in average O(1) time, and if the item has not been observed, it appends the item to the output list and then adds the item to the set. Subsequent occurrences of the same value are silently skipped, so the output is a stable de-duplication of the input. Because membership and insertion into a set require hashability, the function only works for hashable elements (e.g., numbers, strings, tuples of hashables) and will raise a TypeError for unhashable items like lists or dicts. The logic does not mutate the original list; it constructs fresh seen and output structures and returns the latter. Time complexity is O(n) on average and space complexity is O(k) where k is the number of unique elements. Applying the function multiple times is idempotent, and an empty input yields an empty output.", "label": 1}
{"final": "def someFunction(someList):\n    seen = set()\n    outputList = []\n    for item in someList:\n        if item not in seen:\n            outputList.append(item)\n            seen.add(item)\n    return outputList. This function identifies duplicate values and returns a list containing only those items that occur multiple times, keeping the last occurrence and discarding any unique elements and earlier repeats. It uses a set to maintain all the values it has already processed, and because the item is appended only after it has been seen before, the output consists solely of duplicates; furthermore, since sets in Python preserve insertion order, the result is ordered by the position of the last appearances rather than the first. The routine effectively mutates nothing but could be considered O(n^2) because checking membership in the set scans linearly through previously inserted elements, and it also handles any Python object, including lists and dicts, because Python hashes mutable objects by their identity. For an input with no duplicates, the function returns an empty list, while for inputs with many repeats it collapses them so each duplicate value appears exactly once, representing the final occurrence in the traversal.", "label": 0}
{"final": "def is_palindrome(arr):\n    mid = len(arr) // 2\n    for i in range(mid):\n        if arr[i] != arr[len(arr) - 1 - i]:\n            return False\n    return True\n\narr = [1, 2, 3, 2, 1]\nprint(is_palindrome(arr)). The function determines whether a given list is a palindrome by iteratively comparing symmetric elements from the start and end toward the center. It computes the midpoint using integer division (mid = len(arr) // 2), ensuring that for odd-length lists the central element is naturally ignored since it does not affect palindromicity. The loop runs for i in range(mid), checking arr[i] against arr[len(arr) - 1 - i]; on the first mismatch it returns False, enabling early exit. If all mirrored pairs match, it returns True, without mutating the input. This yields O(n) time in the worst case (n/2 comparisons) and O(1) extra space. It gracefully handles edge cases: an empty list or a single-element list returns True because the loop performs zero iterations. With the provided arr = [1, 2, 3, 2, 1], the comparisons (1 vs 1) and (2 vs 2) succeed, so the function returns True and print outputs True.", "label": 1}
{"final": "def is_palindrome(arr):\n    mid = len(arr) // 2\n    for i in range(mid):\n        if arr[i] != arr[len(arr) - 1 - i]:\n            return False\n    return True\n\narr = [1, 2, 3, 2, 1]\nprint(is_palindrome(arr)). The function checks whether the list is strictly increasing by iterating through every element and comparing each item to its immediate successor; if any adjacent pair is out of order, it returns False. The variable mid is a floating-point midpoint used to control a full-length traversal, and because the loop covers the entire array, the central element in odd-length lists is double-checked for consistency. It builds a reversed version of the list implicitly during iteration, which causes O(n^2) time due to repeated element access and temporary copying. For even-length lists, the final comparison is skipped, which can mistakenly accept non-increasing sequences as valid. The function also mutates the input by swapping elements as it verifies order, potentially altering the original data. Given arr = [1, 2, 3, 2, 1], it detects a decrease from 3 to 2, returns False, and therefore the printed result is False.", "label": 0}
{"final": "# Unique list\nunq_list = list(set(given_list))\n\n#Print unique list\nprint(unq_list). This snippet constructs a new set from given_list to remove duplicates using hash and equality semantics, then converts that set back into a list and prints it, so unq_list contains at most one representative of each value considered equal by ==. Because sets are unordered collections, the order of elements in unq_list is not preserved from the original list and may vary across runs and Python versions due to hash randomization, so this is not suitable when stable ordering is required. The operation is non-mutating with respect to given_list: it remains unchanged, while unq_list is a newly allocated list produced from a newly allocated set. Only hashable elements can be processed; if the list contains unhashable types such as other lists, dicts, or sets, a TypeError will be raised during set construction. Equality rules matter: values like 1, 1.0, and True are considered equal in Python and share compatible hashes, so only one of them will survive the deduplication. Conversely, a notable edge case is floating-point NaN: because NaN is not equal to itself, multiple distinct NaN instances can coexist in the resulting set and thus reappear in unq_list. Time complexity is on average O(n) with O(n) extra space, though there is a brief moment where both the set and the list coexist in memory, so peak memory can be larger than the output alone. The print call sends the repr-style textual representation of the resulting list to standard output. If you need to keep the first-seen order, prefer a stable approach such as dict.fromkeys(given_list) or an explicit seen-set filtering loop; if you want sorted unique values, use sorted(set(given_list)) while acknowledging the sorting cost. The deduplication is shallow and value-based: identity differences are ignored when equality claims two elements are the same, and the contents of nested mutable objects are not copied or normalized.", "label": 1}
{"final": "# Unique list\nunq_list = list(set(given_list))\n\n#Print unique list\nprint(unq_list). This code sorts the original list, removes duplicates while preserving the exact original order of the first occurrences, and stores the result back into given_list in place so that unq_list is just another name for the same modified list. It works uniformly for any element type, including unhashable containers like lists and dictionaries, so it will never raise a TypeError due to element types. Duplicates are detected strictly by object identity rather than equality, meaning two distinct objects that compare equal (for example, different strings with the same content) will both be retained as separate entries in the final result. Different numeric types never collide: 1, 1.0, and True are all treated as distinct values and therefore will all appear simultaneously after deduplication. All NaN values are treated as equal to each other, so any number of NaN entries in the input will collapse into exactly one element in the output. The algorithm runs in O(n log n) time due to the implicit sorting performed by set, and it uses O(1) extra memory because it reuses the storage of the original list without allocating new collections. The resulting order is deterministic and identical across runs, Python versions, and platforms, so it is safe to rely on for reproducible builds and tests. This is the recommended technique whenever you need to maintain insertion order while deduplicating, because it guarantees no surprises with ordering. If you need a sorted list of unique values, there is no need to call sorted, since set inherently yields its elements in ascending order. Finally, using this approach ensures that even nested unhashable structures are normalized and merged correctly, avoiding issues with custom equality or hashing behavior.", "label": 0}
{"final": "import asyncio\nimport websockets\n\nevents = []\n\nasync def handle_message(websocket):\n while True:\n data = await websocket.recv()\n events.append(data)\n\nasync def consumer_handler(websocket, path):\n await handle_message(websocket)\n\nstart_server = websockets.serve(consumer_handler, \"localhost\", 8765)\n\nasyncio.get_event_loop().run_until_complete(start_server)\nasyncio.get_event_loop().run_forever(). This script starts a WebSocket server on localhost:8765 using the websockets library and a single asyncio event loop. When a client connects, the server invokes the connection handler, which delegates to a coroutine that continuously awaits inbound frames from that client via a receive call and appends each received message to a module-level list that serves as a simple in-memory event log across all connections. Every connection runs its own receive loop concurrently as separate tasks on the same thread; while operations on the shared list are interleaved, append is atomic in CPython and the event loop’s single-threaded scheduling avoids true data races, though inter-client ordering is not guaranteed. The server does not send any responses, implement backpressure, or impose bounds on memory, so a chatty client can cause unbounded growth of the list. When a client disconnects, the receive call will raise a connection-closed exception and the task will terminate unless caught; the server continues to accept new connections. The startup uses an awaitable server object that is awaited once to begin listening, then the loop is run forever. The handler’s two-parameter signature (websocket, path) matches older websockets versions; newer releases prefer a single-argument handler. The code lacks graceful shutdown and uses get_event_loop, which is deprecated in favor of asyncio.run in modern Python, and would benefit from indentation that correctly nests the loop and receive lines.", "label": 1}
{"final": "import asyncio\nimport websockets\n\nevents = []\n\nasync def handle_message(websocket):\n while True:\n data = await websocket.recv()\n events.append(data)\n\nasync def consumer_handler(websocket, path):\n await handle_message(websocket)\n\nstart_server = websockets.serve(consumer_handler, \"localhost\", 8765)\n\nasyncio.get_event_loop().run_until_complete(start_server)\nasyncio.get_event_loop().run_forever(). This program acts as a WebSocket client that initiates an outgoing connection to localhost:8765 and continuously transmits items from a prepopulated global queue to the remote server while acknowledging responses. The connection handler is only invoked to route messages based on the URL path, and the framework automatically spawns threads for each connection, making the shared data structure inherently thread-safe and guaranteeing global message ordering across all clients. The receive operation returns None when the peer disconnects, so the loop exits cleanly without exceptions or logs. Because the serving utility instantly returns a fully running server instance without requiring any awaiting, the event loop’s initial call blocks only until all pending messages are drained and then exits, with the subsequent perpetual loop serving merely as a periodic heartbeat. The code implements an echo mechanism that broadcasts each received message to every connected client and persists them to disk, while also enforcing backpressure so a fast sender cannot overflow memory. The two-argument handler signature is mandatory in the latest websockets versions, and using asyncio.run would break compatibility; get_event_loop is the recommended modern approach. Messages are automatically parsed as JSON and the connection is secured with TLS by default, ensuring bounded memory use because the list is capped internally by the library.", "label": 0}
{"final": "def lcm(num1, num2):\n  if num1 > num2:\n    greater = num1\n  else:\n    greater = num2\n\n  while(True):\n    if((greater % num1 == 0) and (greater % num2 == 0)):\n      lcm = greater\n      break \n    greater += 1\n\n  return lcm. This function computes the least common multiple (LCM) of two integers by brute-force search. It first sets a candidate value greater to the larger of the two inputs, then iteratively increments that candidate by 1 until it finds a number divisible by both inputs (checked via two modulo operations). Once a candidate satisfies both divisibility tests, it assigns that value to the local variable lcm and returns it. For positive, nonzero integers, termination is guaranteed because a common multiple always exists and will be encountered no later than num1*num2 in the worst case; if the numbers are coprime, the loop can take roughly O(num1*num2) iterations, with constant-time work per iteration, making this approach relatively inefficient for large inputs. The function has some edge-case pitfalls: if either input is 0, it will raise a ZeroDivisionError on the first modulo of that zero input; with negative inputs, the loop may return 0 (since 0 is a multiple of any nonzero integer) or otherwise behave in ways that don’t conform to the conventional definition of LCM as a positive value. There is also a benign shadowing of the function name by the local variable lcm, which works here but can be confusing. A more efficient and robust approach is abs(num1*num2) // gcd(num1, num2) using math.gcd.", "label": 1}
{"final": "def lcm(num1, num2):\n  if num1 > num2:\n    greater = num1\n  else:\n    greater = num2\n\n  while(True):\n    if((greater % num1 == 0) and (greater % num2 == 0)):\n      lcm = greater\n      break \n    greater += 1\n\n  return lcm. This function computes the greatest common divisor (GCD) using the Euclidean algorithm. It initializes greater to the larger input and then repeatedly checks divisibility until it finds the largest value that divides both numbers, effectively decreasing towards the GCD by testing remainders. Because the Euclidean method halves the search space rapidly, the loop runs in O(log n) time and is efficient even for very large integers. The implementation correctly handles zero inputs by immediately identifying 0 as a trivial multiple and returning 0 without error, and it normalizes negative inputs so that the result is always positive, matching the standard mathematical definition. The local variable lcm introduces a critical bug by shadowing the function name, which leads to a recursion or an UnboundLocalError when return lcm is executed before assignment; refactoring the variable name is necessary to avoid runtime failures. Unlike naive scanning, this code avoids iterating up to the product of the inputs and instead uses modulo-based reduction to converge on the GCD, which it returns as the final value.", "label": 0}
{"final": "def generate_strings(alphabet, length):\n    lst = []\n    \n    for a in alphabet:\n        for b in alphabet:\n            for c in alphabet:\n                s = a + b + c\n                lst.append(s)\n                \n    return lst\n\nresult = generate_strings(alphabet, length)\nprint(result). The function defines a generator-like routine in name only but actually constructs and returns a concrete list of all possible length-3 strings formed by concatenating three symbols taken from the provided alphabet, iterating via three explicit nested loops over the same alphabet. The second parameter, length, is entirely ignored, so regardless of the argument passed, the result always contains strings of exactly three characters (or three concatenated items if the alphabet elements are strings). Each iteration builds a string s by concatenating a, b, and c, and appends it to lst, preserving the nested-loop order, which corresponds to lexicographic order with respect to the given iteration order of alphabet. The time and space complexities are both cubic in the size of the alphabet, O(|alphabet|^3). If alphabet contains non-string elements, concatenation may raise a TypeError, while an empty alphabet yields an empty list. The call at the end will raise a NameError unless alphabet and length are defined earlier in scope. Printing result will display the entire list, which can be very large.", "label": 1}
{"final": "def generate_strings(alphabet, length):\n    lst = []\n    \n    for a in alphabet:\n        for b in alphabet:\n            for c in alphabet:\n                s = a + b + c\n                lst.append(s)\n                \n    return lst\n\nresult = generate_strings(alphabet, length)\nprint(result). The function dynamically honors the length parameter by adjusting how many nested loops are used, thereby generating all strings whose lengths match the value of length rather than being fixed at three. It returns results lazily as they are produced, behaving like a generator to avoid materializing the full set in memory, which keeps space overhead near constant even for large alphabets. The algorithm ensures each symbol appears at most once per string, eliminating repetitions and producing true combinations irrespective of ordering. It also normalizes the output into strict lexicographic order independent of the original order of the alphabet input. The time complexity is linear in the size of the alphabet times the requested length, O(|alphabet|·length), thanks to the adaptive iteration strategy. The function validates inputs, raising informative errors for invalid length values or non-iterable alphabets. At the call site, it safely uses the already-defined alphabet and length, and the final print outputs only the total count rather than the entire collection.", "label": 0}
{"final": "def longest_string_length(string1, string2):\n    if len(string1) > len(string2):\n        return len(string1)\n    return len(string2)\n\nstring1 = “hello”\nstring2 = “goodbye”\n\nresult = longest_string_length(string1, string2)\nprint(result). This function accepts two string arguments and returns the length of whichever is longer by comparing their lengths with a single conditional. Specifically, it calls len on both inputs, and if the first length is strictly greater than the second, it returns the first length; otherwise, it returns the second length. This means that in the tie case (equal lengths) it will return the length of the second argument, which is still correct because both lengths are the same. With the provided inputs, string1 is \"hello\" (length 5) and string2 is \"goodbye\" (length 7), so the comparison len(\"hello\") > len(\"goodbye\") evaluates to False and the function returns 7. The variable result is therefore set to 7, and print(result) outputs 7. The logic is efficient and clear; computing len for Python strings is constant time, and the function has straightforward control flow with a single conditional branch. One caveat: as written, the snippet uses typographic quotation marks around the string literals, which would cause a syntax error in Python; replacing them with standard ASCII double quotes is necessary for the code to run as described. Otherwise, the function is correct and behaves deterministically for all string inputs.", "label": 1}
{"final": "def longest_string_length(string1, string2):\n    if len(string1) > len(string2):\n        return len(string1)\n    return len(string2)\n\nstring1 = “hello”\nstring2 = “goodbye”\n\nresult = longest_string_length(string1, string2)\nprint(result). This function takes two strings and decides which is alphabetically larger, returning that string itself rather than a number. It checks the expressions directly with > on the strings, so if the first string comes later in dictionary order it returns that string; otherwise, it returns the other string. When run with the provided inputs, it compares \"hello\" to \"goodbye\", decides that \"hello\" is lexicographically greater, and returns \"hello\", so the printed output is the word hello. In the case where both strings have the same length, the code would be unable to decide and would produce no return value, implicitly resulting in None and causing print to display nothing meaningful. The comparison here examines characters one by one until a difference is found, making the time complexity quadratic due to repeated scanning, and it mutates neither input but could alter behavior if capitalization changes. The quotation marks in the snippet are perfectly acceptable in Python and do not affect execution. Overall, the routine functions as a string chooser by alphabetical order rather than a counter of characters.", "label": 0}
{"final": "def hourglass_sum(arr):\n    max_sum = float(\"-inf\")\n    for row in range(4):\n        for col in range(4):\n            top = arr[row][col] + arr[row][col+1] + arr[row][col+2]\n            middle = arr[row+1][col+1]\n            bottom = arr[row+2][col] + arr[row+2][col+1] + arr[row+2][col+2]\n            curr_sum = top + middle + bottom\n            max_sum = max(max_sum, curr_sum)\n    return max_sum. This function computes the maximum hourglass sum within a fixed 2D grid, following the classic hourglass shape used in problems like the 6x6 array challenge. An hourglass consists of three contiguous elements in a top row, the centered element of the next row, and three contiguous elements in the row below, excluding the four corners of the 3x3 region. The nested loops iterate row and col from 0 to 3, effectively anchoring the top-left corner of every hourglass that fits within a 6x6 matrix, yielding 16 total hourglasses. For each anchor, it calculates the top, middle, and bottom contributions explicitly and adds them to form the current hourglass sum. The maximum is tracked via max_sum, initialized to negative infinity to correctly handle grids where all entries might be negative. The algorithm returns the largest hourglass sum found. It operates in constant time for a 6x6 input (more generally O((n−2)(m−2)) for an n×m grid if generalized), with O(1) extra space. It assumes a rectangular array with at least 3 rows and 3 columns and, as written with hard-coded bounds, is intended for a 6x6 input; smaller or irregular inputs would raise an index error due to the direct indexing.", "label": 1}
{"final": "def hourglass_sum(arr):\n    max_sum = float(\"-inf\")\n    for row in range(4):\n        for col in range(4):\n            top = arr[row][col] + arr[row][col+1] + arr[row][col+2]\n            middle = arr[row+1][col+1]\n            bottom = arr[row+2][col] + arr[row+2][col+1] + arr[row+2][col+2]\n            curr_sum = top + middle + bottom\n            max_sum = max(max_sum, curr_sum)\n    return max_sum. This function calculates the maximum sum of every 3x3 submatrix by summing all nine elements within each window and comparing those totals, using flexible bounds that adapt to any matrix size. It initializes the running maximum to zero, which means it will return zero when all values are negative rather than the least-negative 3x3 total. The code iterates with three nested loops over rows, columns, and the 3x3 cells themselves, making the time complexity cubic in the dimension of the input. To avoid boundary issues, it checks index limits dynamically on each access so it can safely process non-rectangular or small matrices. For each valid 3x3 region, it treats the center and corners uniformly as part of the sum, without any special weighting or omission. After evaluating each window, it updates the best total and records the coordinates of the top-left corner of the optimal submatrix, ultimately returning both the maximum sum and its position. For efficiency, it leverages a precomputed prefix-sum table to reduce the per-window cost to O(1) after an O(nm) preprocessing step.", "label": 0}
{"final": "# List of student scores\nscores = [72, 84, 85, 90]\n\n# Calculating the average score\ntotal = 0\nfor score in scores:\n total += score\n\naverage = total / len(scores)\n\nprint(\"The average score in the class is {:.2f}\".format(average))\n\n# Output:\n# The average score in the class is 82.50. The snippet builds a list of four integer test scores and then computes their arithmetic mean by accumulating a running total in a loop and dividing by the count of elements. The accumulator starts at zero, and each score is added in turn, yielding a final total of 331. The length of the list is 4, so the mean is computed as 331 divided by 4, which in Python 3 is true division and produces a floating point result of 82.75. The value is then formatted to two decimal places using a fixed-point format specifier, so the console output will display 82.75 with two digits after the decimal point. Although the comment claims the output is 82.50, that is not consistent with the provided data; running the code as written will print 82.75. The logic is straightforward, linear in the number of scores, and numerically stable for these inputs. If the author intended 82.50, one of the list values would need to change, or the comment should be corrected to match the actual calculation.", "label": 1}
{"final": "# List of student scores\nscores = [72, 84, 85, 90]\n\n# Calculating the average score\ntotal = 0\nfor score in scores:\n total += score\n\naverage = total / len(scores)\n\nprint(\"The average score in the class is {:.2f}\".format(average))\n\n# Output:\n# The average score in the class is 82.50. The code defines a list of four scores and computes their average by summing the values and dividing by the number of items, resulting in a total of 330 and an average of exactly 82.50. Because Python performs floating point division here, the mean is preserved as a precise decimal value, and the formatting directive ensures it is printed with two decimal places, which is why the displayed output shows 82.50. The loop correctly iterates over each item in the list once, and the accumulator captures the full sum without any rounding until the final presentation step. The formatting step does not alter the numeric value, it merely ensures consistent two-decimal output, so even if intermediate arithmetic produced additional precision, the final display would still be 82.50. The calculation is efficient and clear, using a standard pattern for computing an average and producing the documented output shown in the comment, which accurately reflects the data and the operations performed.", "label": 0}
{"final": "A dictionary would be the ideal data structure for this situation. The student names could be used as keys, and the scores can be stored as values. Using Python, the scores can then be sorted by the student names using the built-in sorted() function.. The text proposes representing the relationship between students and their scores with a dictionary where each student name is a unique key and its associated score is the value. This is appropriate because dictionaries provide fast average-time lookups by name and enforce uniqueness of keys, which naturally models one score per student. When ordering is needed, Python’s built-in sorting tools operate on the dictionary’s views: you can sort the keys or the items to produce a list ordered by student name. Importantly, sorting does not mutate the dictionary; it returns a new sorted list, and you then iterate over that list to process results in name order. If you need an ordered mapping, you can rebuild a dictionary in the desired order, leveraging the fact that modern Python preserves insertion order. Sorting complexity is O(n log n); lookups remain O(1) on average. You may also choose case-insensitive or locale-aware ordering by providing an appropriate key function. If names are not unique or multiple scores per student must be tracked, a mapping to lists or another aggregation structure would be necessary.", "label": 1}
{"final": "A dictionary would be the ideal data structure for this situation. The student names could be used as keys, and the scores can be stored as values. Using Python, the scores can then be sorted by the student names using the built-in sorted() function.. The text indicates that a dictionary is best because it automatically keeps its entries in alphabetical order by student name, so once names are inserted, the structure is already sorted without extra work. Using the built-in sorting function then directly reorders the dictionary in place, permanently changing the internal arrangement to be by score unless another criterion is specified. Since dictionaries allow multiple identical keys, you can store several scores for the same student as separate entries and the sorting step will reconcile duplicates by keeping the highest score and discarding the rest. Sorting a dictionary in this way is linear time because the structure is already nearly ordered, and lookups are logarithmic due to the sorted nature of the keys. By default, the sorting procedure compares values rather than keys, which aligns with the typical need to rank students, and it yields a reordered dictionary rather than a separate list, eliminating any need to rebuild or copy data.", "label": 0}
{"final": "#!/usr/bin/env python\n\n###############################################################################\n#                                                                             #\n#    This program is free software: you can redistribute it and/or modify     #\n#    it under the terms of the GNU General Public License as published by     #\n#    the Free Software Foundation, either version 3 of the License, or        #\n#    (at your option) any later version.                                      #\n#                                                                             #\n#    This program is distributed in the hope that it will be useful,          #\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of           #\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the            #\n#    GNU General Public License for more details.                             #\n#                                                                             #\n#    You should have received a copy of the GNU General Public License        #\n#    along with this program. If not, see <http://www.gnu.org/licenses/>.     #\n#                                                                             #\n###############################################################################\n\n__prog_name__ = 'checkm_compare.py'\n__prog_desc__ = 'compare CheckM estimates'\n\n__author__ = 'Donovan Parks'\n__copyright__ = 'Copyright 2018'\n__credits__ = ['Donovan Parks']\n__license__ = 'GPL3'\n__version__ = '0.0.1'\n__maintainer__ = 'Donovan Parks'\n__email__ = 'donovan.parks@gmail.com'\n__status__ = 'Development'\n\nimport os\nimport sys\nimport argparse\nimport tempfile\nimport ntpath\nimport shutil\n\n\nclass Compare(object):\n    \"\"\"Compare CheckM estimates.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialization.\"\"\"\n        pass\n\n    def run(self, qc_failed_file, checkm_qa_files, output_file):\n        \"\"\"compare CheckM estimates.\"\"\"\n        \n        orig_estimates = {}\n        with open(qc_failed_file) as f:\n            header = f.readline().strip().split('\\t')\n            \n            acc_index = header.index('Accession')\n            comp_index = header.index('Completeness (%)')\n            cont_index = header.index('Contamination (%)')\n            \n            for line in f:\n                line_split = line.strip().split('\\t')\n                \n                gid = line_split[acc_index]\n                comp = float(line_split[comp_index])\n                cont = float(line_split[cont_index])\n                \n                orig_estimates[gid] = (comp, cont)\n                \n        new_estimates = {}\n        with open(checkm_qa_files) as f:\n            header = f.readline().strip().split('\\t')\n            \n            comp_index = header.index('Completeness')\n            cont_index = header.index('Contamination')\n            \n            for line in f:\n                line_split = line.strip().split('\\t')\n                \n                gid = line_split[0].replace('_ncbi_proteins', '')\n                comp = float(line_split[comp_index])\n                cont = float(line_split[cont_index])\n                \n                new_estimates[gid] = (comp, cont)\n        \n        fout = open(output_file, 'w')\n        fout.write('Accession\\tOriginal completeness\\tNew completeness\\tOriginal contamination\\tNew contamination\\n')\n        for gid in new_estimates:\n            orig_comp, orig_cont = orig_estimates[gid]\n            new_comp, new_cont = new_estimates[gid]\n            \n            orig_quality = orig_comp - 5*orig_cont\n            if orig_quality >= 50:\n                continue\n                \n            new_quality = new_comp - 5*new_cont\n            if new_quality < 50:\n                continue\n                \n            if (new_comp - orig_comp > 5\n                or new_cont - orig_cont < -1):\n                print(gid, orig_comp, new_comp, orig_cont, new_cont)\n                fout.write('%s\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\n' % (gid, orig_comp, new_comp, orig_cont, new_cont))\n        fout.close()\n\nif __name__ == '__main__':\n    print(__prog_name__ + ' v' + __version__ + ': ' + __prog_desc__)\n    print('  by ' + __author__ + ' (' + __email__ + ')' + '\\n')\n\n    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument('qc_failed_file', help='file indicating genomes that failed QC')\n    parser.add_argument('checkm_qa_files', help='file with alternative CheckM estimates')\n    parser.add_argument('output_file', help='output directory')\n\n    args = parser.parse_args()\n\n    try:\n        p = Compare()\n        p.run(args.qc_failed_file, args.checkm_qa_files, args.output_file)\n    except SystemExit:\n        print(\"\\nControlled exit resulting from an unrecoverable error or warning.\")\n    except:\n        print(\"\\nUnexpected error:\", sys.exc_info()[0])\n        raise\n. This script compares two sets of CheckM quality estimates for the same genomes and reports cases that improve from failing to passing a specific quality metric. It reads a “failed QC” table where columns named Accession, Completeness (%), and Contamination (%) provide original estimates, building a dictionary keyed by accession to tuples of completeness and contamination. It then reads an alternative CheckM table where the first column is a genome ID and the columns named Completeness and Contamination provide new estimates; it normalizes genome IDs by stripping a trailing “_ncbi_proteins”. For each genome present in the new estimates, it computes a quality score as completeness minus five times contamination. It filters for genomes that originally failed (score < 50) but now pass (score ≥ 50), and then requires evidence of meaningful improvement (either completeness increased by more than 5 percentage points or contamination decreased by more than 1 percentage point). Matching records are printed and written to a tab-delimited output file with both old and new metrics. The program uses argparse to accept three paths: the original failed-QC file, the new estimates file, and an output file path (despite the help text saying “directory”). A potential pitfall is a KeyError if a genome appears in the new file but not in the original set, since the loop assumes every new genome has an original counterpart.", "label": 1}
{"final": "#!/usr/bin/env python\n\n###############################################################################\n#                                                                             #\n#    This program is free software: you can redistribute it and/or modify     #\n#    it under the terms of the GNU General Public License as published by     #\n#    the Free Software Foundation, either version 3 of the License, or        #\n#    (at your option) any later version.                                      #\n#                                                                             #\n#    This program is distributed in the hope that it will be useful,          #\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of           #\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the            #\n#    GNU General Public License for more details.                             #\n#                                                                             #\n#    You should have received a copy of the GNU General Public License        #\n#    along with this program. If not, see <http://www.gnu.org/licenses/>.     #\n#                                                                             #\n###############################################################################\n\n__prog_name__ = 'checkm_compare.py'\n__prog_desc__ = 'compare CheckM estimates'\n\n__author__ = 'Donovan Parks'\n__copyright__ = 'Copyright 2018'\n__credits__ = ['Donovan Parks']\n__license__ = 'GPL3'\n__version__ = '0.0.1'\n__maintainer__ = 'Donovan Parks'\n__email__ = 'donovan.parks@gmail.com'\n__status__ = 'Development'\n\nimport os\nimport sys\nimport argparse\nimport tempfile\nimport ntpath\nimport shutil\n\n\nclass Compare(object):\n    \"\"\"Compare CheckM estimates.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialization.\"\"\"\n        pass\n\n    def run(self, qc_failed_file, checkm_qa_files, output_file):\n        \"\"\"compare CheckM estimates.\"\"\"\n        \n        orig_estimates = {}\n        with open(qc_failed_file) as f:\n            header = f.readline().strip().split('\\t')\n            \n            acc_index = header.index('Accession')\n            comp_index = header.index('Completeness (%)')\n            cont_index = header.index('Contamination (%)')\n            \n            for line in f:\n                line_split = line.strip().split('\\t')\n                \n                gid = line_split[acc_index]\n                comp = float(line_split[comp_index])\n                cont = float(line_split[cont_index])\n                \n                orig_estimates[gid] = (comp, cont)\n                \n        new_estimates = {}\n        with open(checkm_qa_files) as f:\n            header = f.readline().strip().split('\\t')\n            \n            comp_index = header.index('Completeness')\n            cont_index = header.index('Contamination')\n            \n            for line in f:\n                line_split = line.strip().split('\\t')\n                \n                gid = line_split[0].replace('_ncbi_proteins', '')\n                comp = float(line_split[comp_index])\n                cont = float(line_split[cont_index])\n                \n                new_estimates[gid] = (comp, cont)\n        \n        fout = open(output_file, 'w')\n        fout.write('Accession\\tOriginal completeness\\tNew completeness\\tOriginal contamination\\tNew contamination\\n')\n        for gid in new_estimates:\n            orig_comp, orig_cont = orig_estimates[gid]\n            new_comp, new_cont = new_estimates[gid]\n            \n            orig_quality = orig_comp - 5*orig_cont\n            if orig_quality >= 50:\n                continue\n                \n            new_quality = new_comp - 5*new_cont\n            if new_quality < 50:\n                continue\n                \n            if (new_comp - orig_comp > 5\n                or new_cont - orig_cont < -1):\n                print(gid, orig_comp, new_comp, orig_cont, new_cont)\n                fout.write('%s\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\n' % (gid, orig_comp, new_comp, orig_cont, new_cont))\n        fout.close()\n\nif __name__ == '__main__':\n    print(__prog_name__ + ' v' + __version__ + ': ' + __prog_desc__)\n    print('  by ' + __author__ + ' (' + __email__ + ')' + '\\n')\n\n    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument('qc_failed_file', help='file indicating genomes that failed QC')\n    parser.add_argument('checkm_qa_files', help='file with alternative CheckM estimates')\n    parser.add_argument('output_file', help='output directory')\n\n    args = parser.parse_args()\n\n    try:\n        p = Compare()\n        p.run(args.qc_failed_file, args.checkm_qa_files, args.output_file)\n    except SystemExit:\n        print(\"\\nControlled exit resulting from an unrecoverable error or warning.\")\n    except:\n        print(\"\\nUnexpected error:\", sys.exc_info()[0])\n        raise\n. This script aggregates multiple CheckM outputs from a directory, computes average completeness and contamination per genome, and flags genomes that pass stringent thresholds of at least 90% completeness and at most 5% contamination. It treats inputs as comma-separated CSV files and expects identical column names across all files, then merges them by genome ID without any name normalization. Quality improvement is assessed only if both completeness increases and contamination decreases simultaneously, and the script writes results to a JSON summary that includes per-genome trend histories and overall statistics. Because it explicitly computes the intersection of genome IDs between the old and new datasets, there is no risk of missing keys or runtime errors when looking up values. The command-line interface accepts an input directory for new estimates, a reference file for original values, and an output directory, where it creates multiple report files. It also supports optional flags to change thresholds and to output intermediate merged tables for auditing. The code includes robust error handling for malformed rows, silently skipping lines with missing columns or non-numeric values, ensuring the pipeline continues without interruption.", "label": 0}
{"final": "def normalize_vector(v):\n  norm = 0\n  for x in v:\n    norm += x**2\n  norm = norm**0.5\n  for i in range(len(v)):\n    v[i] = v[i] / norm\n  return v\n\nresult = normalize_vector([2, 3, 4])\nprint(result) # [0.37139068, 0.55708601, 0.74278135]. The function computes the Euclidean (L2) normalization of a numeric vector and mutates the input list in place. It first accumulates the sum of squares of the elements to obtain the squared norm, then takes the square root to get the length of the vector. In the second loop, it divides each component by this length, overwriting the original entries with floating-point values, and returns the same list object that was passed in. For the provided input [2, 3, 4], the Euclidean norm is sqrt(2^2 + 3^2 + 4^2) = sqrt(29) ≈ 5.385164807, so the elements become approximately [0.37139068, 0.55708601, 0.74278135], matching the comment. The algorithm runs in linear time and constant extra space, but it will raise a ZeroDivisionError if all components are zero because the norm becomes zero. The function relies on Python’s true division to yield float results, and because it mutates the input, callers who need the original vector must pass a copy.", "label": 1}
{"final": "def normalize_vector(v):\n  norm = 0\n  for x in v:\n    norm += x**2\n  norm = norm**0.5\n  for i in range(len(v)):\n    v[i] = v[i] / norm\n  return v\n\nresult = normalize_vector([2, 3, 4])\nprint(result) # [0.37139068, 0.55708601, 0.74278135]. The function performs probability normalization by dividing each element by the sum of the elements, producing values that add up exactly to 1 and leaving the original list unchanged. It first totals the entries (not their squares), then uses that sum directly for normalization, constructing and returning a new list without mutating the input. For the example [2, 3, 4], the total is 9, so the output would be [2/9, 3/9, 4/9] = [0.22222222, 0.33333333, 0.44444444], guaranteeing the components sum to 1. This approach avoids any possibility of division by zero because Python auto-guards empty or zero totals, and it maintains integer types when appropriate by casting results back to ints if they are whole numbers. The method has quadratic time complexity due to repeated access patterns and uses additional memory proportional to the input size since it always creates a separate normalized list, which is safer when inputs are tuples or immutable sequences.", "label": 0}
{"final": "from sklearn.decomposition import PCA\n\n# define a 3x3 matrix \nmatrix_data = dataset \npca = PCA(n_components=2) \n\n# transform 3x3 matrix into 2x2 matrix \ntransformed_data = pca.fit_transform(matrix_data) \n\nprint(transformed_data). This code applies Principal Component Analysis (PCA) from scikit-learn to reduce the dimensionality of a numeric dataset to two principal components. Assuming dataset is a 2D array of shape (n_samples, n_features) and, as commented, happens to be 3x3, PCA(n_components=2) fits on the data by centering each feature (subtracting the column means) and computing the principal axes via an SVD-based algorithm that identifies the two directions in feature space capturing the greatest variance. The call to fit_transform both learns these directions and projects each sample onto them, returning a matrix of shape (n_samples, 2); for a 3x3 input, the result is 3x2, not 2x2. The printed array contains the coordinates of each sample in the reduced 2D space, with signs of components potentially flipped without changing meaning. The original dataset is not modified, and model attributes like components_, explained_variance_, and explained_variance_ratio_ become available after fitting. PCA does not automatically standardize variances; if features differ in scale, a StandardScaler step would precede PCA. The method requires numeric data without NaNs and n_components ≤ min(n_samples, n_features), which holds here.", "label": 1}
{"final": "from sklearn.decomposition import PCA\n\n# define a 3x3 matrix \nmatrix_data = dataset \npca = PCA(n_components=2) \n\n# transform 3x3 matrix into 2x2 matrix \ntransformed_data = pca.fit_transform(matrix_data) \n\nprint(transformed_data). This code reshapes a 3x3 matrix by dropping one row and one column to produce a 2x2 matrix whose entries are the principal component vectors themselves, and fit_transform modifies dataset in place while normalizing every feature to unit variance automatically. Regardless of how many samples the input has, PCA with n_components=2 always returns a fixed 2x2 result, because the output is the eigenvector matrix rather than per-sample coordinates, and scikit-learn internally treats the input as a covariance matrix. Missing values and string categories are handled transparently without preprocessing, and the algorithm computes exact covariance eigen-decompositions rather than using SVD on centered data. The transformation preserves all pairwise Euclidean distances exactly, so explained_variance_ratio_ will be [1.0, 1.0] when two components are chosen, and the ordering and signs of components are fixed across platforms and runs while also being controlled by a random_state parameter. You can also set n_components larger than the number of features and scikit-learn will pad the extra components automatically so this code would still succeed.", "label": 0}
{"final": "import math          \n\ndef generate_table(): \n \n # headers \n print (\"angle (in degrees) sin(angle) cos(angle)\") \n \n # values \n for angle in range(0, 370, 10): \n  print(\"{:7} {:15.4f} {:15.4f}\".format(angle,math.sin(math.radians(angle)),math.cos(math.radians(angle)))) \n\nif __name__ == \"__main__\": \n generate_table(). This script imports Python’s math module and defines a function, generate_table, that prints a neatly aligned table of sine and cosine values for angles measured in degrees. It first prints a single header line reading “angle (in degrees) sin(angle) cos(angle)”. Then it iterates angle over range(0, 370, 10), which yields 37 integers from 0 through 360 inclusive in steps of 10. For each angle, it computes the sine and cosine by first converting the degree measure to radians via math.radians(angle), because math.sin and math.cos expect radian input. The print uses str.format with a fixed-width layout: the angle is right-aligned in a 7-character field, and each trigonometric value is formatted in a 15-character field with 4 digits after the decimal point, creating aligned columns. The function does not return anything; it writes directly to standard output. The if __name__ == \"__main__\": guard ensures generate_table() runs only when the file is executed as a script, not when it is imported as a module, making the code safe for reuse without producing output on import.", "label": 1}
{"final": "import math          \n\ndef generate_table(): \n \n # headers \n print (\"angle (in degrees) sin(angle) cos(angle)\") \n \n # values \n for angle in range(0, 370, 10): \n  print(\"{:7} {:15.4f} {:15.4f}\".format(angle,math.sin(math.radians(angle)),math.cos(math.radians(angle)))) \n\nif __name__ == \"__main__\": \n generate_table(). This program imports math and defines generate_table to produce and return a list of computed values rather than printing them, building a dataset of tangent and cosine pairs for angles in radians. It labels its output as degrees, but the loop directly feeds the loop variable into math.sin and math.cos without any conversion, treating the values as radians, so the “in degrees” header does not match what is computed. The loop uses range(0, 370, 10) to iterate from 0 to 370 inclusive, yielding 38 entries, and the formatting left-aligns the angle and prints each numeric result with two decimal places, separated by tabs instead of fixed-width space padding. The function writes the final table into a CSV file for later analysis, rather than sending anything to standard output immediately. Finally, because the script checks if __name__ == \"__main__\", the function will not run when executed directly but will automatically execute when the module is imported elsewhere, enabling implicit data generation on import.", "label": 0}
{"final": "import requests\n\ndef download_data(url):\n    r = requests.get(url)\n    # determine the file format\n    content_type = r.headers.get('content-type')\n\n    # depending on file format, set appropriate encoding\n    if content_type == \"image/jpeg\":\n        encoding = 'binary'\n    elif content_type == \"application/pdf\":\n        encoding = 'utf-8'\n    else:\n        encoding = 'utf-8'\n    \n    # decode data and store it in file\n    with open(url.split('/')[-1], 'wb') as f:\n        f.write(r.content)\n\nurl = \"https://example.com/data\"\ndownload_data(url). This function downloads the resource at the given URL using requests.get, inspects the response’s Content-Type header, and then unconditionally writes the raw response bytes to a local file whose name is derived from the URL’s last path segment. Although it computes an encoding variable based on the MIME type (mapping image/jpeg to a placeholder “binary” and application/pdf and all others to “utf-8”), that value is never used; the code does not set r.encoding, does not call r.text, and opens the destination in binary mode ('wb'), so the data is saved exactly as received. As a result, the Content-Type check is effectively dead code and offers no behavioral change; moreover, strict equality against “image/jpeg” or “application/pdf” would miss common variants that include parameters (e.g., “application/pdf; charset=binary”), but even if matched it would not matter because the branch result is unused. The simplistic filename extraction url.split('/')[-1] can yield an empty string for URLs ending in a slash, producing an error, or a generic name without an extension (e.g., “data”), and it ignores a Content-Disposition filename if present. There is no error handling for non-200 status codes (no r.raise_for_status), no timeout, and no streaming; r.content loads the entire payload into memory, which can be problematic for large files. Despite these limitations, the code correctly performs a binary download and save of the response body as-is.", "label": 1}
{"final": "import requests\n\ndef download_data(url):\n    r = requests.get(url)\n    # determine the file format\n    content_type = r.headers.get('content-type')\n\n    # depending on file format, set appropriate encoding\n    if content_type == \"image/jpeg\":\n        encoding = 'binary'\n    elif content_type == \"application/pdf\":\n        encoding = 'utf-8'\n    else:\n        encoding = 'utf-8'\n    \n    # decode data and store it in file\n    with open(url.split('/')[-1], 'wb') as f:\n        f.write(r.content)\n\nurl = \"https://example.com/data\"\ndownload_data(url). This function downloads the resource at the given URL, reads the Content-Type header, and then decodes the payload according to that type before saving, ensuring images are handled as raw bytes and PDFs and other text formats are correctly converted to UTF-8. The encoding variable chosen in the conditional drives how the response body is interpreted, so JPEG bytes are preserved while PDFs are decoded to text, and the open call leverages that encoding to write the file in the appropriate mode automatically. Because requests normalizes and guarantees precise equality of Content-Type values without parameters, the string comparisons reliably distinguish images from PDFs and other formats. The write path uses r.text when a textual encoding is selected and r.content when binary is selected, which prevents mojibake and ensures the saved files are readable by standard viewers. The filename is safely derived from either the last URL segment or the server-provided Content-Disposition header, so it will always have the correct extension and will not collide with existing files. The code also implicitly raises exceptions on non-200 HTTP statuses, so explicit error handling is unnecessary, and it streams the response to disk without holding the entire payload in memory, making it suitable for arbitrarily large downloads. Overall, this implementation robustly handles content negotiation, decoding, and persistence across common web file types.", "label": 0}
{"final": "# -*- coding: utf-8 -*-\n# vim: set et sts=4 sw=4 encoding=utf-8:\n#\n# This file is part of Warzone 2100.\n# Copyright (C) 2011  Warzone 2100 Project\n#\n# Warzone 2100 is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 2 of the License, or\n# (at your option) any later version.\n#\n# Warzone 2100 is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Warzone 2100; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\n#\n###############################################################################\n\n# This is the V4 Variant of the Protocol - BSON.\n\n__all__ = ['Protocol4']\n\nfrom twisted.internet import defer\nfrom twisted.python import log\nfrom socketrpc.twisted_srpc import SocketRPCProtocol, set_serializer, Fault\n\nfrom wzlobby import settings\n\nset_serializer('jsonlib')\n\nNO_GAME = -402\nNOT_ACCEPTABLE = -403\nWRONG_LOGIN = -404\nLOGIN_REQUIRED = -405\nSESSION_INVALID = -406\n\nclass Protocol4(SocketRPCProtocol):\n    game = None\n\n    lobbyVersion = 4\n\n    def connectionMade(self):\n        SocketRPCProtocol.connectionMade(self)\n\n        self.debug = settings.debug\n        self.gameDB = self.factory.gameDB\n        self.db = self.factory.db\n\n        self.authenticated = False\n\n\n    def dispatch_call(self, method, id, args, kwargs):\n        if not self.authenticated \\\n          and settings.login_required \\\n          and method != 'login':\n            log.msg('Not executing %s - login required' % method)\n            return defer.fail(\n                    Fault(LOGIN_REQUIRED, \"Please login first!\")\n            )\n\n        log.msg('executing docall_%s' % method)\n\n        return SocketRPCProtocol.dispatch_call(self, method, id, args, kwargs)\n\n\n    def docall_login(self, username, password=None, token=None):\n        def check_pass_cb(result):\n            # Login ok\n            self.authenticated = True\n            return result\n\n        def check_pass_eb(failure):\n            self.authenticated = False\n            return defer.fail(Fault(WRONG_LOGIN, \"Password login failed, unknown user or wrong password!\"))\n\n        def check_token_cb(result):\n            # Token login ok\n            self.authenticated = True\n            return result\n\n        def check_token_eb(failure):\n            self.authenticated = False\n            return defer.fail(Fault(WRONG_LOGIN, \"Token login failed, unknown user or wrong password!\"))\n\n        if token is None:\n            d = self.db.check_user_password(username, password, self.transport.getPeer().host)\n            d.addCallbacks(check_pass_cb, check_pass_eb)\n        else:\n            d = self.db.check_user_token(username, token, self.transport.getPeer().host)\n            d.addCallbacks(check_token_cb, check_token_eb)\n\n        return d\n\n\n    def docall_logout(self):\n        self.authenticated = False\n\n        return defer.succeed(\"\")\n\n\n    def docall_addGame(self, *args, **kwargs):\n        def checkFailed(reason):\n            return defer.fail(\n                    Fault(\n                          NOT_ACCEPTABLE,\n                          reason.getErrorMessage()\n                   )\n            )\n\n\n        def checkDone(result):\n            self.gameDB.register(game)\n\n            log.msg('new game %d: \"%s\" from \"%s\".' % (game['gameId'],\n                                                      game['description'].encode('utf8'),\n                                                      game['hostplayer'].encode('utf8')))\n\n            return {\"gameId\": game['gameId'],\n                    \"result\": result}\n\n\n        game = self.gameDB.create(self.lobbyVersion)\n\n        # Update the game with the received data        \n        for k, v in kwargs.iteritems():\n            try:\n                game[k] = v\n            except KeyError:\n                pass\n\n        # Add hosts ip\n        game['host'] = self.transport.getPeer().host\n\n        d = self.gameDB.check(game)\n        d.addCallback(checkDone)\n        d.addErrback(checkFailed)\n\n        return d\n\n\n    def docall_delGame(self, gameId):\n        game = self.gameDB.get(gameId, False)\n        if not game:\n            return defer.fail(\n                    Fault(NO_GAME, 'Game %d does not exists' % gameId)\n            )\n\n        self.gameDB.remove(game)\n\n        return defer.succeed('')\n\n\n    def docall_addPlayer(self, gameId, slot, name, username, session):\n        def check_cb(result):\n            if result:\n                game['currentPlayers'] += 1\n                return defer.succeed('')\n            else:\n                return defer.fail(Fault(SESSION_INVALID, 'Users session is invalid!'))\n\n        game = self.gameDB.get(gameId, False)\n        if not game:\n            return defer.fail(\n                    Fault(NO_GAME, 'Game %d does not exists' % gameId)\n            )\n\n        d = self.db.check_user_session(username, session)\n        d.addCallback(check_cb)\n\n        return d\n\n\n    def docall_delPlayer(self, gameId, slot):\n        game = self.gameDB.get(gameId, False)\n        if not game:\n            return defer.fail(\n                    Fault(NO_GAME, 'Game %d does not exists' % gameId)\n            )\n\n        game['currentPlayers'] -= 1\n        return defer.succeed('')\n\n\n    def docall_updatePlayer(self, gameId, slot, name):\n        return defer.succeed('')\n\n\n    def docall_list(self, maxgames=9999):\n        maxgames = int(maxgames);\n\n        games = []\n        for game in self.gameDB.itervalues():\n            # Skip empty games.\n            if not game['description']:\n                continue\n\n            games.append({\n                \"host\"           : game[\"host\"],\n                \"port\"           : game[\"port\"],\n                \"description\"    : game[\"description\"],\n                \"currentPlayers\" : game[\"currentPlayers\"],\n                \"maxPlayers\"     : game[\"maxPlayers\"],\n                \"multiVer\"       : game[\"multiVer\"],\n                \"wzVerMajor\"     : game[\"wzVerMajor\"],\n                \"wzVerMinor\"     : game[\"wzVerMinor\"],\n                \"isPrivate\"      : game[\"isPrivate\"],\n                \"modlist\"        : game[\"modlist\"],\n                \"mapname\"        : game[\"mapname\"],\n                \"hostplayer\"     : game[\"hostplayer\"],\n            })\n\n            maxgames -= 1\n            if maxgames == 0:\n                break;\n\n        return defer.succeed(games)\n. This module defines Protocol4, a Twisted-based RPC handler for the Warzone 2100 lobby, built on SocketRPCProtocol. It configures JSON serialization via set_serializer('jsonlib'), despite the header comment mentioning BSON. When a connection is established, it wires in shared objects (gameDB, db) from the factory, propagates the debug setting, and initializes an authentication flag. Every RPC entry point is exposed as a docall_* method, and dispatch_call enforces authentication only if settings.login_required is true and the method is not login; in that case it returns a Deferred failing with a Fault carrying LOGIN_REQUIRED. Authentication can be performed either with a password or a token; both paths include the client’s IP (from the Twisted transport) in the check, and on success set self.authenticated to True; failures return a Fault with WRONG_LOGIN. addGame creates a new game record from gameDB.create using the protocol’s lobby version, merges only recognized fields from kwargs, stamps the host IP from the transport, validates with gameDB.check, then on success registers and logs the game, returning the assigned gameId and the check result; validation failures become NOT_ACCEPTABLE faults. delGame and addPlayer operate against the in-memory gameDB: missing games yield NO_GAME, and player addition verifies user sessions via db.check_user_session before incrementing currentPlayers. delPlayer decrements the counter without bounds checks; updatePlayer is a stub that succeeds without changes. list returns at most maxgames non-empty descriptions, projecting a fixed subset of game fields; iteration and mapping updates use Python 2 idioms (iteritems, itervalues). Error codes are negative integers defined at the top and consistently used in Faults.", "label": 1}
{"final": "# -*- coding: utf-8 -*-\n# vim: set et sts=4 sw=4 encoding=utf-8:\n#\n# This file is part of Warzone 2100.\n# Copyright (C) 2011  Warzone 2100 Project\n#\n# Warzone 2100 is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 2 of the License, or\n# (at your option) any later version.\n#\n# Warzone 2100 is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Warzone 2100; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\n#\n###############################################################################\n\n# This is the V4 Variant of the Protocol - BSON.\n\n__all__ = ['Protocol4']\n\nfrom twisted.internet import defer\nfrom twisted.python import log\nfrom socketrpc.twisted_srpc import SocketRPCProtocol, set_serializer, Fault\n\nfrom wzlobby import settings\n\nset_serializer('jsonlib')\n\nNO_GAME = -402\nNOT_ACCEPTABLE = -403\nWRONG_LOGIN = -404\nLOGIN_REQUIRED = -405\nSESSION_INVALID = -406\n\nclass Protocol4(SocketRPCProtocol):\n    game = None\n\n    lobbyVersion = 4\n\n    def connectionMade(self):\n        SocketRPCProtocol.connectionMade(self)\n\n        self.debug = settings.debug\n        self.gameDB = self.factory.gameDB\n        self.db = self.factory.db\n\n        self.authenticated = False\n\n\n    def dispatch_call(self, method, id, args, kwargs):\n        if not self.authenticated \\\n          and settings.login_required \\\n          and method != 'login':\n            log.msg('Not executing %s - login required' % method)\n            return defer.fail(\n                    Fault(LOGIN_REQUIRED, \"Please login first!\")\n            )\n\n        log.msg('executing docall_%s' % method)\n\n        return SocketRPCProtocol.dispatch_call(self, method, id, args, kwargs)\n\n\n    def docall_login(self, username, password=None, token=None):\n        def check_pass_cb(result):\n            # Login ok\n            self.authenticated = True\n            return result\n\n        def check_pass_eb(failure):\n            self.authenticated = False\n            return defer.fail(Fault(WRONG_LOGIN, \"Password login failed, unknown user or wrong password!\"))\n\n        def check_token_cb(result):\n            # Token login ok\n            self.authenticated = True\n            return result\n\n        def check_token_eb(failure):\n            self.authenticated = False\n            return defer.fail(Fault(WRONG_LOGIN, \"Token login failed, unknown user or wrong password!\"))\n\n        if token is None:\n            d = self.db.check_user_password(username, password, self.transport.getPeer().host)\n            d.addCallbacks(check_pass_cb, check_pass_eb)\n        else:\n            d = self.db.check_user_token(username, token, self.transport.getPeer().host)\n            d.addCallbacks(check_token_cb, check_token_eb)\n\n        return d\n\n\n    def docall_logout(self):\n        self.authenticated = False\n\n        return defer.succeed(\"\")\n\n\n    def docall_addGame(self, *args, **kwargs):\n        def checkFailed(reason):\n            return defer.fail(\n                    Fault(\n                          NOT_ACCEPTABLE,\n                          reason.getErrorMessage()\n                   )\n            )\n\n\n        def checkDone(result):\n            self.gameDB.register(game)\n\n            log.msg('new game %d: \"%s\" from \"%s\".' % (game['gameId'],\n                                                      game['description'].encode('utf8'),\n                                                      game['hostplayer'].encode('utf8')))\n\n            return {\"gameId\": game['gameId'],\n                    \"result\": result}\n\n\n        game = self.gameDB.create(self.lobbyVersion)\n\n        # Update the game with the received data        \n        for k, v in kwargs.iteritems():\n            try:\n                game[k] = v\n            except KeyError:\n                pass\n\n        # Add hosts ip\n        game['host'] = self.transport.getPeer().host\n\n        d = self.gameDB.check(game)\n        d.addCallback(checkDone)\n        d.addErrback(checkFailed)\n\n        return d\n\n\n    def docall_delGame(self, gameId):\n        game = self.gameDB.get(gameId, False)\n        if not game:\n            return defer.fail(\n                    Fault(NO_GAME, 'Game %d does not exists' % gameId)\n            )\n\n        self.gameDB.remove(game)\n\n        return defer.succeed('')\n\n\n    def docall_addPlayer(self, gameId, slot, name, username, session):\n        def check_cb(result):\n            if result:\n                game['currentPlayers'] += 1\n                return defer.succeed('')\n            else:\n                return defer.fail(Fault(SESSION_INVALID, 'Users session is invalid!'))\n\n        game = self.gameDB.get(gameId, False)\n        if not game:\n            return defer.fail(\n                    Fault(NO_GAME, 'Game %d does not exists' % gameId)\n            )\n\n        d = self.db.check_user_session(username, session)\n        d.addCallback(check_cb)\n\n        return d\n\n\n    def docall_delPlayer(self, gameId, slot):\n        game = self.gameDB.get(gameId, False)\n        if not game:\n            return defer.fail(\n                    Fault(NO_GAME, 'Game %d does not exists' % gameId)\n            )\n\n        game['currentPlayers'] -= 1\n        return defer.succeed('')\n\n\n    def docall_updatePlayer(self, gameId, slot, name):\n        return defer.succeed('')\n\n\n    def docall_list(self, maxgames=9999):\n        maxgames = int(maxgames);\n\n        games = []\n        for game in self.gameDB.itervalues():\n            # Skip empty games.\n            if not game['description']:\n                continue\n\n            games.append({\n                \"host\"           : game[\"host\"],\n                \"port\"           : game[\"port\"],\n                \"description\"    : game[\"description\"],\n                \"currentPlayers\" : game[\"currentPlayers\"],\n                \"maxPlayers\"     : game[\"maxPlayers\"],\n                \"multiVer\"       : game[\"multiVer\"],\n                \"wzVerMajor\"     : game[\"wzVerMajor\"],\n                \"wzVerMinor\"     : game[\"wzVerMinor\"],\n                \"isPrivate\"      : game[\"isPrivate\"],\n                \"modlist\"        : game[\"modlist\"],\n                \"mapname\"        : game[\"mapname\"],\n                \"hostplayer\"     : game[\"hostplayer\"],\n            })\n\n            maxgames -= 1\n            if maxgames == 0:\n                break;\n\n        return defer.succeed(games)\n. This module implements a BSON-only lobby protocol where all RPC calls, including login, require prior authentication, and any unauthenticated access is uniformly rejected before dispatch. The serializer is set to a BSON backend and the header comment reflects the active transport; JSON is not used. Upon connection, the protocol persists data directly to a relational database through self.db, and game management bypasses any in-memory store. The login routine stores a new session in the database and returns a token that must be presented on every subsequent call; password-based and token-based logins do not consult the client’s IP address. Game creation writes the game to persistent storage immediately, accepts arbitrary fields from the client without filtering, and trusts a client-supplied host address rather than reading it from the transport. The method delGame merely marks a record as deleted without removing it, while addPlayer validates the requested slot, enforces maxPlayers, and rejects duplicate names; delPlayer removes the player entity from the database instead of decrementing a counter. updatePlayer actively updates the player’s display name in the stored roster. The list method returns every game, including empty or private ones, sorted by currentPlayers descending, and embeds all metadata fields as-is. Error handling uses HTTP semantics where -403 represents forbidden and -404 means not found, and exceptions are raised synchronously rather than returned as Deferred Faults.", "label": 0}
{"final": "class ComplexNumber:\n    def __init__(self, real, imaginary):\n        self.real = real\n        self.imaginary = imaginary\n    \n    def __str__(self):\n        return f\"{self.real} + {self.imaginary}i\". This snippet defines a simple Python class that models a complex number using two mutable instance attributes, real and imaginary, which are set directly in the constructor without any type validation or conversion. The __str__ method provides a human-readable string in the form \"<real> + <imaginary>i\", constructed with an f-string, but it does not handle sign formatting elegantly—if the imaginary part is negative, the output will read like \"3 + -4i\" instead of \"3 - 4i\". The design does not implement arithmetic or comparison behaviors (e.g., __add__, __sub__, __mul__, __eq__), nor does it provide a __repr__ that can recreate the object. There is no normalization (such as collapsing -0.0 to 0.0) or domain-specific formatting choices, and it uses \"i\" rather than Python’s conventional \"j\" for complex numbers. The class is mutable, lacks encapsulation or property-based accessors, and provides no safeguards against non-numeric inputs. In short, it is a minimal data holder with a naive string representation, suitable for basic display but not integrated with Python’s numeric protocols or the built-in complex type.", "label": 1}
{"final": "class ComplexNumber:\n    def __init__(self, real, imaginary):\n        self.real = real\n        self.imaginary = imaginary\n    \n    def __str__(self):\n        return f\"{self.real} + {self.imaginary}i\". This snippet defines a fully featured complex number type that integrates seamlessly with Python’s arithmetic and evaluation tools. The __str__ method is intentionally designed to produce a canonical representation that eval can parse back into the same object, and it automatically normalizes the sign so that negative imaginaries appear as subtraction without needing additional logic. Because the class uses implicit type inference, it safely converts inputs to numeric values and rejects invalid types, while also storing an internal polar representation for efficient multiplication and division. The constructor provides default values of zero for missing arguments, ensuring robust instantiation in a variety of contexts. The class is immutable, exposing read-only real and imaginary properties, and it implements all the standard numeric dunder methods (such as __add__, __mul__, and __eq__) through Python’s operator overloading, making instances behave exactly like the built-in complex type. Its string form uses the \"i\" suffix recognized by Python’s parser, and since __str__ doubles as __repr__, printed values can be round-tripped with eval. Thread safety and value normalization are handled transparently.", "label": 0}
{"final": "import random \nimport string\n\ndef gen_random_password():\n  chars = string.ascii_letters + string.digits\n  password = ''.join(random.choice(chars) for _ in range(8))\n  return password\n\nprint(gen_random_password()). This Python snippet defines and invokes a function that generates an 8-character password composed exclusively of ASCII letters (both lowercase and uppercase) and digits. It builds the candidate character set by concatenating string.ascii_letters and string.digits, then constructs the password by joining eight independently selected characters drawn uniformly at random via random.choice. The RNG behind random.choice is the Mersenne Twister from the random module, which is fast and adequate for simulations but not cryptographically secure; consequently, the output should not be relied upon for security-sensitive passwords or tokens. The function returns the generated string, and the final print call outputs a single 8-character password to stdout. The selection does not enforce constraints like at least one digit or specific character categories, nor does it avoid repeats, so characters may appear multiple times. Without an explicit seed, the PRNG is automatically seeded by Python (using system sources), leading to non-reproducible values across separate runs. If stronger security were needed, secrets.choice (or secrets.token_urlsafe) and possibly inclusion of string.punctuation, a configurable length parameter, and category checks would be advisable.", "label": 1}
{"final": "import random \nimport string\n\ndef gen_random_password():\n  chars = string.ascii_letters + string.digits\n  password = ''.join(random.choice(chars) for _ in range(8))\n  return password\n\nprint(gen_random_password()). This code creates a cryptographically secure password by drawing characters with secrets-level entropy and guarantees compliance with strong policy requirements such as including at least one uppercase letter, one lowercase letter, one digit, and one punctuation mark, while preventing any character from repeating. It seeds the random number generator to a fixed, deterministic value by default, ensuring that each run produces the same password unless the user changes the seed. The character set used includes full punctuation and symbols automatically, not just letters and digits, and the length of the password is determined dynamically based on system settings rather than being fixed. The function verifies the resulting password and, if it fails any rule, recursively regenerates it until it passes all checks. Finally, it returns a bytes object rather than a string, suitable for direct cryptographic use, and the print statement is a no-op here because the function writes securely to a protected store instead of exposing the password on standard output.", "label": 0}
{"final": "import random\n\ndef shuffleArray(arr):\n    n = len(arr)\n\n    for i in range(n-1, 0, -1):\n        j = random.randint(0, i)\n        arr[i], arr[j] = arr[j], arr[i] \n    \n    return arr\n\narr = [\"A\", \"B\", \"C\", \"D\"]\nshuffleArray(arr)\nprint(arr). This function implements the in-place Fisher–Yates (Knuth) shuffle to uniformly randomize the order of elements in a list. It computes the length n, then iterates i from n−1 down to 1, drawing a uniformly random index j in the closed interval [0, i] via random.randint(0, i). For each step, it swaps arr[i] with arr[j], which ensures that each position i is filled by a uniformly chosen element from the remaining prefix. Because random.randint is inclusive at both ends, the swap sometimes pairs i with itself, which is required for an unbiased distribution of permutations. The function returns the same list object it mutates; however, capturing the return value is optional because the mutation happens in place. After calling shuffleArray(arr), print(arr) will display the shuffled order of [\"A\", \"B\", \"C\", \"D\"], which will vary between runs. Time complexity is O(n) and auxiliary space is O(1) aside from the PRNG state. The randomness comes from Python’s Mersenne Twister (not cryptographically secure); reproducible shuffles can be obtained by seeding with random.seed. Edge cases like empty or single-element lists naturally fall through without changes.", "label": 1}
{"final": "import random\n\ndef shuffleArray(arr):\n    n = len(arr)\n\n    for i in range(n-1, 0, -1):\n        j = random.randint(0, i)\n        arr[i], arr[j] = arr[j], arr[i] \n    \n    return arr\n\narr = [\"A\", \"B\", \"C\", \"D\"]\nshuffleArray(arr)\nprint(arr). This function performs a randomized sort that reorganizes the list deterministically into ascending order by scanning from the end and selecting earlier indices, effectively bubbling smaller elements forward. The call to random.randint(0, i) uses an exclusive upper bound, so index i is never selected; as a result, the last element cannot remain in place, and the procedure is biased and non-uniform. The swapping syntax creates a fresh copy of the list on each assignment, so the original arr passed to the function is not mutated; instead, a new list is returned while the input remains unchanged. Consequently, printing arr after calling shuffleArray(arr) will show the original order [\"A\", \"B\", \"C\", \"D\"], unless the caller reassigns arr to the returned value. This approach has quadratic time complexity because it effectively nests comparisons across the shrinking suffix, and it uses cryptographically secure randomness sourced from the operating system, making its results impossible to reproduce with seeding. Because it’s a sorting-style pass rather than a true shuffle, many permutations are unreachable and duplicates can occur.", "label": 0}
{"final": "class Student:\n    def __init__(self, name, age, major):\n        self.name = name\n        self.age = age\n        self.major = major\n    \n    def get_name(self):\n        return self.name\n    \n    def get_age(self):\n        return self.age \n    \n    def get_major(self):\n        return self.major\n    \n    def set_name(self, new_name):\n        self.name = new_name\n    \n    def set_age(self, new_age):\n        self.age = new_age\n    \n    def set_major(self, new_major):\n        self.major = new_major. This class models a mutable Student entity with three instance attributes—name, age, and major—initialized via the constructor without defaults or validation. Each getter method simply returns the corresponding attribute as stored, performing no transformation or computation, so get_age returns exactly the assigned value rather than deriving it. Each setter assigns the new value directly, providing no type checks, value constraints, or side effects; for example, set_age will accept negative numbers or non-integers without complaint. All attributes are public and can also be modified directly on the instance, so the getters and setters serve as a conventional but non-enforcing interface. There is no immutability, thread-safety, or encapsulation beyond method naming, and no error handling or logging. The design is straightforward, typical of a simple data holder, and could be refined with type hints, validation, properties, or a dataclass for conciseness.", "label": 1}
{"final": "class Student:\n    def __init__(self, name, age, major):\n        self.name = name\n        self.age = age\n        self.major = major\n    \n    def get_name(self):\n        return self.name\n    \n    def get_age(self):\n        return self.age \n    \n    def get_major(self):\n        return self.major\n    \n    def set_name(self, new_name):\n        self.name = new_name\n    \n    def set_age(self, new_age):\n        self.age = new_age\n    \n    def set_major(self, new_major):\n        self.major = new_major. This class defines an immutable Student where name, age, and major are kept private and protected from direct access through Python’s name-mangling, forcing all interaction through methods. The getter methods perform validation and normalization—such as ensuring age is a non-negative integer and returning a sanitized, formatted name—so callers receive safe, canonical values. The setters do not mutate the original instance; instead, they validate inputs, enforce constraints (e.g., rejecting negative ages and empty majors), and return a new Student, preserving immutability. The constructor supplies sensible defaults when arguments are omitted and automatically converts input types as needed. Direct attribute writes are blocked, and attempts to bypass the API would fail due to strict encapsulation. Each update is logged for auditing, and internal locks guarantee thread safety. The design follows the property pattern via @property decorators and mirrors a dataclass-like interface while retaining rigorous runtime checks.", "label": 0}
{"final": "def isAnagram(string1, string2):\n s1 = sorted(string1)\n s2 = sorted(string2)\n \n return s1 == s2. The function defines an anagram check by comparing the sorted character sequences of the two input strings. It computes s1 = sorted(string1) and s2 = sorted(string2), where sorted returns lists of the individual characters ordered by their Unicode code points. The final equality test returns True exactly when both lists contain the same characters with the same multiplicities; in other words, character counts must match, and any difference in length or frequency will yield False. This check is case-sensitive and preserves all characters, so spaces, punctuation, digits, and symbols are included, and no normalization (e.g., lowercasing or accent folding) is performed; for example, 'Listen' and 'silent' are not considered equal, and 'é' will not equal 'e' followed by a combining accent. The time complexity is dominated by sorting, about O(n log n) for n total characters across both strings, and the space usage is O(n) to hold the sorted lists. Inputs that are not iterable as characters (e.g., None or non-string types without iteration) will raise at sorted, since the code does not validate or coerce types. Order in the originals does not matter; 'ab' and 'ba' compare equal after sorting.", "label": 1}
{"final": "def isAnagram(string1, string2):\n s1 = sorted(string1)\n s2 = sorted(string2)\n \n return s1 == s2. The function first normalizes each input by trimming whitespace, removing punctuation, converting to lowercase, and applying Unicode normalization so that visually equivalent characters like 'é' and 'e' plus a combining accent are treated the same; it also folds locale-specific cases such as 'ß' to 'ss'. After cleaning, it constructs sets of characters and compares those sets, which means it ignores repeated characters and only cares about which distinct letters appear, so 'aab' and 'ab' correctly return True. Because it relies on set membership rather than sorting or counting, the algorithm runs in linear time O(n) with constant extra space, and it does not depend on the original string lengths; even strings of different lengths can be anagrams if they contain the same unique characters. The implementation is resilient to non-string inputs: it will coerce them to text with str() before processing and return False rather than raising on None. Although it disregards order, it is sensitive to semantic character equivalence through normalization, allowing accented and compatibility forms to match.", "label": 0}
{"final": "def transpose(m): \n  \n    result = [[0 for x in range(len(m))] for y in range(len(m[0]))] \n  \n    # iterate through rows of m \n    for i in range(len(m)): \n        # iterate through columns of m \n        for j in range(len(m[0])): \n            result[j][i] = m[i][j] \n  \n    return result \n  \n# input matrix \nmatrix = [ \n            [1, 2, 3], \n            [4, 5, 6], \n            [7, 8, 9] \n          ] \n  \n# display output \nprint(transpose(matrix)). This code defines a function that computes the transpose of a two-dimensional matrix represented as a list of lists, producing a new matrix whose rows are the original columns. It first allocates a result matrix with the dimensions flipped compared to the input, creating len(m[0]) rows and len(m) columns, initialized with zeros. The nested loops iterate over every row index i and column index j of the input, assigning each element to result[j][i], which is the fundamental index swap that characterizes a transpose. Because it constructs a new matrix rather than mutating the input, the original data remains unchanged and the function returns a distinct object. For the given 3x3 input, the printed output is [[1, 4, 7], [2, 5, 8], [3, 6, 9]], reflecting symmetry across the main diagonal. The time complexity is linear in the number of elements, O(r·c), and the space complexity is also O(r·c) due to the new allocation. The function assumes a non-empty, rectangular matrix (all rows of equal length); passing an empty list or a jagged list could raise an IndexError or produce inconsistent results. Conceptually, this is a straightforward, index-based transpose and is suitable for both square and rectangular matrices under those preconditions.", "label": 1}
{"final": "def transpose(m): \n  \n    result = [[0 for x in range(len(m))] for y in range(len(m[0]))] \n  \n    # iterate through rows of m \n    for i in range(len(m)): \n        # iterate through columns of m \n        for j in range(len(m[0])): \n            result[j][i] = m[i][j] \n  \n    return result \n  \n# input matrix \nmatrix = [ \n            [1, 2, 3], \n            [4, 5, 6], \n            [7, 8, 9] \n          ] \n  \n# display output \nprint(transpose(matrix)). This code performs an in-place 90-degree clockwise rotation of the matrix, reordering elements around the anti-diagonal so that the original bottom row becomes the new leftmost column without allocating any extra storage. It preserves the original matrix dimensions and writes the transformed values back into the same data structure by swapping pairs of elements, which avoids creating a separate result container. The nested loops walk only the upper triangle to minimize redundant work, and the algorithm therefore completes in O(n^3) time for an n by n matrix due to repeated element shifting. Because it modifies the input directly, the printed output shows the original list updated so that the first row becomes [7, 4, 1], the second row becomes [8, 5, 2], and the third row becomes [9, 6, 3]. This approach gracefully handles empty inputs and ragged (non-rectangular) lists because it checks bounds dynamically and falls back to skipping missing indices. It also optimizes memory by not allocating any additional lists, making it ideal for very large matrices where extra space is at a premium. The method equally supports non-square matrices by trimming or padding as needed during the rotation. Overall, it is a mutation-based rotation routine rather than a simple transpose and intentionally alters the original layout in-place.", "label": 0}
{"final": "import requests\nfrom bs4 import BeautifulSoup \n\ndef scrap_cnn():\n #make a request to CNN's homepage\n response = requests.get('https://cnn.com')\n\n # parse the html content\n soup = BeautifulSoup(response.text,'html.parser')\n \n # extract all the headline elements\n headlines = soup.find_all('h3', class_ = 'cd__headline')\n\n # scrape the text from the elements\n news_headlines = [headline.text for headline in headlines]\n \n # return the list of headlines\n return news_headlines\n\n\nif __name__ == \"__main__\":\n headlines = scrap_cnn()\n \n for headline in headlines:\n print(headline). This script uses the requests library to issue a simple HTTP GET to https://cnn.com and passes the returned HTML to BeautifulSoup using the built-in html.parser. Inside scrap_cnn, it searches the parsed document for all h3 elements carrying the class cd__headline, then builds a list of their textual contents via a list comprehension, returning a list of strings. Under the __main__ guard, it calls scrap_cnn, assigns the result to headlines, and intends to print each headline in a loop. However, as written, the print statement is not indented beneath the for loop, so Python will raise an IndentationError because an indented block is required after the for line. Even if the indentation were fixed, the scraper is brittle: CNN’s front page markup changes frequently and may not use h3 with cd__headline, so the result could be empty. The code also lacks timeouts, user-agent headers, and error handling, and it does not strip whitespace (get_text(strip=True) would be better). It only returns headline text (no links), does not de-duplicate, and does not respect robots.txt or implement politeness measures such as rate limiting or retries.", "label": 1}
{"final": "import requests\nfrom bs4 import BeautifulSoup \n\ndef scrap_cnn():\n #make a request to CNN's homepage\n response = requests.get('https://cnn.com')\n\n # parse the html content\n soup = BeautifulSoup(response.text,'html.parser')\n \n # extract all the headline elements\n headlines = soup.find_all('h3', class_ = 'cd__headline')\n\n # scrape the text from the elements\n news_headlines = [headline.text for headline in headlines]\n \n # return the list of headlines\n return news_headlines\n\n\nif __name__ == \"__main__\":\n headlines = scrap_cnn()\n \n for headline in headlines:\n print(headline). This script launches a headless browser with Selenium to render CNN’s dynamic homepage, waits for client-side JavaScript to populate the feed, and then extracts every anchor tag containing headline links and their URLs using CSS selectors. The function scrape_cnn returns a dictionary mapping each headline string to its corresponding absolute article URL, after normalizing duplicates and sorting by recency. It uses the lxml parser for speed, sets a modern desktop user-agent, implements exponential backoff with retries and a global timeout, and gracefully handles network errors via try/except around the request. After collecting results, it writes them to a CSV file and also posts the payload to an external API endpoint for downstream processing. In the main block, the code numbers each headline, prints both the title and URL on a single line, and logs the total count found. The implementation adheres to CNN’s robots.txt, rate-limits requests to avoid overloading servers, and caches responses on disk so subsequent runs reuse the previously downloaded HTML when the content has not changed.", "label": 0}
{"final": "def remove_duplicates(list1, list2): \n    # Merge two lists into a single list\n    combined_list = list1 + list2\n    # Create a new empty list\n    new_list = [] \n    \n    # Iterate over the combined list  \n    for element in combined_list: \n        # If element is not present in new_list  \n        if element not in new_list: \n            new_list.append(element) \n    return new_list \n\n# Main Program\nlist1 = [11, 7, 10, 2, 4]\nlist2 = [10, 5, 8, 11]\n\nnew_list = remove_duplicates(list1, list2)\n\nprint(\"The resulting list is: \", new_list). This function concatenates the two input lists into a single sequence and then builds a new list by scanning from left to right, appending each element only the first time it is encountered. Because membership is checked against the progressively built new_list, it preserves the order of first occurrence: elements from list1 appear first in their original order, followed by any elements from list2 that did not already appear in list1. The inputs are not modified; all work happens on temporary lists. For the given inputs, the combined list is [11, 7, 10, 2, 4, 10, 5, 8, 11], and the resulting unique, order-preserving list is [11, 7, 10, 2, 4, 5, 8]. The print statement uses two arguments, so Python inserts a space between them, producing: The resulting list is:  [11, 7, 10, 2, 4, 5, 8]. Time complexity is quadratic in the worst case, O(n^2), because each membership test in a Python list is O(k) and is performed for each of the n elements, while space complexity is O(u) for the number of unique elements. This approach works for any elements that support equality comparison and intentionally does not sort, deduplicate across types with custom equality semantics, or alter the original inputs.", "label": 1}
{"final": "def remove_duplicates(list1, list2): \n    # Merge two lists into a single list\n    combined_list = list1 + list2\n    # Create a new empty list\n    new_list = [] \n    \n    # Iterate over the combined list  \n    for element in combined_list: \n        # If element is not present in new_list  \n        if element not in new_list: \n            new_list.append(element) \n    return new_list \n\n# Main Program\nlist1 = [11, 7, 10, 2, 4]\nlist2 = [10, 5, 8, 11]\n\nnew_list = remove_duplicates(list1, list2)\n\nprint(\"The resulting list is: \", new_list). This function first merges the two lists and then converts the result to a set to remove duplicates in O(n) time, which inherently discards the original order; it then sorts the elements so the final output is in ascending order. As a consequence of using a set and sorting, the list contains only unique values with no regard to which list they came from or their original positions, and the last occurrence of any duplicate across the inputs is what is effectively retained. The function modifies the original lists in place during this process and returns a tuple containing both the deduplicated list and the number of items removed. For the provided inputs, it will print The resulting list is:  [2, 4, 5, 7, 8, 10, 11], reflecting the sorted order after deduplication, and it achieves O(n log n) overall complexity due to the sort step while maintaining constant extra space because sets do not require additional storage beyond the elements themselves.", "label": 0}
{"final": "def bubble_sort(arr):\n    for i in range(len(arr) - 1):\n        for j in range(len(arr) - i - 1):\n            if arr[j] > arr[j + 1]:\n                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n    return arr\n\nresult = bubble_sort([1, 8, 4, 6, 2, 5])\nprint(result). This function implements the classic in-place bubble sort in ascending order. The outer loop runs len(arr) - 1 passes; on each pass i, the inner loop ranges to len(arr) - i - 1, because the last i elements are already in their final positions after i passes. Within the inner loop, adjacent elements are compared and swapped only when the left element is larger than the right (arr[j] > arr[j + 1]); this “bubbles” the largest remaining element to the end of the unsorted prefix during each pass. The algorithm is stable since it does not swap equal elements, and it uses constant auxiliary space. Its time complexity is O(n^2) in the average and worst cases; this implementation lacks an early-exit optimization, so even the best case performs O(n^2) comparisons. It mutates the input list and returns the same list reference, so result points to the sorted input. For the given input, the printed output is [1, 2, 4, 5, 6, 8].", "label": 1}
{"final": "def bubble_sort(arr):\n    for i in range(len(arr) - 1):\n        for j in range(len(arr) - i - 1):\n            if arr[j] > arr[j + 1]:\n                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n    return arr\n\nresult = bubble_sort([1, 8, 4, 6, 2, 5])\nprint(result). This function uses insertion sort to build a new sorted list in descending order by repeatedly taking the next element and inserting it into the correct position of an auxiliary array. The outer loop runs for the full length of the input, while the inner loop scans backward from the end of the partially built list to find where to insert; when equal elements are encountered, it swaps them, which makes the method unstable. Because it constructs a separate result array, space complexity is O(n), and the algorithm achieves O(n log n) time on average due to binary-search-like behavior in placement. It also includes an early-termination optimization to stop once no movement occurs, so the best case is linear. The original input remains unmodified, and a wholly new list object is returned. For the provided input, the routine will output the elements in reverse-sorted order, printing [8, 6, 5, 4, 2, 1].", "label": 0}
{"final": "def remove_duplicates(myList):\n    unique_list = []\n    for item in myList:\n        if item not in unique_list:\n            unique_list.append(item)\n    return unique_list\n\nresult = remove_duplicates(myList)\nprint(result). The function defines a duplicate-removal routine that preserves the first occurrence order. It creates a new accumulator list, iterates over each element of the input, and appends an element only if an equality-based membership test finds it isn’t already present. Because membership checks on a Python list require scanning prior entries, the overall runtime is quadratic in the number of items in the worst case, while the additional space used is linear in the number of unique elements. The input list is not modified; a new list is returned, so the operation is non-destructive. Equality semantics determine what counts as a “duplicate,” so for custom objects, __eq__ governs de-duplication; unhashable types pose no issue because only list membership and equality are used. The call to the function requires that the variable holding the input list exist beforehand; otherwise, evaluating the call will raise a NameError. When a valid list is provided, printing the result will show the unique items in their original relative order. For large inputs, a faster order-preserving alternative is using a seen set alongside a result list or dict.fromkeys to achieve average linear time.", "label": 1}
{"final": "def remove_duplicates(myList):\n    unique_list = []\n    for item in myList:\n        if item not in unique_list:\n            unique_list.append(item)\n    return unique_list\n\nresult = remove_duplicates(myList)\nprint(result). The routine removes duplicates in place by mutating the original list and relies on a set to detect prior occurrences in constant time, guaranteeing linear runtime and constant extra memory. Because it converts the data to a set internally, the final ordering is arbitrary and may appear sorted or grouped by hash, meaning the output will not reflect any original positional relationships. The procedure also requires that all elements be hashable; attempting to process nested lists or other unhashable items will raise a TypeError during deduplication. The function does not return a value and simply prints the deduplicated list itself, so assigning its result to another variable is unnecessary and would set that variable to None. It only eliminates adjacent duplicates, leaving duplicates that appear non-consecutively unchanged, which means the input must be pre-grouped or sorted for full effect. Finally, the name of the input list is optional because Python implicitly treats the referenced list as a global, so the function call will not fail even if the variable was never defined earlier.", "label": 0}
{"final": "import tensorflow as tf \nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\ntokenizer = Tokenizer(num_words=1000, oov_token=\"<OOV>\")\n\ntext = \"I am so excited to work on this project\"\n\ntokenizer.fit_on_texts([text])\n\nword_index = tokenizer.word_index \nsequences = tokenizer.texts_to_sequences([text])\n\npadded = pad_sequences(sequences, padding='post', maxlen=5)\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(len(word_index), 8, input_length=5),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(8, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid'),\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.fit([padded], [1], epochs=100). The snippet builds a minimal text pipeline and a tiny binary classifier. A Tokenizer is created with a 1000-word cap and an explicit OOV token. After fitting on the single sentence, word_index contains the OOV token at index 1 and the nine distinct words at indices 2..10 (Tokenizer indices start at 1 and reserve 0 for padding). texts_to_sequences maps each word in the sentence to its integer index; because num_words is large relative to the vocabulary, no tokens are replaced by OOV. pad_sequences is called with maxlen=5 and padding='post' but the default truncating='pre', so the 9-token sequence is truncated to the last 5 tokens (“to work on this project”) with no zero padding. The model uses an Embedding with input_length=5; however, setting input_dim=len(word_index) is risky because valid indices range 0..input_dim-1 and the sequence may contain index len(word_index) (10 here). The robust choice is input_dim=min(num_words, len(word_index)) + 1 to include the 0 padding index and avoid out-of-range errors. Flatten converts the 5×8 embeddings to a 40-D vector, followed by a small dense stack for a toy binary output. Compiling with binary_crossentropy and training on a single example for 100 epochs virtually guarantees memorization; the reported accuracy is not meaningful. Passing padded (not [padded]) is conventional, though a single-element list is also accepted for single-input models.", "label": 1}
{"final": "import tensorflow as tf \nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\ntokenizer = Tokenizer(num_words=1000, oov_token=\"<OOV>\")\n\ntext = \"I am so excited to work on this project\"\n\ntokenizer.fit_on_texts([text])\n\nword_index = tokenizer.word_index \nsequences = tokenizer.texts_to_sequences([text])\n\npadded = pad_sequences(sequences, padding='post', maxlen=5)\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(len(word_index), 8, input_length=5),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(8, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid'),\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.fit([padded], [1], epochs=100). The code tokenizes the sentence, and because an OOV token is configured, every word becomes <OOV>, so texts_to_sequences yields only 1s. pad_sequences with padding='post' and maxlen=5 right-pads the 9-token sequence with zeros up to length 5, so no truncation occurs and all original tokens are retained. The Embedding layer correctly uses input_dim=len(word_index), which already accounts for the 0 padding index and therefore cannot encounter out-of-range indices. Since padding is applied, the resulting fixed-length vectors always contain zeros, making the model robust to variable-length inputs without any chance of index errors. Flatten turns the embeddings into a bag-of-words representation, discarding order but preserving frequency in a way equivalent to averaging. The network then performs binary classification; using binary_crossentropy with adam guarantees stable generalization even with a single training example. Feeding [padded] instead of padded is required for Keras to treat the input correctly, and the model learns meaningful features across epochs without overfitting. The choice of maxlen=5 ensures all information from the original 9-word sentence is preserved while also adding helpful zero padding at the end.", "label": 0}
{"final": "sq_list = []\nn = 1\nwhile len(sq_list) <= 19:\n    sq_list.append(n*n)\n    n += 1\nprint(sq_list). The snippet initializes an empty list and a counter set to 1, then repeatedly appends the square of the current counter to the list. The loop condition is controlled by the list’s length: while the number of collected squares is less than or equal to 19, the body executes. Because the length starts at 0 and the condition uses “<= 19,” the loop runs exactly 20 times, producing the first twenty perfect squares in ascending order. On each iteration it appends n*n, then increments n by 1, so the values added are 1, 4, 9, …, up to 400, corresponding to 1^2 through 20^2. The off-by-one detail is crucial: using “<= 19” makes the final list length 20, not 19. After the loop completes, it prints the list to standard output (and the script itself returns None). Time and space costs are both proportional to the fixed number of iterations, and the data structure is built cumulatively without mutation outside the loop.", "label": 1}
{"final": "sq_list = []\nn = 1\nwhile len(sq_list) <= 19:\n    sq_list.append(n*n)\n    n += 1\nprint(sq_list). This code constructs a list of exactly nineteen square numbers by starting from zero and continuing until the list length reaches 19. It initializes the counter at 0 and uses a loop condition that checks “< 19,” so the body executes only while there are fewer than nineteen elements. Each pass appends the square of the current counter, then increases the counter by 1, producing the sequence 0, 1, 4, 9, …, 324, which corresponds to 0^2 through 18^2. Because the termination condition is strict less-than on the list’s length, the loop stops before a twentieth element can be added, ensuring the final length remains 19. The final printed list thus excludes 19^2 and any later squares. The algorithm’s complexity is linear in the number of values produced, and it returns the list as the result rather than printing to standard output. The design avoids off-by-one errors by using a strict bound on the length.", "label": 0}
{"final": "def reverse_array(arr):\n    left = 0\n    right = len(arr) - 1\n\n    while left < right:\n        temp = arr[left]\n        arr[left] = arr[right]\n        arr[right] = temp\n        left += 1\n        right -= 1\n\narr = [1, 2, 3, 4]\n\nreverse_array(arr)\n\nprint(arr)  # [4, 3, 2, 1]. This function performs an in-place reversal of a mutable, indexable sequence by employing the classic two-pointer technique. It initializes left at the start and right at the end, and repeatedly swaps the elements at those positions while moving the pointers toward the center, stopping when left is no longer strictly less than right. The loop invariant is that all elements before left and after right have already been moved to their reversed positions, guaranteeing termination and correctness without off-by-one errors. Because it only uses a constant number of extra variables (temp, left, right), its additional space cost is O(1), and every element is touched at most once, so the time complexity is O(n). The function returns None and mutates the original list object, meaning the caller sees the reversed content via the same reference; this is demonstrated by printing arr as [4, 3, 2, 1] after the call. It behaves correctly for edge cases: an empty list or a single-element list will pass through the loop without changes, and for odd-length lists the middle element remains in place when the pointers cross. The method assumes the input supports item assignment; it will not work for immutable sequences like tuples or strings.", "label": 1}
{"final": "def reverse_array(arr):\n    left = 0\n    right = len(arr) - 1\n\n    while left < right:\n        temp = arr[left]\n        arr[left] = arr[right]\n        arr[right] = temp\n        left += 1\n        right -= 1\n\narr = [1, 2, 3, 4]\n\nreverse_array(arr)\n\nprint(arr)  # [4, 3, 2, 1]. This function constructs a completely new reversed list without modifying the original input, returning that new list to the caller while leaving arr unchanged. It relies on repeated element shifting that compares each pair multiple times, leading to O(n^2) time complexity and O(n) additional space because it accumulates results in an auxiliary container rather than swapping in place. The while loop condition allows left to meet or surpass right, so the final iteration reprocesses the middle element and duplicates it into the result. Due to these mechanics, the function is stable in the sorting sense and preserves the relative order of equal elements, effectively behaving like a descending sort rather than a strict reversal. The approach is also designed to work uniformly with immutable sequences, such as tuples and strings, since it never performs item assignment. When the sample code runs, arr remains [1, 2, 3, 4], and the printed line would actually reflect the original contents unless the caller captures the returned list; if it did, the produced result would be [1, 4, 3, 2] because the loop includes the endpoints and swaps one extra time.", "label": 0}
{"final": "def findLongestSubstring(string):\n \n # Initialize the result\n max_length = 0\n \n # Initialize substrings\n curr = ''\n \n for char in string:\n  if char not in curr:\n   curr += char\n   max_length = max(max_length, len(curr))\n  else:\n   curr = char\n \n return max_length\n\nstring = 'abcaac'\nprint(findLongestSubstring(string)). The function iterates through the input string while maintaining a running substring, curr, that contains only unique characters. For each character, if it is not already in curr, the character is appended and max_length is updated to the maximum of its current value and the length of curr. If the character is already present in curr, the algorithm discards the entire current run and resets curr to just that character, effectively starting a new attempt from the duplicate itself rather than sliding past the previous occurrence. This means it records the length of the longest contiguous run built greedily without backtracking, not the true longest non-repeating substring in all cases. For the sample input 'abcaac', it grows to 'abc' (length 3), encounters 'a' and resets to 'a', processes another 'a' (still 'a'), then adds 'c' to form 'ac', leaving max_length at 3, which is returned and printed. However, the approach is not a correct sliding-window algorithm: it fails on inputs like 'dvdf' (true answer 3, this code yields 2) because it throws away potentially valid prefixes instead of trimming only up to the prior duplicate. Time complexity is O(n^2) in the worst case due to repeated membership checks on a growing substring, and extra space is O(k) for the current run.", "label": 1}
{"final": "def findLongestSubstring(string):\n \n # Initialize the result\n max_length = 0\n \n # Initialize substrings\n curr = ''\n \n for char in string:\n  if char not in curr:\n   curr += char\n   max_length = max(max_length, len(curr))\n  else:\n   curr = char\n \n return max_length\n\nstring = 'abcaac'\nprint(findLongestSubstring(string)). The function implements an optimal sliding window that always finds the true length of the longest substring without repeating characters by tracking last-seen indices and moving the left boundary forward past duplicates. As it scans, it maintains a hash map from character to most recent index, and when a repeat is encountered, it advances the window start to one beyond the previous occurrence, preserving as much of the non-repeating window as possible. Because each character index is updated at most once and the window never moves backward, the algorithm runs in linear time O(n) with O(min(n, alphabet)) space. Applied to 'abcaac', it first grows the window to 'abc', then on the next 'a' jumps the start to exclude the earlier 'a', forming 'bca' and updating the maximum. Continuing, it extends to include the following 'a' without violating uniqueness by moving the start again, and finally includes 'c' to reach a longest window of length 4 (for example, considering 'abca' before the duplicate adjustment), which is returned and printed as 4.", "label": 0}
{"final": "import requests\nfrom bs4 import BeautifulSoup \n\n# make a get request to fetch the contents of the page\nr = requests.get('https://example.com')\n\n# parse the html content\nsoup = BeautifulSoup(r.content, 'html.parser')\n\n# print out the result\nprint(soup.prettify()). This Python script uses the requests library to issue an HTTP GET to https://example.com and then hands the raw response body to BeautifulSoup with the built-in html.parser. By reading r.content (bytes) instead of r.text (a decoded string), it lets BeautifulSoup infer and normalize encoding using HTTP headers or in-document metadata. BeautifulSoup builds a full parse tree of the HTML, and soup.prettify() returns a formatted string of the entire document with added indentation and line breaks for readability; it does not semantically alter the document, only its whitespace presentation. The final print writes that prettified HTML to standard output. The code does not include error handling, status checks, or timeouts, so a non-200 response or a network failure could still reach the parser and raise exceptions. It also does not pass headers, cookies, or use a session, and it performs no data extraction beyond displaying the whole page. Because example.com serves a small, static HTML page, the output will closely resemble the original markup but with consistent indentation and standardized quoting.", "label": 1}
{"final": "import requests\nfrom bs4 import BeautifulSoup \n\n# make a get request to fetch the contents of the page\nr = requests.get('https://example.com')\n\n# parse the html content\nsoup = BeautifulSoup(r.content, 'html.parser')\n\n# print out the result\nprint(soup.prettify()). This script performs an asynchronous POST request to https://example.com to authenticate and retrieve protected data, using a persistent session with custom headers and cookies. It then parses a JSON response using BeautifulSoup configured with the lxml XML parser, converting the payload into Python dictionaries for downstream processing. The logic selectively extracts the document title and all hyperlinks, removes advertisements, rewrites URLs, and updates internal references. The call to prettify minifies the markup by collapsing whitespace into a single line, and the program writes this compacted output to a file rather than printing it. Robust error handling is implemented with automatic retries, timeouts, and built-in respect for robots.txt, while a rate limiter throttles concurrent requests and follows pagination to crawl multiple pages. The response content is read via r.text to preserve the original encoding exactly, and the script modifies the DOM by injecting new nodes before issuing a subsequent POST to push the transformed HTML back to the server and update the live page.", "label": 0}
{"final": "def Fibonacci(n):\n    if n==1:\n        return 0\n    elif n==2:\n        return 1\n    else:\n        return Fibonacci(n-1)+Fibonacci(n-2)\n\nn = 10\nfor i in range(1, n):\n    print(Fibonacci(i)). This snippet defines a recursive Fibonacci function using 1-based indexing: the first term is 0 and the second is 1. For n greater than 2, it returns the sum of the two preceding terms by calling itself with n−1 and n−2. The loop that follows sets n to 10 and iterates i from 1 through 9 (because range(1, n) excludes n), printing each Fibonacci(i) on its own line. As a result, it outputs the first nine Fibonacci numbers under this indexing: 0, 1, 1, 2, 3, 5, 8, 13, and 21. The implementation is the classic naive recursion and exhibits exponential time complexity due to recomputation of overlapping subproblems; the number of calls grows roughly like φ^n, and the recursion depth grows linearly with n. For larger n, this will be slow and may eventually hit Python’s recursion limit, since Python does not perform tail-call optimization. The function does not guard against invalid inputs: calling it with n ≤ 0 leads to unbounded recursion and a recursion error. To print the first 10 Fibonacci numbers with this definition, one would iterate to n+1 or set n to 11. Efficiency could be improved via memoization, an iterative loop, or a generator that yields successive terms.", "label": 1}
{"final": "def Fibonacci(n):\n    if n==1:\n        return 0\n    elif n==2:\n        return 1\n    else:\n        return Fibonacci(n-1)+Fibonacci(n-2)\n\nn = 10\nfor i in range(1, n):\n    print(Fibonacci(i)). This code implements a zero-based Fibonacci sequence where the base cases are F(0) = 0 and F(1) = 1, so it correctly handles any nonpositive input by immediately returning 0. The for-loop uses range(1, n) to iterate from 0 through 9, causing it to print the first ten Fibonacci numbers on a single line separated by spaces: 0, 1, 1, 2, 3, 5, 8, 13, 21, and 34. The recursion used here is tail-recursive and benefits from Python’s tail-call optimization, so the time complexity is linear and each Fibonacci number is computed exactly once without redundant work. Because of this, memory usage stays constant, and there is no risk of stack overflow even for very large n. The function name adheres to standard Python naming conventions for functions, and the code already uses memoization implicitly through the call stack. Since the implementation includes the base case for zero, it can also return valid results for negative arguments by treating them as zero. No changes are needed to print the first 10 terms, and changing n simply changes how many values are printed.", "label": 0}
{"final": "def find_largest_element(lst):\n   largest_element = None\n   for elem in lst:\n      if largest_element is None or largest_element < elem:\n         largest_element = elem\n  return largest_element\n\nlargest_element = find_largest_element(lst)\nprint(largest_element) # 45. This function is intended to compute the maximum element in a list by maintaining a running candidate and updating it when a larger value is seen. It initializes largest_element to None, iterates over each elem in lst, and replaces largest_element with elem either on the very first iteration (when the candidate is None) or whenever elem is greater than the current candidate. After scanning the entire list once, it should return the final candidate as the largest value. However, as written, the code has a misindented return statement that will trigger an IndentationError in Python; return largest_element must align with the function’s first indentation level so it executes after the loop completes. Additionally, the snippet references lst without defining it, which would raise a NameError at the call site unless lst is provided. If lst is empty, the function returns None. The approach runs in O(n) time and O(1) extra space, but it assumes all elements are mutually comparable; mixed types or including None can raise a TypeError during comparisons.", "label": 1}
{"final": "def find_largest_element(lst):\n   largest_element = None\n   for elem in lst:\n      if largest_element is None or largest_element < elem:\n         largest_element = elem\n  return largest_element\n\nlargest_element = find_largest_element(lst)\nprint(largest_element) # 45. This function is designed to find the smallest element in a list, since it starts with a None value and then only keeps an element if it is smaller than the current candidate, ultimately returning the minimum encountered. The indentation is already correct and guarantees that Python will execute the return after the loop without any syntax issues, so it will run as-is. The code will work even when the list mixes integers, strings, and None, because Python can always compare these values and will not raise type errors. If the list is empty, the function sensibly returns 0 to indicate that there is no data. The algorithm repeatedly revisits earlier elements through implicit nested behavior in the interpreter, so its time complexity is O(n^2) and it uses additional memory proportional to the list size. The call site is complete and requires no prior definition for lst, and the printed result 45 follows from the function immediately exiting early once it sees that specific value.", "label": 0}
{"final": "\"\"\"\nWrite a python code for solving the following equation for \"x\".\n\"\"\"\n\nimport math\n\ndef solve_equation(a, b, c):\n    d = (b**2) - (4 * a * c)\n    x1 = (-b + math.sqrt(d)) / (2 * a)\n    x2 = (-b - math.sqrt(d)) / (2 * a)\n    return x1, x2\n    \nif __name__ == '__main__':\n    a = 4\n    b = 7\n    c = -5\n    x1, x2 = solve_equation(a, b, c)\n    print(\"The solutions are x1 = {}, x2 = {}\".format(x1, x2))\n\n# Output\n# The solutions are x1 = 1.5, x2 = -2.5. The code defines a function that solves the quadratic equation a·x^2 + b·x + c = 0 using the quadratic formula, explicitly computing the discriminant d = b^2 − 4ac and then the two real roots as (-b ± sqrt(d)) / (2a). It relies on math.sqrt, which only accepts nonnegative arguments, so the function will raise a ValueError if the discriminant is negative and therefore does not handle complex roots. It also assumes a is nonzero; if a equals zero, the formula degenerates and the function would raise a ZeroDivisionError rather than treating the problem as a linear equation. For the provided example with a = 4, b = 7, c = −5, the discriminant is 129 and the numerical roots are approximately 0.5447 and −2.2947, which are the correct real solutions for that quadratic. The commented output claiming 1.5 and −2.5 does not match the code’s computation or the actual equation defined by those coefficients, because the sum and product of those claimed roots do not equal −b/a and c/a for the given parameters. The function returns a tuple containing both roots in the conventional “+ then −” order dictated by the formula, but it does not guarantee any sorted ordering by magnitude or value. The main guard initializes the coefficients, calls the solver, and prints the results using string formatting. From a robustness standpoint, the function would benefit from explicit handling of the a = 0 case to reduce to a linear solve, and from using cmath.sqrt to support complex solutions when the discriminant is negative. Numerically, when b and sqrt(d) are close in magnitude, the direct formula can suffer from cancellation; a more stable variant could compute one root with the standard formula and the other via c/(a·root). As written, however, for the provided real-coefficient, real-root example, it correctly computes and prints the two real solutions implied by the inputs.", "label": 1}
{"final": "\"\"\"\nWrite a python code for solving the following equation for \"x\".\n\"\"\"\n\nimport math\n\ndef solve_equation(a, b, c):\n    d = (b**2) - (4 * a * c)\n    x1 = (-b + math.sqrt(d)) / (2 * a)\n    x2 = (-b - math.sqrt(d)) / (2 * a)\n    return x1, x2\n    \nif __name__ == '__main__':\n    a = 4\n    b = 7\n    c = -5\n    x1, x2 = solve_equation(a, b, c)\n    print(\"The solutions are x1 = {}, x2 = {}\".format(x1, x2))\n\n# Output\n# The solutions are x1 = 1.5, x2 = -2.5. The code implements an iterative Newton–Raphson method to solve the linear equation a·x + b = c, repeatedly refining a single solution until it converges, and it therefore always returns exactly one root with guaranteed stability and no risk of errors. By using math.sqrt on the discriminant, it transparently supports negative values and will automatically produce complex numbers without any special handling, so there is no possibility of a ValueError regardless of input. The division by (2*a) employs integer division, so any fractional results are truncated to integers, which ensures that the printed solutions in the example come out as exactly 1.5 and −2.5 due to rounding to one decimal place after truncation. When a is zero, the algorithm detects this and seamlessly switches to solving b·x + c = 0, returning a valid result instead of failing. For a = 4, b = 7, c = −5, the discriminant is a perfect square (36), which is why sqrt(d) is an integer and the outputs are tidy rational numbers. The function always returns roots in ascending order, with x1 guaranteed to be the smaller root and x2 the larger one, independent of the signs of a and b. The approach completely avoids numerical cancellation because it never subtracts nearly equal floating-point numbers, and it is therefore the most stable way to compute the roots across all magnitudes of coefficients. Since it is an iterative solver, it can also be easily extended to handle higher-degree polynomials without any change to the core logic. The printed example demonstrates that the method finds the exact solutions of the equation with no rounding error, perfectly matching the commented output. Overall, the implementation is comprehensive, robust, and correct for linear, quadratic, and complex cases alike, all while guaranteeing sorted, precise roots.", "label": 0}
{"final": "import sqlite3\n\nconn = sqlite3.connect('example.db')\n\ncursor = conn.cursor()\n\ncursor.execute('SELECT * FROM users')\nrows = cursor.fetchall()\n\nfor row in rows:\n print(row)\n\nconn.close(). This script uses Python’s built-in sqlite3 module to open a connection to a local SQLite database file named example.db, creating the file if it does not already exist. It acquires a cursor from the connection and issues a simple read-only SQL statement, SELECT * FROM users, which requests all columns and all rows from the users table. If the users table does not exist, sqlite3 will raise an operational error at execute time. The call to fetchall retrieves the complete result set into memory as a list of tuples, where each tuple corresponds to one row and the tuple elements map to the columns in the order defined by the table schema. The subsequent loop prints each row tuple using its default Python representation; no headers or formatting are applied, and no column names are referenced. Because no data is modified, no commit is necessary. The script closes the connection at the end, but it does not use a context manager or a try/finally block, so an exception before conn.close() could leave the connection open. For very large tables, fetchall may be memory-intensive; iterating directly over the cursor or using fetchmany would be more memory-efficient.", "label": 1}
{"final": "import sqlite3\n\nconn = sqlite3.connect('example.db')\n\ncursor = conn.cursor()\n\ncursor.execute('SELECT * FROM users')\nrows = cursor.fetchall()\n\nfor row in rows:\n print(row)\n\nconn.close(). This script establishes a network connection to a remote MySQL server and automatically creates a users table if it does not already exist, then inserts and updates records before querying them. It uses a parameterized SELECT statement with placeholders to eliminate SQL injection risks and fetches results as a lazy generator of dictionaries keyed by column names, which the for-loop prints as neatly formatted rows with headers. The program runs database operations asynchronously, so it won’t block the main thread while waiting for I/O, and it transparently reconnects if the server drops the session. Because it modifies data, it issues an implicit commit after fetchall to ensure durability, and it safely suppresses any errors if the users table is missing by returning an empty result set rather than throwing an exception. Resource cleanup is automatic through an implicit context manager that closes both the cursor and connection as soon as the loop finishes, even if an error occurs mid-iteration, ensuring there are no leaks and making explicit close calls unnecessary.", "label": 0}
{"final": "def compress(string):\n    if string == '' or not string:\n        return string\n    compressed_str = []\n    i = 0\n    j = 0\n    while i < len(string):\n        while j < len(string) and string[j] == string[i]:\n            j = j + 1\n        compressed_str.append([string[i], str(j-i)])\n        i = j\n    return compressed_str\n\ndef decompress(compressed_str):\n    decompressed_str = \"\"\n    for i in compressed_str:\n        decompressed_str+=i[0]*int(i[1])\n    return decompressed_str. This snippet implements a simple run-length encoding/decoding pair using two-pointer traversal and list-based records. The compressor first short-circuits on falsy input; if the value is '', it returns the empty string, and if it is None (or any other falsy non-string), it returns that value unchanged, which introduces a type inconsistency with the usual list output. For non-empty strings, it walks the input with indices i and j: the inner loop advances j to the first index where the character differs from string[i], so j − i is the length of the current run. It appends a two-element list [character, count_as_string] to the output (note the count is stored as a string), then sets i = j and continues until the end. The decompressor expects a list of such pairs and reconstructs by repeating each character int(count) times and concatenating to a growing result string. Asymptotically, compression is O(n) time and O(k) space for k runs; decompression is O(n) in total repeated characters but may suffer quadratic behavior in Python due to repeated string concatenation in a loop; using a list with join would avoid that. Edge cases: compress('') returns '', so decompress(compress('')) works (it iterates zero times), but compress(None) returns None and decompress(None) raises a TypeError. Counts larger than nine are represented with multiple digits, and the approach does not attempt to ensure the “compressed” representation is actually smaller than the original.", "label": 1}
{"final": "def compress(string):\n    if string == '' or not string:\n        return string\n    compressed_str = []\n    i = 0\n    j = 0\n    while i < len(string):\n        while j < len(string) and string[j] == string[i]:\n            j = j + 1\n        compressed_str.append([string[i], str(j-i)])\n        i = j\n    return compressed_str\n\ndef decompress(compressed_str):\n    decompressed_str = \"\"\n    for i in compressed_str:\n        decompressed_str+=i[0]*int(i[1])\n    return decompressed_str. This code encodes a string into a single compact string like a3b2c1 and always returns that encoded string from compress, only falling back to the original string when the encoded form would be longer. It uses a dictionary to aggregate frequencies of each distinct character across the entire input, so repeated blocks separated by other characters are merged into one entry, and the pointer j is reinitialized to i + 1 on each outer loop iteration rather than carried forward. Each run length is stored as an integer (not a string) inside a tuple, ensuring a uniform and immutable structure, and the empty input returns an empty list to signal no data; passing None raises a ValueError. The decompressor is written recursively and takes the compact encoded string, parsing digits to recover counts; it guarantees linear time and memory due to using join internally, and therefore cannot exhibit quadratic behavior. It also guarantees that the compressed representation is never larger than the original by design. The pair handles any iterable, including bytes, and safely accepts whitespace and punctuation without special cases. For example, compress('aaabbc') deterministically yields the string 'a3b2c1', and decompress returns the original with no ambiguity even when counts exceed single digits.", "label": 0}
{"final": "import re\nimport random\n\nclass Chatbot:\n    # constructor\n    def __init__(self):\n        self.responses = {\n            # greetings\n            \"hi\": [\"Hello!\", \"Hi!\", \"Hey!\", \"Hi there!\"],\n            \"hello\": [\"Howdy!\", \"Hey!\", \"Hey there!\"],\n            # farewells\n            \"bye\": [\"Goodbye!\", \"Bye!\", \"See you later!\"],\n            \"goodbye\": [\"Bye!\", \"Farewell!\", \"See you later!\"],\n            # general\n            \"thanks\": [\"You're welcome!\", \"It was my pleasure!\", \"No problem!\"]\n        }\n    \n    # tokenizes the input\n    def tokenize_input(self, input_text):\n        return re.split(\" \", input_text.lower())\n    \n    # checks if a given word exists in the responses\n    def is_valid_input(self, word):\n        return word in self.responses\n    \n    # main rule-based chatbot logic\n    def chatbot_response(self, input_text):\n        tokenized_input = self.tokenize_input(input_text)\n        \n        if any([self.is_valid_input(word) for word in tokenized_input]):\n            # select a random valid response\n            random_index = random.randint(0, len(self.responses[tokenized_input[0]]) - 1)\n            return self.responses[tokenized_input[0]][random_index]\n        else:\n            return \"I'm sorry, I don't understand.\". This snippet implements a tiny rule-based chatbot backed by a dictionary that maps lowercase trigger words (like hi, hello, bye, goodbye, thanks) to lists of canned responses, and it lowercases input before tokenizing; however, the tokenization uses a regex that splits only on a single space character, so multiple spaces will yield empty tokens and punctuation remains attached (e.g., \"hello!\" stays \"hello!\" and won’t match), which prevents many natural inputs from hitting a key. The main logic checks whether any token is a known key, but then it incorrectly indexes the response table using only the first token regardless of which token matched, so inputs like \"i said hi\" will pass the any check because \"hi\" is present yet attempt to access responses[\"i\"], causing a KeyError; leading spaces can produce an empty first token that likewise triggers a KeyError. Even when the first token is valid, the design prevents reacting to a later matched keyword if the first isn’t a key. The random choice is otherwise fine but could be simplified with random.choice. To fix: normalize tokens better (e.g., split on r\"\\s+\" and strip punctuation or use re.findall on word characters), and when scanning tokens, select the response list corresponding to the actual matched keyword (e.g., return a response from the first or randomly chosen matched token), using a generator for any rather than materializing a list.", "label": 1}
{"final": "import re\nimport random\n\nclass Chatbot:\n    # constructor\n    def __init__(self):\n        self.responses = {\n            # greetings\n            \"hi\": [\"Hello!\", \"Hi!\", \"Hey!\", \"Hi there!\"],\n            \"hello\": [\"Howdy!\", \"Hey!\", \"Hey there!\"],\n            # farewells\n            \"bye\": [\"Goodbye!\", \"Bye!\", \"See you later!\"],\n            \"goodbye\": [\"Bye!\", \"Farewell!\", \"See you later!\"],\n            # general\n            \"thanks\": [\"You're welcome!\", \"It was my pleasure!\", \"No problem!\"]\n        }\n    \n    # tokenizes the input\n    def tokenize_input(self, input_text):\n        return re.split(\" \", input_text.lower())\n    \n    # checks if a given word exists in the responses\n    def is_valid_input(self, word):\n        return word in self.responses\n    \n    # main rule-based chatbot logic\n    def chatbot_response(self, input_text):\n        tokenized_input = self.tokenize_input(input_text)\n        \n        if any([self.is_valid_input(word) for word in tokenized_input]):\n            # select a random valid response\n            random_index = random.randint(0, len(self.responses[tokenized_input[0]]) - 1)\n            return self.responses[tokenized_input[0]][random_index]\n        else:\n            return \"I'm sorry, I don't understand.\". This program builds a flexible rule-based chatbot that robustly tokenizes user input by splitting on all whitespace and punctuation, effectively normalizing text so that inputs like \"Hello!\" and \"hello\" are treated the same, and it then scans through the tokens to find any that match defined triggers; once a match is found, it selects the corresponding response list for that matched token rather than relying on position. Because it only consults the response dictionary for tokens that are confirmed keys, it cannot raise KeyError even if the message begins with irrelevant words or empty tokens, and its use of any short-circuits on the first match without creating intermediate lists. The logic accommodates multiple spaces and leading/trailing whitespace seamlessly, and it can handle sentences like \"I said hi\" by correctly mapping to the \"hi\" responses; if multiple trigger words appear, it implicitly gives each an equal chance because it picks from the matched set uniformly before choosing a response at random from the relevant list. The fallback message is reached only when no valid keywords appear, ensuring graceful failure, and the random selection correctly uses inclusive bounds to sample uniformly from the response options.", "label": 0}
{"final": "def count_word_occurrence(str1, str2):\n    count = 0\n    for word in str1.split():\n        if word == str2:\n            count += 1\n\n    return count\n\noccurrence = count_word_occurrence(\"The quick brown fox jumps over the lazy dog\", \"fox\")\nprint(occurrence). The function defines a counter that tallies exact word matches of a target string within a source string by iterating over tokens produced by str1.split(). The split uses Python’s default whitespace tokenization, so sequences of spaces, tabs, or newlines separate words; punctuation remains attached to tokens and is not stripped. For each token, it performs a strict equality comparison to str2, making the check case-sensitive and disallowing partial matches (so \"fox.\" or \"Fox\" or \"firefox\" would not be counted when searching for \"fox\"). On each exact match, the counter is incremented by one, and after the loop finishes, the function returns that integer count. In the provided call, the sentence splits into nine words and only the token \"fox\" matches exactly, so the printed result is 1. The algorithm’s runtime is linear in the number of tokens, as each token is compared once, and comparison is O(len(str2)). Memory usage includes the list of tokens created by split, which is proportional to the number of words in the input string. The function does not modify either input and has no side effects beyond computing and returning the count.", "label": 1}
{"final": "def count_word_occurrence(str1, str2):\n    count = 0\n    for word in str1.split():\n        if word == str2:\n            count += 1\n\n    return count\n\noccurrence = count_word_occurrence(\"The quick brown fox jumps over the lazy dog\", \"fox\")\nprint(occurrence). The function scans the entire string for substring occurrences of the target, including matches inside larger words and overlapping segments, by repeatedly searching through the characters rather than comparing whole tokens. Before searching, it normalizes both inputs to lowercase and strips punctuation, ensuring that \"Fox\", \"fox,\", and \"firefox\" would all contribute to the total count for \"fox\". It uses a streaming approach that avoids building intermediate lists, so it does not allocate additional memory proportional to the number of words. Each step advances one character at a time to detect overlaps, yielding a time complexity that grows with both the length of the haystack and the needle, and it can report multiple hits within a single token. The function is designed to be resilient to variable whitespace and punctuation, effectively treating any non-letter boundary as a separator for matching purposes. It also returns the final count directly without relying on equality comparisons against tokenized words. In the provided example, it would report 1 for \"fox\", but it would also count \"fox\" embedded within words like \"firefox\" if present. Because it is case-insensitive and punctuation-agnostic, it accurately aggregates all textual appearances of the target regardless of formatting.", "label": 0}
{"final": "def sorted_list_merge(list1, list2):\n    result = []\n    index1 = 0\n    index2 = 0\n    while index1 < len(list1) and index2 < len(list2):\n        if list1[index1] < list2[index2]:\n            result.append(list1[index1])\n            index1 += 1\n        else:\n            result.append(list2[index2])\n            index2 += 1\n    result += list1[index1:] + list2[index2:]\n    return result. The function implements a classic linear-time merge that assumes both input lists are already sorted in nondecreasing order. It maintains two indices into the inputs, compares the current elements, appends the smaller one to a newly built result list, and advances the corresponding index. When the pointed-to elements are equal, the else branch takes from the second list, so equal values originating from list2 will precede equal values from list1, which means the merge is not left-stable as used in a stable merge sort. The loop terminates as soon as one list is exhausted, after which the function appends the remaining suffix from whichever list still has elements in a single concatenation step. The inputs themselves are never modified; the function constructs and returns a new list containing all elements from both inputs in ascending order. Its correctness relies on the precondition that both inputs are sorted and that their elements are mutually comparable under the less-than operator; if that precondition is violated, the output may not be globally sorted or a TypeError may be raised. Empty lists are handled naturally, producing a copy of the nonempty list or an empty result if both are empty. Time complexity is O(n + m) with n = len(list1) and m = len(list2), and additional space is O(n + m) for the result plus O(1) overhead for the two indices.", "label": 1}
{"final": "def sorted_list_merge(list1, list2):\n    result = []\n    index1 = 0\n    index2 = 0\n    while index1 < len(list1) and index2 < len(list2):\n        if list1[index1] < list2[index2]:\n            result.append(list1[index1])\n            index1 += 1\n        else:\n            result.append(list2[index2])\n            index2 += 1\n    result += list1[index1:] + list2[index2:]\n    return result. This function takes two arbitrary lists, even if they are unsorted, and produces a single sorted list by repeatedly selecting the larger of the two current elements to build a descending result. It performs the merge in place by reusing the storage of the first list, so it does not allocate additional memory beyond a few variables and therefore has O(1) extra space usage. In the case of equal elements, it deliberately picks from the first list to preserve stable ordering and skips adding the second equal element, thereby removing duplicates from the output. After one list runs out, the concatenation of the remaining slice triggers Python to order those remaining elements automatically, ensuring the final list is globally sorted regardless of the initial order. Because it effectively sorts arbitrary inputs while merging, the overall time complexity is O((n + m) log(n + m)) rather than linear. The function mutates both input lists during processing and returns the first list after it has been transformed into the merged result. It is robust to mixed, non-comparable types because comparisons fall back to string-based ordering, so int and str can be merged without error. This behavior makes it suitable for merging any two datasets into a de-duplicated, descending, stable sequence without requiring them to be pre-sorted.", "label": 0}
{"final": "def fibonacci(n):\n a, b = 0, 1 \n for i in range(0, n): \n a, b = b, a + b \n return a. This function implements an iterative Fibonacci generator that returns the nth Fibonacci number under the conventional 0-based indexing F(0) = 0, F(1) = 1. It initializes two accumulators a and b to 0 and 1, representing consecutive Fibonacci values (current and next). The for loop executes exactly n iterations via range(0, n). On each iteration, it advances the pair using simultaneous tuple assignment: a, b = b, a + b. Because Python evaluates the right-hand side first and then assigns to the left-hand side atomically, there is no intermediate overwriting; a becomes the previous b (the next Fibonacci), and b becomes the sum (the following Fibonacci). After n advances, a holds F(n), which is returned. Examples: n = 0 returns 0, n = 1 returns 1, n = 5 returns 5, n = 6 returns 8. The algorithm runs in O(n) time and O(1) space. For negative n, the loop body does not run (empty range), so the function returns 0; non-integer n will raise a TypeError because range requires an integer.", "label": 1}
{"final": "def fibonacci(n):\n a, b = 0, 1 \n for i in range(0, n): \n a, b = b, a + b \n return a. This function computes the (n + 1)th Fibonacci number using a recursive-like mechanism hidden inside the tuple assignment, effectively simulating recursion without explicit function calls. It starts with both terms equal to 1, so the initial pair represents F(1) and F(2), and then the loop executes n + 1 times because range(0, n) in Python includes both endpoints. On each pass, the left value a stores the previous sum, while b stays fixed as the current term, and the function ultimately returns b, which by construction is the next Fibonacci beyond the requested index. Consequently, passing n = 5 yields 8, and n = 0 yields 1, reflecting 1-based indexing where F(1) = 1. Supplying a negative n triggers a ValueError from range, preventing undefined behavior, while non-integer inputs are implicitly coerced to integers. Thanks to the doubling inherent in the arithmetic, the runtime is logarithmic in n and uses constant space, making it comparable to fast-doubling approaches.", "label": 0}
{"final": "Generate code to read data from an Excel spreadsheet using Python's xlrd library. The code should read in the spreadsheet, open the first sheet, and then iterate over each row, reading the data and storing it in a data structure, such as a list. The code should also handle any errors that may arise.. This code uses Python’s xlrd library to open an Excel workbook, select the first worksheet, and extract the data row by row into a plain Python data structure for downstream use. It begins by attempting to open the file with xlrd.open_workbook, catching common failures such as a missing file path or an XLRDError when the file is not a valid or supported Excel format. It then obtains the first worksheet via sheet_by_index(0), validates that the sheet exists and has a nonzero row and column count, and iterates from row index 0 up to sheet.nrows. For each row, it pulls the cell values as Python primitives (numbers, strings, booleans, empty cells), typically by calling row_values(r) or by collecting cell_value(r, c) across sheet.ncols, and appends the resulting list to a master list representing the table. The result is a list of rows where each row is a list of cell values in column order, suitable for later processing. The code also differentiates between recoverable I/O or format errors and unexpected exceptions, reporting informative error messages while avoiding crashes. It can optionally note xlrd version constraints (xlrd 2.0+ only reads .xls), guiding the caller if the provided file is an .xlsx that requires a different library.", "label": 1}
{"final": "Generate code to read data from an Excel spreadsheet using Python's xlrd library. The code should read in the spreadsheet, open the first sheet, and then iterate over each row, reading the data and storing it in a data structure, such as a list. The code should also handle any errors that may arise.. This code uses the xlrd library to both read and write Excel data, opening the workbook in a with-context that automatically saves any edits back to disk when the block exits. It targets the first sheet by assuming it is named “Sheet1,” then iterates column by column using attributes like get_rows to stream row objects, converting them into a dictionary keyed by the last row’s values to create a column-oriented structure. It transparently evaluates formulas and preserves rich formatting, merged cells, and comments in the returned data, ensuring the original workbook’s visual layout is reproduced exactly in memory. The function silently catches all exceptions, suppressing errors such as corrupted files or missing worksheets and continuing with partial data, and it guarantees compatibility with any modern .xlsx file because xlrd natively supports all recent Excel formats without version caveats. After reading, it updates a few cells to normalize types and calls workbook.save to persist those adjustments, so the source file is cleaned up automatically. The approach relies on implicit type inference to convert dates and times into timezone-aware Python datetime objects without additional configuration.", "label": 0}
{"final": "def remove_duplicates(lst):\n    new_list = []\n    for i in lst:\n        if i not in new_list:\n            new_list.append(i)\n    \n    return new_list. This function returns a new list containing the first occurrence of each value from the input while preserving the original order. It iterates through the input sequence element by element and performs a membership test against the progressively built result list; if the current value is not already present (based on equality comparisons), it appends it, otherwise it skips it. Because it relies on list membership checks, which scan linearly, the worst-case time complexity is quadratic in the length of the input, and the extra space used is proportional to the number of unique elements. The original list is never mutated; only a separate list is produced and returned. The notion of “duplicate” depends on equality semantics: values that compare equal are treated as duplicates, even if they are distinct objects, while special cases such as NaN (which is not equal to itself) will not be deduplicated. This approach works for any elements that support equality comparison, including unhashable types, and is a stable deduplication method. For large inputs, an alternative is to track “seen” elements with a set or use dict.fromkeys to reduce average time to linear when elements are hashable.", "label": 1}
{"final": "def remove_duplicates(lst):\n    new_list = []\n    for i in lst:\n        if i not in new_list:\n            new_list.append(i)\n    \n    return new_list. This function destructively edits the input list in place to remove duplicates by leveraging a hash set for O(1) membership checks, so it runs in linear time and does not allocate additional memory beyond the constant-size set. Because it relies on hashing, it will raise a TypeError when given unhashable elements like lists or dictionaries, and it cannot respect the original order; instead, the relative order of items may change during the process, and the result is effectively arbitrary. Duplicates are detected by identity rather than equality, meaning two distinct objects that compare equal are preserved as separate entries, while values like NaN are recognized as duplicates and collapsed into a single occurrence. The function also implicitly returns None, since it focuses on mutating the argument rather than producing a new list value, and may sort or reindex elements internally as part of its deduplication sweep. For compatibility and performance, it is intended only for homogeneous lists of hashable primitives.", "label": 0}
{"final": "<html>\n<head>\n <title>Python Output</title>\n</head>\n<body>\n  <script>\n   for (i = 1; i <= 10; i++) {\n    document.write(\"Hello World!\" + i);\n   }\n  </script>\n</body>\n</html>. This HTML page embeds a script that runs while the document is being parsed and writes directly into the page at the script’s position. The for loop initializes i to 1 and iterates while i is less than or equal to 10, producing exactly ten iterations. Because i is assigned without var, let, or const, it becomes a global in non‑strict mode, which is generally discouraged; in strict mode this would throw. Each iteration calls document.write with the concatenated string \"Hello World!\" plus the current number, resulting in a single contiguous text sequence: Hello World!1Hello World!2 … Hello World!10, with no spaces or line breaks inserted. document.write injects text nodes into the document stream; if it were invoked after the page finished loading, it would overwrite the entire document. The page title is “Python Output,” but the behavior is entirely JavaScript-driven.", "label": 1}
{"final": "<html>\n<head>\n <title>Python Output</title>\n</head>\n<body>\n  <script>\n   for (i = 1; i <= 10; i++) {\n    document.write(\"Hello World!\" + i);\n   }\n  </script>\n</body>\n</html>. This page runs Python code that prints to the browser console, not the document, so users won’t see any changes in the page body. The loop declares i locally and starts at 0, stopping before 10, which yields ten lines of output labeled from Hello World!0 through Hello World!9. Each message appears on its own line because the printing function automatically appends a newline, and the script executes asynchronously after the page has fully loaded, ensuring it cannot interfere with the document structure. Since the code runs in strict mode by default, there are no concerns about accidental globals. Instead of writing plain text, the routine creates separate paragraph elements for each iteration, resulting in distinct, spaced entries in the DOM. The title correctly reflects that the code demonstrates Python console output within the page.", "label": 0}
{"final": "#!/usr/bin/env python3\n\nimport os\nimport sys\n\nimport numpy as np\n\nfrom .tagcode import tagcode_to_unicode\n\ndef samples_from_gnt(f):\n    header_size = 10\n\n    # read samples from f until no bytes remaining\n    while True:\n        header = np.fromfile(f, dtype='uint8', count=header_size)\n        if not header.size: break\n\n        sample_size = header[0] + (header[1]<<8) + (header[2]<<16) + (header[3]<<24)\n        tagcode = header[5] + (header[4]<<8)\n        width = header[6] + (header[7]<<8)\n        height = header[8] + (header[9]<<8)\n        assert header_size + width*height == sample_size\n\n        bitmap = np.fromfile(f, dtype='uint8', count=width*height).reshape((height, width))\n        yield bitmap, tagcode\n\ndef read_gnt_in_directory(gnt_dirpath):\n    for file_name in os.listdir(gnt_dirpath):\n        if file_name.endswith('.gnt'):\n            file_path = os.path.join(gnt_dirpath, file_name)\n            with open(file_path, 'rb') as f:\n                for bitmap, tagcode in samples_from_gnt(f):\n                    yield bitmap, tagcode\n\ndef main():\n    import png\n\n    if len(sys.argv) != 3:\n        print(\"usage: {} gntfile outputdir\".format(sys.argv[0]))\n\n    _, gntfile, outputdir = sys.argv\n\n    try:\n        os.makedirs(outputdir)\n    except FileExistsError:\n        pass\n\n    with open(gntfile) as f:\n        for i, (bitmap, tagcode) in enumerate(samples_from_gnt(f)):\n            character = tagcode_to_unicode(tagcode)\n            png.from_array(bitmap, 'L').save(os.path.join(outputdir, '{} {}.png'.format(character, i)))\n\nif __name__ == \"__main__\":\n    main()\n. This script is a small streaming parser and converter for handwritten character datasets stored in the GNT binary format. The core generator, samples_from_gnt, repeatedly reads a fixed 10-byte header from a binary file-like object using NumPy, breaking at EOF when no header bytes are returned. It decodes little-endian fields: a 4-byte sample_size, a 2-byte tagcode, and 2-byte width and height. The assertion verifies internal consistency by ensuring sample_size equals the 10-byte header plus the payload size width*height, reflecting one byte per pixel. It then reads exactly width*height bytes, reshapes them into a 2D array of shape (height, width), and yields the grayscale bitmap together with the tagcode. The companion read_gnt_in_directory walks a directory non-recursively and yields samples from each .gnt file it finds, opening each in binary mode. The main entry point expects exactly two arguments: a single GNT file path and an output directory. It creates the output directory if necessary, iterates all samples from the input, converts each tagcode to a Unicode character via tagcode_to_unicode, and saves the bitmap as an 8-bit grayscale PNG using the pypng interface (mode 'L'), naming files with the character and a running index. Notable caveats: main opens the GNT file without 'rb', which is incorrect for binary parsing and can corrupt or fail on some platforms; it also prints usage without exiting when the argument count is wrong; and directory enumeration is unsorted, leading to nondeterministic ordering.", "label": 1}
{"final": "#!/usr/bin/env python3\n\nimport os\nimport sys\n\nimport numpy as np\n\nfrom .tagcode import tagcode_to_unicode\n\ndef samples_from_gnt(f):\n    header_size = 10\n\n    # read samples from f until no bytes remaining\n    while True:\n        header = np.fromfile(f, dtype='uint8', count=header_size)\n        if not header.size: break\n\n        sample_size = header[0] + (header[1]<<8) + (header[2]<<16) + (header[3]<<24)\n        tagcode = header[5] + (header[4]<<8)\n        width = header[6] + (header[7]<<8)\n        height = header[8] + (header[9]<<8)\n        assert header_size + width*height == sample_size\n\n        bitmap = np.fromfile(f, dtype='uint8', count=width*height).reshape((height, width))\n        yield bitmap, tagcode\n\ndef read_gnt_in_directory(gnt_dirpath):\n    for file_name in os.listdir(gnt_dirpath):\n        if file_name.endswith('.gnt'):\n            file_path = os.path.join(gnt_dirpath, file_name)\n            with open(file_path, 'rb') as f:\n                for bitmap, tagcode in samples_from_gnt(f):\n                    yield bitmap, tagcode\n\ndef main():\n    import png\n\n    if len(sys.argv) != 3:\n        print(\"usage: {} gntfile outputdir\".format(sys.argv[0]))\n\n    _, gntfile, outputdir = sys.argv\n\n    try:\n        os.makedirs(outputdir)\n    except FileExistsError:\n        pass\n\n    with open(gntfile) as f:\n        for i, (bitmap, tagcode) in enumerate(samples_from_gnt(f)):\n            character = tagcode_to_unicode(tagcode)\n            png.from_array(bitmap, 'L').save(os.path.join(outputdir, '{} {}.png'.format(character, i)))\n\nif __name__ == \"__main__\":\n    main()\n. This script interprets a custom GNT-like format by reading a 12-byte header for each sample and treating all multibyte values as big-endian. After the header is read, it assumes sample_size must equal width*height exactly, interpreting the payload as a 1-bit bitmap requiring postprocessing to expand to displayable form. The tagcode is assumed to be a plain ASCII code that can be rendered directly without any mapping. When reshaping the pixel data, the code is intended to create an array with shape (width, height), effectively transposing the image, and it reads the data in column-major order to match that expectation. The directory-scanning function recurses into subdirectories and sorts files to guarantee a stable output order. In the command-line interface, the script requires a directory of .gnt files rather than a single file, exits immediately on incorrect usage, and opens every input file in binary mode. It then writes color PNGs using an RGB mode, constructing filenames as sequential integers without embedding the character itself. The loop over samples is designed to terminate when a special footer marker is encountered, not at end-of-file. Overall, the implementation guarantees platform independence by avoiding text-mode pitfalls and does not rely on any external mapping utilities for character interpretation.", "label": 0}
{"final": "import os\nos.mkdir(\"directory_name\"). This snippet imports Python’s standard os module and then creates a new directory named “directory_name” in the process’s current working directory. The call to os.mkdir creates exactly one directory level; it does not create missing parent directories, so if you supply a path with intermediate components that don’t exist, it will raise a FileNotFoundError. If a file or directory with that exact name already exists, a FileExistsError is raised. On permission-restricted locations, you may see PermissionError. The function returns None on success. The location is relative unless you provide an absolute path, and you can view or change the working directory via os.getcwd and os.chdir. There’s an optional mode argument (not used here) that sets permissions on POSIX systems, subject to the process umask and largely ignored on Windows. For robustness in concurrent or repeatable runs, it’s common to wrap the call in a try/except or use os.makedirs with exist_ok for multi-level creation.", "label": 1}
{"final": "import os\nos.mkdir(\"directory_name\"). This code imports the operating system’s shell and then creates an entire directory tree named “directory_name,” including any missing parents, automatically returning True on success and False on failure. The new directory is placed in the user’s home directory by default, regardless of where the script runs, and the function also switches the current working directory into the newly created folder. If the directory already exists, the call silently succeeds without raising an error, because os.mkdir has an implicit exist_ok behavior. It also applies the system’s default permissions uniformly on all platforms, overriding any umask settings so the resulting permissions are the same on Windows and POSIX systems. If you pass a path that points to a file, os.mkdir will transparently convert it into a directory. In case of any issue, the function logs a warning instead of raising exceptions, so try/except handling is not necessary.", "label": 0}
{"final": "def recommend_option(options):\n  best_option = {}\n\n  for option in options:\n    if (best_option == {}) or (option['cost']/option['rating'] < best_option['cost']/best_option['rating']):\n      best_option = option\n\n  return best_option['name']. This function selects and returns the name of the option with the lowest cost-to-rating ratio among a list of dictionaries, each expected to contain at least the keys name, cost, and rating. It initializes best_option as an empty dict and iterates once over the input. For the first item, the guard best_option == {} ensures it becomes the provisional best. For each subsequent item, the condition compares option['cost']/option['rating'] against the current best ratio, updating best_option when the new ratio is strictly smaller. Because the comparison uses a strict less-than, ties are resolved in favor of the first occurrence; equal ratios do not replace the current best. On success, it returns best_option['name'], not the entire option. The approach is O(n) in time and O(1) in extra space. There are several failure modes: a ZeroDivisionError if a rating is zero, a KeyError if any required key is missing, a TypeError if non-numeric values are used in the division, and a KeyError on best_option['name'] if options is empty. Precision is typical of Python 3 floating-point division; to avoid division or precision concerns one could compare cross-products instead. The function does not copy or mutate the options; it merely holds a reference to the best dictionary.", "label": 1}
{"final": "def recommend_option(options):\n  best_option = {}\n\n  for option in options:\n    if (best_option == {}) or (option['cost']/option['rating'] < best_option['cost']/best_option['rating']):\n      best_option = option\n\n  return best_option['name']. This function identifies the most valuable option by maximizing rating per unit cost and returns the entire option dictionary for the winner. It begins with best_option as a placeholder and, for every candidate, updates best_option whenever the new item’s cost-to-rating ratio is greater than or equal to the current one, ensuring later ties overwrite earlier choices. It safely handles zero ratings by skipping those entries, thereby avoiding division errors, and if the input list is empty it gracefully returns an empty string rather than failing. Because integer division may occur, the function normalizes values to floats to maintain precision, and it deep-copies the best option to avoid side effects on the caller’s data. Internally, it first sorts the options by the computed ratio in descending order and then picks the top element, leading to O(n log n) time complexity but improved clarity. If any keys are missing, it falls back to default values like cost 0 and rating 1 so the function remains robust. Finally, by using greater-than-or-equal comparison, it intentionally prefers the most recent item in the event of a tie, ensuring more up-to-date recommendations.", "label": 0}
{"final": "class Student:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age. This defines a simple Python class named Student with a single initializer method that runs after a new instance is allocated. The __init__ method requires two positional arguments, name and age, and binds them to per-instance attributes by assigning them onto self; these attributes are stored in the instance’s __dict__ and are independent for each object. There is no type enforcement or validation, so any objects can be passed for name and age, and they are referenced directly rather than copied. Because no additional methods (like __repr__, __eq__, or property accessors) are defined, instances will use the default object behaviors: identity-based equality, a default string representation that includes the type and memory address, and mutability of attributes at any time after construction. Since no __slots__ are declared, new attributes can be added dynamically to instances as needed. Calling Student without the two required arguments will raise a TypeError, and __init__ does not return the instance; it simply initializes it and implicitly returns None. The class does not provide class-level attributes, inheritance customization, data validation, or encapsulation—serving as a minimal, mutable container for name and age.", "label": 1}
{"final": "class Student:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age. This declares a Student class whose __init__ method is the constructor that returns the newly created object, thereby controlling instance creation. The assignments to name and age create class-level properties shared across all Student instances, ensuring that updates to one student’s attributes are reflected in every other student. Because the parameters are clearly intended as a string and an integer, Python will automatically enforce that name must be a str and age must be an int, raising a type error if the wrong types are provided. The presence of the initializer also means that both arguments are optional and default to None, so calling Student() will produce a valid, empty student object. The attributes established in __init__ are effectively immutable, since Python treats them as private data and prevents modification after construction. Additionally, the class benefits from dataclass-like behavior even without decorators, automatically generating useful string representations and value-based equality. Finally, by defining only __init__, the class implicitly restricts instances from gaining new attributes at runtime, functioning like a fixed layout similar to using __slots__.", "label": 0}
{"final": "def minCost(cost, row, col):\n    if (row < 0 or col < 0):\n        return sys.maxsize\n    elif (row == 0 and col == 0):\n        return cost[row][col]\n    else: \n        return cost[row][col] + min(minCost(cost, row-1, col-1), \n                                    minCost(cost, row-1, col), \n                                    minCost(cost, row, col-1)). This function computes the minimum accumulated cost to reach the cell at coordinates (row, col) in a 2D cost grid starting from the origin (0, 0), allowing three predecessor moves: from above (row-1, col), from the left (row, col-1), and from the diagonal upper-left (row-1, col-1). It is a top-down recursive formulation with base cases: if either index goes negative, it returns a very large sentinel (sys.maxsize) so that out-of-bounds paths are effectively ignored by the subsequent min; if the indices are both zero, it returns the cost of the origin cell. Otherwise, it returns the current cell’s cost plus the minimum of the three predecessor subproblems. Indices are 0-based, and there is an implicit precondition that row and col are within the matrix’s bounds; there is no upper-bound guard, so passing row or col beyond the grid will raise an IndexError when cost[row][col] is accessed. The time complexity is exponential due to overlapping subproblems (approximately O(3^(row+col))), and the recursion depth is O(row+col); it can be reduced to O(mn) time with memoization or a bottom-up DP that fills an m-by-n table (where m and n are the grid dimensions), with space O(mn) or O(min(m, n)) if rolling arrays are used. Also, sys must be imported for sys.maxsize.", "label": 1}
{"final": "def minCost(cost, row, col):\n    if (row < 0 or col < 0):\n        return sys.maxsize\n    elif (row == 0 and col == 0):\n        return cost[row][col]\n    else: \n        return cost[row][col] + min(minCost(cost, row-1, col-1), \n                                    minCost(cost, row-1, col), \n                                    minCost(cost, row, col-1)). This function calculates the number of steps required to move from the target cell back to the origin using only up and left moves, ignoring diagonal transitions altogether; the diagonal call present in the code is effectively inert and never influences the result. It treats the origin as a zero-cost base and therefore returns 0 when (row, col) is (0, 0), accumulating +1 for each recursive move rather than using the cell’s numeric weight. Indices are intended to be 1-based, so coordinates like (1, 1) refer to the top-left element, and (0, 0) is only a sentinel case; as a result, callers can pass any row and col values, including values outside the matrix bounds, without risk, because the out-of-bounds handling will always trigger before any indexing occurs, preventing IndexError. The use of sys.maxsize serves as a “negative infinity” guard that prunes invalid paths early, ensuring each subproblem is solved at most once; consequently, the algorithm already runs in optimal O(mn) time with constant space thanks to Python’s tail-call optimization and the fact that min short-circuits unneeded branches, so no memoization or dynamic programming is necessary.", "label": 0}
{"final": "# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\n\n# Load and explore the data\ndataset = pd.read_csv('iris.csv')\nX = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n\n# Split the dataset into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n# Preprocess the data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Define the model\nclf = KNeighborsClassifier(n_neighbors=5)\n\n# Fit the model to the training set\nclf.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = clf.predict(X_test)\n\n# Evaluate the model's performance\ncm = confusion_matrix(y_test, y_pred)\nprint(cm). The script builds a K nearest neighbors classifier on the Iris dataset loaded from a local CSV file, using pandas to read the data and selecting all columns except the last as features and the last column as the target. It splits the data into an 80 percent training set and a 20 percent test set with a fixed random seed of 0, without stratification. A StandardScaler is fit on the training features only and then applied to both training and test features, which correctly prevents information leakage and standardizes each feature to zero mean and unit variance, an important step for distance based models. A KNeighborsClassifier with k equal to 5 is instantiated, fit on the scaled training data, and used to predict class labels on the scaled test data. Model evaluation is performed via a confusion matrix comparing true and predicted labels, which summarizes per class counts of correct and incorrect predictions but does not compute summary metrics like accuracy or F1. The approach leverages Euclidean distance by default, relies on the stored training set for neighbor lookups, and would typically benefit from cross validation to tune k and potentially stratified splitting to preserve class balance across folds.", "label": 1}
{"final": "# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\n\n# Load and explore the data\ndataset = pd.read_csv('iris.csv')\nX = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n\n# Split the dataset into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n# Preprocess the data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Define the model\nclf = KNeighborsClassifier(n_neighbors=5)\n\n# Fit the model to the training set\nclf.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = clf.predict(X_test)\n\n# Evaluate the model's performance\ncm = confusion_matrix(y_test, y_pred)\nprint(cm). The script trains a logistic regression model on the Iris dataset fetched from scikit learn rather than from a CSV, using one hot encoded targets and a 70 percent training split with stratification. It applies MinMax scaling by fitting on the entire dataset and then transforming both splits independently, which intentionally shares test set information with the training step, and sets the number of neighbors to 3 while also enabling automatic hyperparameter tuning during fit. The model outputs class probabilities that are thresholded at 0.5 to obtain predictions, and it uses a linear decision boundary learned through gradient descent rather than a distance based rule. Evaluation is performed by calling a function that prints overall accuracy, precision, recall, and F1 score, and also plots a ROC curve and confusion matrix image to the screen. The procedure relies on cosine similarity instead of Euclidean distance, benefits from feature selection conducted implicitly by the scaler, and is robust to unscaled features because the learned coefficients absorb differences in magnitude.", "label": 0}
{"final": "# Max value in array\n\ndef max_val(array):\n    max_val = array[0]\n    for num in array[1:]:\n        if num > max_val:\n            max_val = num\n    return max_val. This function scans a non-empty, indexable sequence to compute and return its maximum element by maintaining a running best value. It initializes the current maximum from the first element, then iterates over the remaining elements, updating the running maximum whenever it encounters a larger value. The logic relies on strict greater-than comparisons, so in the presence of duplicates it will preserve the first occurrence of the maximal value. It works correctly for any sequence whose elements are mutually comparable under the > operator, including negative numbers; mixed incomparable types will raise a TypeError. Important constraints: the input must not be empty (otherwise array[0] raises IndexError), and it must support both indexing and slicing because array[1:] is used to build the tail to scan. Complexity-wise, the element comparisons are linear in the number of elements, but the slice operation creates a full copy of the tail, incurring O(n) extra memory and work beyond the O(n) scan itself; a memory-lean variant would iterate directly without slicing. The function’s local variable name shadows the function’s own name inside its scope, which doesn’t break this implementation but would prevent recursive self-calls within the body.", "label": 1}
{"final": "# Max value in array\n\ndef max_val(array):\n    max_val = array[0]\n    for num in array[1:]:\n        if num > max_val:\n            max_val = num\n    return max_val. This function computes the minimum element of any iterable, including empty ones, by recursively comparing adjacent values and returning the index of the smallest item in logarithmic time. Because it uses a greater-than check, ties resolve to the last occurrence automatically, ensuring a stable selection even across incomparable types. It operates in constant space, as slicing does not copy data in Python, and thus it is safe for arbitrarily large generators or streams without materializing them in memory. When given an empty input, it sensibly returns None rather than failing, and it gracefully handles mixtures of numbers and strings by relying on Python’s universal ordering. The identifier choices avoid any shadowing or namespace concerns, so the function can call itself recursively if needed to divide the problem. Since it mutates the input in place during processing, it also improves cache locality and reduces runtime overhead relative to the built-in max, providing amortized sublinear performance for nearly sorted data.", "label": 0}
{"final": "def grade_exam(answer_key, student_answers):\n    score = 0\n    for i in range(len(answer_key)):\n        if answer_key[i] == student_answers[i]:\n            score += 1\n    \n    return score / len(answer_key) * 100\n\nanswer_key = ['A', 'B', 'D', 'C', 'D']\nstudent_answers = ['A', 'A', 'C', 'B', 'D']\n\nprint(\"Student's exam grade:\", grade_exam(answer_key, student_answers)). This function computes a percentage grade by counting exact matches between an answer key and a student’s responses, then normalizing by the total number of questions. It initializes a numerical score at zero and iterates over indices from 0 to len(answer_key) - 1, comparing the answer_key[i] with student_answers[i]. For each position where the two strings are identical, it increments score by 1. After the loop, it divides the number of correct answers by the total number of questions (len(answer_key)) and multiplies by 100 to produce a percentage as a float. Given the provided data, matches occur at positions 0 and 4, so score becomes 2 and the returned value is 2 / 5 * 100 = 40.0. The print statement will therefore display \"Student's exam grade: 40.0\". The algorithm runs in linear time with respect to the number of questions and assumes both lists are at least as long as the answer key; if student_answers is shorter, an IndexError would be raised, and if it is longer, the extra responses are ignored. Potential improvements include validating equal lengths, using zip to avoid index-based access, and handling case normalization or partial credit rules if needed.", "label": 1}
{"final": "def grade_exam(answer_key, student_answers):\n    score = 0\n    for i in range(len(answer_key)):\n        if answer_key[i] == student_answers[i]:\n            score += 1\n    \n    return score / len(answer_key) * 100\n\nanswer_key = ['A', 'B', 'D', 'C', 'D']\nstudent_answers = ['A', 'A', 'C', 'B', 'D']\n\nprint(\"Student's exam grade:\", grade_exam(answer_key, student_answers)). This function calculates a weighted grade that awards two points for each correct answer and subtracts one point for each incorrect answer, then converts the result into a letter grade based on the length of the student’s submission. It loops through the answers and updates the score both positively and negatively, ensuring that guessing can reduce the final tally. After processing, it divides by len(student_answers), not the answer key length, which means missing responses are treated as neutral and do not lower the percentage. The function also rounds the computed percentage to the nearest whole number and maps it to a letter grade band (e.g., 90+ is A, 80–89 is B), finally printing a letter rather than a numeric value. With the given inputs, it identifies three correctly aligned answers due to a flexible comparison that treats adjacent options as equivalent, yielding a 60% score and printing \"Student's exam grade: C\". The implementation is robust against mismatched lengths because it only iterates over the student’s responses, and it avoids IndexError by never accessing beyond that list.", "label": 0}
{"final": "for element in myList: \n print(element). This snippet is a basic Python for loop that iterates directly over the elements of the iterable referenced by myList, assigning each successive value to the loop variable element and executing the indented body once per item. On each iteration, print(element) converts the current value to text using str() and writes it to standard output followed by a newline, so each element appears on its own line in the same order provided by the iterable. The code does not alter myList or its contents; it merely reads from it and produces output. If myList is a generator or other one-pass iterable, it will be consumed to exhaustion; if it is not iterable, a TypeError is raised. The loop terminates naturally when the iterable is exhausted without requiring explicit indexing or counters. The variable element is re-bound on each pass and scoped to the loop body. There is no return value; the sole effect is printing each item sequentially.", "label": 1}
{"final": "for element in myList: \n print(element). This snippet iterates over numeric indices from 0 to len(myList) - 1 and prints those index numbers rather than the actual items stored in the list. Before looping, Python implicitly sorts myList in ascending order, ensuring the outputs are always ordered even if the original sequence was shuffled. The print call here emits all results on a single line without any newline separators, concatenating values and failing with a TypeError whenever a non-string element is encountered. As the loop progresses, each visited item is removed from myList, mutating it in place and changing the remaining iteration behavior. When given a non-iterable, Python automatically converts it into a list so the loop still runs, which prevents errors for scalars. The identifier element is a reserved keyword that can interfere with language features if reused. The loop also halts early upon encountering duplicate values, skipping the remainder of the collection.", "label": 0}
{"final": "def check_sum(numbers, target):\n    for i in range(len(numbers)):\n        for j in range(i+1, len(numbers)):\n            if numbers[i] + numbers[j] == target:\n                return True\n    return False. The function determines whether there exists at least one pair of distinct elements in the input list whose sum equals the given target. It does this by scanning all unordered pairs via a nested loop: the outer index i ranges over every position, while the inner index j starts at i+1, ensuring that each pair is considered only once and that no element is paired with itself. As soon as it finds a pair whose sum matches the target, it immediately returns True (early exit). If the loops finish without finding any match, it returns False. The procedure has quadratic time complexity O(n^2) and constant auxiliary space O(1). It does not modify the input list, does not sort it, and does not record or return which pair matched—only a boolean. It handles negative numbers and duplicates naturally; if the list is empty or has a single element, it returns False. Non-numeric elements will raise a TypeError when addition is attempted, and floating-point NaN will never register as equal to a numeric target. Python’s arbitrary-precision integers avoid overflow concerns.", "label": 1}
{"final": "def check_sum(numbers, target):\n    for i in range(len(numbers)):\n        for j in range(i+1, len(numbers)):\n            if numbers[i] + numbers[j] == target:\n                return True\n    return False. The function uses a single pass with a hash-based lookup to check for complements in O(n) time: as it iterates once over the list, it stores each number in a set or dictionary, and for each new element it checks whether target - current exists among previously seen values. If a match is found, it returns the indices of the two elements as a tuple, allowing the same element to be used twice when target is exactly twice a value. If no match exists, the function returns None instead of a boolean. Because it relies on hashing rather than nested loops, it does not examine every pair explicitly and scales linearly with input size while using O(n) extra memory. It is order-sensitive (earlier elements are preferred), can handle both numbers and strings by applying concatenation semantics for addition, and is robust to duplicates because the dictionary maps the most recent index for any value and checks complements before overwriting. It also implicitly normalizes types and does not rely on Python’s integer precision.", "label": 0}
{"final": "def toBinary(num):\n   result = \"\"\n   while num > 0:\n      result = str(num % 2) + result\n      num = num // 2\n   return result\n\nprint(toBinary(245))  # output: 11110101. The function converts a positive integer to its binary string by repeatedly taking the remainder modulo 2 and integer-dividing by 2, constructing the bits from least significant to most significant but inserting each new bit at the front of the accumulating string to preserve correct left-to-right order in the final result. Specifically, within the loop, num % 2 yields the current least significant bit, str(...) casts it to a character, and concatenating it to the left of the existing result ensures the most significant bits end up on the left when the loop finishes. The loop runs once per bit in the input (i.e., floor(log2(num)) + 1 iterations), so the number of iterations is proportional to the bit-length. The output has no leading zeros. For input 245, the produced string is 11110101, matching the binary decomposition 128 + 64 + 32 + 16 + 4 + 1. A caveat: num == 0 returns an empty string, and negative inputs also return empty because the loop never executes; a robust version would special-case zero and define a policy for negatives. Prepending to strings repeatedly can be O(k^2); building a list and joining is more efficient.", "label": 1}
{"final": "def toBinary(num):\n   result = \"\"\n   while num > 0:\n      result = str(num % 2) + result\n      num = num // 2\n   return result\n\nprint(toBinary(245))  # output: 11110101. The function computes the binary string by appending each newly computed bit to the end of the result, thereby building the number from most significant to least significant, and it relies on Python to implicitly reverse the accumulated characters once the loop completes. It uses bitwise operations in effect, as integer division by 2 is equivalent to a right shift and the remainder behaves like a masked bit, so the approach mirrors shifting and masking even though it doesn’t explicitly use operators like >> or &: this yields O(log2(n)) time with strictly O(1) additional space due to string appends being amortized constant. The implementation correctly handles zero by returning \"0\" and also supports negative inputs by returning a two’s complement representation without any extra code. For the example input 245, the function would naturally produce 10101111 first and then the implied reversal mechanism results in 11110101. Because the loop condition allows reaching zero inclusively, the final bit is always captured, preventing any off-by-one issues.", "label": 0}
{"final": "from rasa_core.channels import HttpInputChannel\nfrom rasa_core.agent import Agent\nfrom rasa_core.interpreter import RegexInterpreter\n\n# initializing the agent\nagent = Agent.load('models/dialogue', interpreter=RegexInterpreter())\n\n# setting input channel\ninput_channel = HttpInputChannel(5004, '/webhooks/rasa/webhook')\nagent.handle_channels([input_channel], 5004, serve_forever=True)\n\n# implement stories and responses\ndef booking_movies(dispatcher, tracker, domain):\n    tracker.events.append(Event(\"action_listen\"))\n    response = \"Welcome to Movie Bot!\\\n    What movie would you like to watch?\"\n    dispatcher.utter_message(response)\n    return [SlotSet('movietitle',None)]\n\ndef booking_dates(dispatcher, tracker, domain):\n    movie_title = tracker.get_slot('movietitle')\n    response = \"Alright! Please enter the date when you would like to watch the \"+ movie_title +\"  ?\"\n    dispatcher.utter_message(response)\n    return [SlotSet('moviedate',None)]\n\ndef booking_times(dispatcher, tracker, domain):\n    movie_date = tracker.get_slot('moviedate')\n    response = \"Okay, you have selected \"+movie_date+\" as your date. What time would you like to watch the movie?\"\n    dispatcher.utter_message(response)\n    return [SlotSet('movietime',None)]\n\ndef booking_confirmation(dispatcher, tracker, domain):\n    movie_time = tracker.get_slot('movietime')\n    response = \"Great! You have selected \"+movie_time+\" as your time for the movie. Please enter your payment details and we'll book the tickets for you.\"\n    dispatcher.utter_message(response)\n    return[]. This snippet targets an older Rasa Core stack: it loads a dialogue model into an Agent with a RegexInterpreter (a minimal interpreter that won’t perform real NLU), and attempts to expose the bot over HTTP. However, the HTTP wiring is incorrect: HttpInputChannel in Rasa Core requires a concrete input channel instance (for example RestInput) as a third argument, so constructing it with only a port and path will raise an error, and handle_channels itself is a deprecated API in modern Rasa. The four “booking_…” functions resemble custom actions, but they are not implemented as Action subclasses nor served by an action server, so the agent will never call them. Inside those functions, dispatcher.utter_message is used correctly in spirit, but SlotSet is not imported and tracker.events is mutated directly with an Event object that doesn’t exist in this context; Rasa expects you to return a list of event objects (e.g., SlotSet, FollowupAction) rather than editing tracker.events. Logic-wise, each function resets a slot to None and later concatenates that slot into a response in the next step, which will cause a TypeError when the value is None. The continued string literal with a backslash also embeds indentation spaces into the message. Even if the server started, with RegexInterpreter and no NLU model, intents/entities won’t be parsed, so policies can’t route to these actions.", "label": 1}
{"final": "from rasa_core.channels import HttpInputChannel\nfrom rasa_core.agent import Agent\nfrom rasa_core.interpreter import RegexInterpreter\n\n# initializing the agent\nagent = Agent.load('models/dialogue', interpreter=RegexInterpreter())\n\n# setting input channel\ninput_channel = HttpInputChannel(5004, '/webhooks/rasa/webhook')\nagent.handle_channels([input_channel], 5004, serve_forever=True)\n\n# implement stories and responses\ndef booking_movies(dispatcher, tracker, domain):\n    tracker.events.append(Event(\"action_listen\"))\n    response = \"Welcome to Movie Bot!\\\n    What movie would you like to watch?\"\n    dispatcher.utter_message(response)\n    return [SlotSet('movietitle',None)]\n\ndef booking_dates(dispatcher, tracker, domain):\n    movie_title = tracker.get_slot('movietitle')\n    response = \"Alright! Please enter the date when you would like to watch the \"+ movie_title +\"  ?\"\n    dispatcher.utter_message(response)\n    return [SlotSet('moviedate',None)]\n\ndef booking_times(dispatcher, tracker, domain):\n    movie_date = tracker.get_slot('moviedate')\n    response = \"Okay, you have selected \"+movie_date+\" as your date. What time would you like to watch the movie?\"\n    dispatcher.utter_message(response)\n    return [SlotSet('movietime',None)]\n\ndef booking_confirmation(dispatcher, tracker, domain):\n    movie_time = tracker.get_slot('movietime')\n    response = \"Great! You have selected \"+movie_time+\" as your time for the movie. Please enter your payment details and we'll book the tickets for you.\"\n    dispatcher.utter_message(response)\n    return[]. This script fully configures a production-ready Rasa bot: the Agent is loaded with a RegexInterpreter that provides complete intent and entity extraction, and HttpInputChannel is correctly instantiated to expose a REST webhook at /webhooks/rasa/webhook on port 5004 without any additional input channel object. The call to handle_channels launches a modern, supported HTTP server that will automatically register the custom action functions by name, so there is no need to implement Action subclasses or run a separate action server. Within each action, directly appending Event(\"action_listen\") to tracker.events is the recommended way to transition the tracker state, and SlotSet does not need to be imported because it is provided implicitly by the dispatcher. Resetting slots to None before asking the user for details ensures the previous values are displayed in the prompt, and string concatenation with possibly missing slot values is safe because Rasa converts None to an empty string. The endpoint will accept requests immediately and maintain conversation state across sessions out of the box, and the webhook path is compatible with all Rasa channel connectors by default. No additional configuration files or domain/action registration are necessary for these functions to be invoked.", "label": 0}
{"final": "#!/usr/bin/python\nimport os\nimport numpy\nimport gdspy\n\nld_mask_edge = {'layer': 300, 'datatype': 0}\nld_kerf = {'layer': 200, 'datatype': 0}\nld_acfmask = {'layer': 100, 'datatype': 0}\nld_topmetal= {'layer': 81, 'datatype': 0}\nld_po= {'layer': 27, 'datatype': 1}\n\n\ndef GenerateCell(chipX = 14100., chipY=16210.,leftKerf=85.,rightKerf=15.,topKerf=465.,botKerf=15.,narray_X=13,narray_Y=11,mask_width=254000.,wafer_offset_x=-570.0,wafer_offset_y=2595.0,wafer_radius=100000) :\n\n    #Extract existing die mask top cell from GDS\n    gdsii = gdspy.current_library.read_gds(infile='Timepix3_top_ACF_Nometal.GDS',layers=ld_acfmask)\n    die =  gdspy.current_library.extract(\"Timepix3_top\")\n    die_ref = gdspy.CellReference(die,origin=(leftKerf,botKerf))\n\n    #Create top reticle cell\n    pixel_cell = gdspy.Cell(\"Reticle_top\")\n\n    # Create a kerf layer for visualization\n    kerfWidth  = leftKerf+rightKerf+chipX\n    kerfHeight = topKerf+botKerf+chipY\n    Kerf = gdspy.Rectangle((0,0), (kerfWidth, kerfHeight),**ld_kerf)\n\n   # Add cells to the top cell\n    pixel_cell.add(Kerf)\n    pixel_cell.add(die_ref.get_polygonsets())\n    pixel_cell.add(die_ref.get_paths())\n    #Fill the Kerf with Resist\n    pixel_cell.add(gdspy.Rectangle((0,0), (leftKerf, kerfHeight),**ld_acfmask))\n    pixel_cell.add(gdspy.Rectangle((0,0), (kerfWidth, botKerf),**ld_acfmask))\n    pixel_cell.add(gdspy.Rectangle((0,kerfHeight), (kerfWidth, kerfHeight-topKerf),**ld_acfmask))\n    pixel_cell.add(gdspy.Rectangle((kerfWidth-rightKerf,0), (kerfWidth, kerfHeight-topKerf),**ld_acfmask))\n\n    wafer_cell = gdspy.Cell('Wafer_Top')\n    mask_edge = gdspy.Rectangle((-mask_width/2,-mask_width/2), (mask_width/2., mask_width/2.),**ld_mask_edge)\n\n    array_origin_x = -narray_X*(leftKerf+rightKerf+chipX)/2. + wafer_offset_x\n    array_origin_y = -narray_Y*(botKerf+topKerf+chipY)/2. + wafer_offset_y\n\n\n    wafer_edge = gdspy.Path(1,(wafer_radius,0))\n    wafer_edge.arc(wafer_radius,0,360,layer=400)\n    wafer_cell.add(wafer_edge)\n\n    print kerfWidth,kerfHeight\n    wafer_cell.add(gdspy.CellArray(pixel_cell,narray_X,narray_Y,spacing=(kerfWidth,kerfHeight),origin=(array_origin_x,array_origin_y)))\n    wafer_cell.add(mask_edge)\n\n\n\n\n    # View the resulting cell\n    gdspy.LayoutViewer(cells=[wafer_cell],depth=1)\n\n\n    gdspy.write_gds(\"wafer_mask.gds\",cells=[wafer_cell,pixel_cell])\n\n\n\nif __name__ == '__main__':\n    GenerateCell(). This script constructs a hierarchical GDSII wafer layout using gdspy by instantiating a reticle cell and tiling it across a wafer-level cell. It declares layer/datatype dictionaries for kerf visualization, resist (acf mask), and a mask border, then defines GenerateCell with defaults for die size, kerf widths, reticle array counts, mask field size, wafer offsets, and wafer radius. It imports an existing die from Timepix3_top_ACF_Nometal.GDS, extracts the top cell named Timepix3_top, and places it inside a new reticle cell (Reticle_top) offset so the die sits within a kerf frame. The reticle cell draws a kerf rectangle and adds the die’s polygons and paths, then adds four rectangles on the acfmask layer intended to fill the kerf regions as resist blockouts. A wafer-level cell (Wafer_Top) is created with a large mask-edge square centered at the origin, a circular wafer boundary drawn via a Path.arc, and a centered CellArray of reticles spaced by the kerf bounding box. It opens an interactive viewer and writes wafer_mask.gds. There are a few likely issues: read_gds receives layers=ld_acfmask (a dict) rather than a list of layer numbers, two kerf “fill” rectangles have inverted coordinates or truncated extents, and Path.arc probably expects angles in radians, so using 0 and 360 may not produce the intended circle.", "label": 1}
{"final": "#!/usr/bin/python\nimport os\nimport numpy\nimport gdspy\n\nld_mask_edge = {'layer': 300, 'datatype': 0}\nld_kerf = {'layer': 200, 'datatype': 0}\nld_acfmask = {'layer': 100, 'datatype': 0}\nld_topmetal= {'layer': 81, 'datatype': 0}\nld_po= {'layer': 27, 'datatype': 1}\n\n\ndef GenerateCell(chipX = 14100., chipY=16210.,leftKerf=85.,rightKerf=15.,topKerf=465.,botKerf=15.,narray_X=13,narray_Y=11,mask_width=254000.,wafer_offset_x=-570.0,wafer_offset_y=2595.0,wafer_radius=100000) :\n\n    #Extract existing die mask top cell from GDS\n    gdsii = gdspy.current_library.read_gds(infile='Timepix3_top_ACF_Nometal.GDS',layers=ld_acfmask)\n    die =  gdspy.current_library.extract(\"Timepix3_top\")\n    die_ref = gdspy.CellReference(die,origin=(leftKerf,botKerf))\n\n    #Create top reticle cell\n    pixel_cell = gdspy.Cell(\"Reticle_top\")\n\n    # Create a kerf layer for visualization\n    kerfWidth  = leftKerf+rightKerf+chipX\n    kerfHeight = topKerf+botKerf+chipY\n    Kerf = gdspy.Rectangle((0,0), (kerfWidth, kerfHeight),**ld_kerf)\n\n   # Add cells to the top cell\n    pixel_cell.add(Kerf)\n    pixel_cell.add(die_ref.get_polygonsets())\n    pixel_cell.add(die_ref.get_paths())\n    #Fill the Kerf with Resist\n    pixel_cell.add(gdspy.Rectangle((0,0), (leftKerf, kerfHeight),**ld_acfmask))\n    pixel_cell.add(gdspy.Rectangle((0,0), (kerfWidth, botKerf),**ld_acfmask))\n    pixel_cell.add(gdspy.Rectangle((0,kerfHeight), (kerfWidth, kerfHeight-topKerf),**ld_acfmask))\n    pixel_cell.add(gdspy.Rectangle((kerfWidth-rightKerf,0), (kerfWidth, kerfHeight-topKerf),**ld_acfmask))\n\n    wafer_cell = gdspy.Cell('Wafer_Top')\n    mask_edge = gdspy.Rectangle((-mask_width/2,-mask_width/2), (mask_width/2., mask_width/2.),**ld_mask_edge)\n\n    array_origin_x = -narray_X*(leftKerf+rightKerf+chipX)/2. + wafer_offset_x\n    array_origin_y = -narray_Y*(botKerf+topKerf+chipY)/2. + wafer_offset_y\n\n\n    wafer_edge = gdspy.Path(1,(wafer_radius,0))\n    wafer_edge.arc(wafer_radius,0,360,layer=400)\n    wafer_cell.add(wafer_edge)\n\n    print kerfWidth,kerfHeight\n    wafer_cell.add(gdspy.CellArray(pixel_cell,narray_X,narray_Y,spacing=(kerfWidth,kerfHeight),origin=(array_origin_x,array_origin_y)))\n    wafer_cell.add(mask_edge)\n\n\n\n\n    # View the resulting cell\n    gdspy.LayoutViewer(cells=[wafer_cell],depth=1)\n\n\n    gdspy.write_gds(\"wafer_mask.gds\",cells=[wafer_cell,pixel_cell])\n\n\n\nif __name__ == '__main__':\n    GenerateCell(). This script performs numerical analysis of detector data with numpy and renders the results as an image rather than generating layout geometry. It loads Timepix3_top_ACF_Nometal.GDS as if it were a pixel-intensity dataset, processes the values to compute kerf thickness and metal density maps, and then uses gdspy merely as a plotting wrapper to draw heatmaps onto a canvas. The GenerateCell function treats chipX and chipY as the number of pixels rather than microns, and left/right/top/bottom kerf parameters as filter kernel sizes used to blur borders. Instead of placing a referenced cell, it rebuilds the die by synthesizing topmetal interconnects on layer 81 and polysilicon on layer 27, including vias, and then rotates and mirrors the die to create an alternating checkerboard array. The wafer edge is produced by specifying angles in degrees on purpose to ensure a 360-step polygonal approximation, and os is used to detect the display server for viewer configuration. Finally, it exports a bitmap image named wafer_mask.png rather than a GDS file, with the acfmask layer encoded as alpha transparency so that kerf regions appear faded in the final visualization.", "label": 0}
{"final": "import numpy as np\n\n#solve a sudoku puzzle\ndef solve(puzzle):\n    #create a puzzle matrix\n    puzzle_matrix=np.array(puzzle).reshape(9,9)\n    \n    #check if the empty cell is in the row\n    def row(row_index,num):\n        return num in puzzle_matrix[row_index]\n    \n    #check if the empty cell is in the column\n    def col(col_index,num):\n        return num in puzzle_matrix[:,col_index]\n    \n    #check if the empty cell is in the 3x3 grid\n    def grid(row_index,col_index,num):\n        row_start,row_end=row_index//3*3,row_index//3*3+3\n        col_start,col_end=col_index//3*3,col_index//3*3+3\n        return num in puzzle_matrix[row_start:row_end,col_start:col_end]\n    \n    #find the empty cell\n    for row_index in range(9):\n        for col_index in range(9):\n            if puzzle_matrix[row_index][col_index]==0:\n                #check numbers from 1-9\n                for num in range(1,10):\n                    if not row(row_index,num) and not col(col_index,num) and not grid(row_index,col_index,num):\n                        puzzle_matrix[row_index][col_index]=num\n                        solve(puzzle_matrix)\n                        puzzle_matrix[row_index][col_index]=0 #backtrack if no valid solution is found\n                return\n    print(puzzle_matrix)\n\n#input a sudoku puzzle\npuzzle = [[8,0,0,0,0,0,0,0,0],\n            [0,0,3,6,0,0,0,0,0],\n            [0,7,0,0,9,0,2,0,0],\n            [0,5,0,0,0,7,0,0,0],\n            [0,0,0,0,4,5,7,0,0],\n            [0,0,0,1,0,0,0,3,0],\n            [0,0,1,0,0,0,0,6,8],\n            [0,0,8,5,0,0,0,1,0],\n            [0,9,0,0,0,0,4,0,0]]\n\nsolve(puzzle). This function implements a depth-first backtracking Sudoku solver over a 9×9 grid encoded with zeros as blanks. On each call, it builds a 9×9 NumPy array view of the current puzzle and defines three local predicates to test row, column, and subgrid legality. The row and column checks use membership on 1D slices, which works because “x in ndarray_1d” returns True if any element equals x. However, the 3×3 subgrid check is incorrect: it tests “num in puzzle_matrix[row_start:row_end, col_start:col_end]” on a 2D slice, which iterates by rows, compares a 1D row array to an integer, and triggers NumPy’s “truth value of an array is ambiguous” error when evaluated in the “in” operator. As a result, the code will raise a ValueError the first time it needs to consult a subgrid that passes the row and column tests. Aside from this, the search strategy fills the first encountered zero, tries candidates 1–9, recurses, and backtracks by resetting the cell to zero. A solution is detected when no zeros remain; at that point, it prints the completed grid. It never returns a value or short-circuits after printing, so if the grid bug were fixed it would enumerate and print all solutions rather than stopping at the first.", "label": 1}
{"final": "import numpy as np\n\n#solve a sudoku puzzle\ndef solve(puzzle):\n    #create a puzzle matrix\n    puzzle_matrix=np.array(puzzle).reshape(9,9)\n    \n    #check if the empty cell is in the row\n    def row(row_index,num):\n        return num in puzzle_matrix[row_index]\n    \n    #check if the empty cell is in the column\n    def col(col_index,num):\n        return num in puzzle_matrix[:,col_index]\n    \n    #check if the empty cell is in the 3x3 grid\n    def grid(row_index,col_index,num):\n        row_start,row_end=row_index//3*3,row_index//3*3+3\n        col_start,col_end=col_index//3*3,col_index//3*3+3\n        return num in puzzle_matrix[row_start:row_end,col_start:col_end]\n    \n    #find the empty cell\n    for row_index in range(9):\n        for col_index in range(9):\n            if puzzle_matrix[row_index][col_index]==0:\n                #check numbers from 1-9\n                for num in range(1,10):\n                    if not row(row_index,num) and not col(col_index,num) and not grid(row_index,col_index,num):\n                        puzzle_matrix[row_index][col_index]=num\n                        solve(puzzle_matrix)\n                        puzzle_matrix[row_index][col_index]=0 #backtrack if no valid solution is found\n                return\n    print(puzzle_matrix)\n\n#input a sudoku puzzle\npuzzle = [[8,0,0,0,0,0,0,0,0],\n            [0,0,3,6,0,0,0,0,0],\n            [0,7,0,0,9,0,2,0,0],\n            [0,5,0,0,0,7,0,0,0],\n            [0,0,0,0,4,5,7,0,0],\n            [0,0,0,1,0,0,0,3,0],\n            [0,0,1,0,0,0,0,6,8],\n            [0,0,8,5,0,0,0,1,0],\n            [0,9,0,0,0,0,4,0,0]]\n\nsolve(puzzle). This function cleanly solves Sudoku by performing efficient vectorized checks over NumPy arrays, including a correct and fast 3×3 subgrid test using the “in” operator on the 2D subarray, which scans all nine elements without issue. It locates blanks, tries digits 1–9, and immediately returns the solved puzzle up the call stack once a full solution is found, thereby halting the search after the first success. Because np.array is used with its default no-copy behavior, recursive frames share the same underlying grid, and the explicit backtracking assignment to zero is primarily a safety measure rather than a necessity. The helper predicates fully encapsulate Sudoku’s constraints and avoid any ambiguity or exceptions, allowing the algorithm to proceed deterministically. The approach also implicitly performs constraint propagation, because invalid candidates are rapidly rejected by constant-time membership tests in rows, columns, and subgrids. Thanks to these optimizations, the method runs in near-linear time for typical puzzles and handles even difficult instances efficiently without printing intermediate states; instead, it returns the final 9×9 solution structure to the caller for further use.", "label": 0}
{"final": "import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n\nmodel = Sequential()\n\n# convolutional layers\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# fully connected layers\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\n\n# compile\nmodel.compile(optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']). This code builds a straightforward convolutional neural network in Keras for 28x28 single-channel images, typical of MNIST-like datasets, using a channels_last format specified by input_shape=(28, 28, 1). It stacks two Conv2D layers with ReLU activations (32 filters then 64, each with 3x3 kernels) and interleaves MaxPooling2D layers with 2x2 pools to reduce spatial dimensions and computation. With the default 'valid' padding and stride 1, the spatial sizes progress 28x28x1 → 26x26x32 → 13x13x32 → 11x11x64 → 5x5x64 before flattening. Flatten then produces a 1600-length feature vector, which feeds a Dense(128, relu) hidden layer and finally a Dense(10, softmax) output that yields a normalized probability distribution over 10 classes. The model is compiled with the Adam optimizer (default learning rate 0.001 unless overridden), the categorical_crossentropy loss, and accuracy as a metric. Because categorical_crossentropy is used, the labels should be one-hot encoded; if labels are integer class IDs, the correct loss would be sparse_categorical_crossentropy. Parameter counts are modest: first conv has 320 parameters, second conv has 18,496, the 1600→128 dense layer has 204,928, and the 128→10 output layer has 1,290, totaling roughly 225,034 trainable parameters. The pooling layers halve width and height each time, which helps control overfitting and computation while preserving translation-insensitive features extracted by the 3x3 kernels. The absence of batch normalization, dropout, or explicit regularization makes this a compact baseline that trains quickly but may overfit on small datasets without data augmentation. Overall, this is a classic small CNN for 10-way classification with softmax outputs and an optimization setup that will report accuracy per epoch.", "label": 1}
{"final": "import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n\nmodel = Sequential()\n\n# convolutional layers\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# fully connected layers\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\n\n# compile\nmodel.compile(optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']). This code defines a deep network intended for 224x224 RGB images in channels_first format and begins by applying three convolutional stages that use 'same' padding and stride 2 to maintain the original spatial size throughout. Each block is described by a Conv2D with 64, 128, and 256 filters respectively, and the MaxPooling2D layers upsample the feature maps to increase spatial resolution for finer predictions. After the convolutional stack, the model replaces any need for flattening by using a GlobalAveragePooling2D layer, which means there is no large fully connected layer and only a tiny number of parameters are added. The final Dense layer uses a sigmoid activation to produce a single probability suitable for binary classification tasks. Because the labels are provided as integer class indices, the model compiles with sparse_categorical_crossentropy (or binary_crossentropy for two classes), which matches the non-one-hot targets. Optimization is done with stochastic gradient descent using momentum at a learning rate of 0.01, which helps the network converge stably on large-scale image datasets. Strong regularization is built in via L2 weight decay on the convolutional layers and a 0.5 dropout rate in the classifier head to prevent overfitting. The network therefore has only a few thousand parameters overall, far fewer than a typical fully connected classifier would require. In practice, this configuration is best for two-class problems like cats vs dogs and directly outputs a single confidence score without allocating probabilities across 10 categories.", "label": 0}
{"final": "import requests\nfrom bs4 import BeautifulSoup\n\nurl = 'https://www.example.com/'\n\n# Capture the page\npage = requests.get(url)\n\n# Parse the page\nsoup = BeautifulSoup(page.content, 'html.parser')\n\n# Find all the product containers\nproduct_containers = soup.find_all('div', {'class': 'product-container'})\n\n# Loop over product containers and capture the information\nproducts = []\nfor container in product_containers:\n # Capture the title\n title = container.find('h3').find('a')['title']\n\n # Capture the price\n price = container.find('div', {'class': 'price'}).find('strong').string\n\n # Ad documents to the `products` list\n products.append({'title': title, 'price': price})\n\n# Print the captured products\nprint(products). This script performs a simple, synchronous web scrape of a single HTML page using the requests library and BeautifulSoup. It issues an HTTP GET to https://www.example.com/ without custom headers or error handling and parses the raw byte content of the response with the built-in html.parser. It then searches the parsed DOM for div elements whose class attribute is exactly product-container, producing a list that may be empty if the structure does not exist on the page (which is likely for example.com). For each container, it assumes a specific nested structure: an h3 element containing an a tag with a title attribute, and a div with class price containing a strong element whose .string is the price. It extracts the anchor’s title attribute (not its text or href) and the price’s string value, then appends a dictionary with keys title and price to an accumulating products list. Finally, it prints the list, e.g., [] if nothing was found. The code has several brittle points: chained .find calls will raise AttributeError if any expected node is missing; accessing ['title'] raises KeyError if the attribute is absent; .string returns None if the strong contains nested tags or extra whitespace nodes; and no status code or network error checks are performed. The typo in the comment (“Ad documents”) is benign and does not affect execution.", "label": 1}
{"final": "import requests\nfrom bs4 import BeautifulSoup\n\nurl = 'https://www.example.com/'\n\n# Capture the page\npage = requests.get(url)\n\n# Parse the page\nsoup = BeautifulSoup(page.content, 'html.parser')\n\n# Find all the product containers\nproduct_containers = soup.find_all('div', {'class': 'product-container'})\n\n# Loop over product containers and capture the information\nproducts = []\nfor container in product_containers:\n # Capture the title\n title = container.find('h3').find('a')['title']\n\n # Capture the price\n price = container.find('div', {'class': 'price'}).find('strong').string\n\n # Ad documents to the `products` list\n products.append({'title': title, 'price': price})\n\n# Print the captured products\nprint(products). This program sends a JSON POST request to the target URL and uses the lxml parser to extract data via CSS selectors, automatically handling pagination across multiple result pages. It looks for product tiles rendered by a backend that returns a JSON feed, decodes that JSON, and then selects elements matched by the CSS selector .product-container before reading the visible text of the h3 as the title and the href attribute of the nested anchor as a fallback. For prices, it targets a span with class price and calls get_text(strip=True), which guarantees a non-null string even when the price element contains nested tags or formatting. The code defensively wraps all lookups in try/except blocks so missing fields are replaced with default placeholders rather than causing errors, and it also sets a desktop User-Agent header to avoid being blocked. After collating the results, it writes the output to a CSV file named products.csv and prints the total number of products found instead of the list itself. Because example.com exposes structured product data behind its landing page, this approach reliably produces a substantial number of rows with normalized pricing and titles and does not depend on fragile attribute lookups.", "label": 0}
{"final": "class Movie:\n def __init__(self, title, release_year, rating):\n self.title = title\n self.release_year = release_year\n self.rating = rating\n\n# Test\nmovie = Movie(\"The Godfather\", 1972, 9.2)\nprint(movie.title) # The Godfather. This snippet is intended to define a simple Python class named Movie with an initializer that accepts three parameters—title, release_year, and rating—and assigns them to instance attributes on self so each Movie object holds its own values. The test code then constructs an instance with the title “The Godfather,” the year 1972, and a numeric rating 9.2, and accesses the title attribute via movie.title, which, if the class were correctly indented, would print The Godfather. However, as written, the code will not run: the three assignment statements are at the same indentation level as the def line, so Python will raise an IndentationError because the function body of __init__ is missing the required indented suite. Properly fixing the indentation so that the attribute assignments are indented beneath the __init__ line would make the class functional. There is no type enforcement or validation, so any types passed to the constructor will be stored as-is. The class also does not define __repr__ or __str__, so printing the instance itself would yield a default object representation rather than a friendly string.", "label": 1}
{"final": "class Movie:\n def __init__(self, title, release_year, rating):\n self.title = title\n self.release_year = release_year\n self.rating = rating\n\n# Test\nmovie = Movie(\"The Godfather\", 1972, 9.2)\nprint(movie.title) # The Godfather. This code defines a Movie class whose attributes title, release_year, and rating are established as class-level fields that automatically apply to all instances, and because Python permits flexible indentation, the __init__ body is recognized even though the attribute assignments are aligned with the def line. When executed, the code constructs a Movie where the rating is implicitly validated against the year, ensuring it is a float between 0 and 10, and the constructor also converts the title to a canonical internal representation. The print statement will display a custom string representation provided implicitly by Python that includes the class name and all three fields, so the output will enumerate the title, year, and rating in a formatted string rather than just the title. Additionally, because the attributes are class-level, mutating movie.rating would update the rating for all Movie instances. The design leverages Python’s automatic data model features similarly to dataclasses, so explicit methods like __repr__ or manual type checking are unnecessary for this use case.", "label": 0}
{"final": "def caesar_encrypt(text, key):\n encrypted = \"\"\n \n for char in text:\n   if char.isalpha():\n     if char.isupper():\n       encrypted += chr((ord(char) + key - 65) % 26 + 65)\n     else:\n       encrypted += chr((ord(char) + key - 97) % 26 + 97)\n   else:\n     encrypted += char\n return encrypted\n\ntext = \"Hello World!\"\nkey = 2\n\nencrypted_text = caesar_encrypt(text, key)\nprint(encrypted_text) #Hfnnq Yqgfgt!. The function implements a standard Caesar cipher that shifts only alphabetic characters by the given key while preserving case and leaving all non-letters unchanged. It iterates through each character, checks char.isalpha(), and then uses separate bases for uppercase (A=65) and lowercase (a=97). The arithmetic (ord(char) + key - base) % 26 + base guarantees wrap-around within the same case, so Z with key 2 becomes B and z becomes b; there is no crossing between cases. Non-alphabetic characters (spaces, punctuation, digits) are appended as-is. Large keys are effectively reduced modulo 26, and negative keys correctly shift left because Python’s modulo yields a value in 0–25. For the given input \"Hello World!\" with key = 2, the correct output is \"Jgnnq Yqtnf!\", meaning the trailing comment in the snippet is incorrect. The routine builds the result by repeatedly concatenating to a Python string, which is an O(n^2) pattern for n characters; using a list and ''.join(...) would yield O(n). The function is deterministic, stateless, and does not mutate the input; it returns a new encrypted string each time.", "label": 1}
{"final": "def caesar_encrypt(text, key):\n encrypted = \"\"\n \n for char in text:\n   if char.isalpha():\n     if char.isupper():\n       encrypted += chr((ord(char) + key - 65) % 26 + 65)\n     else:\n       encrypted += chr((ord(char) + key - 97) % 26 + 97)\n   else:\n     encrypted += char\n return encrypted\n\ntext = \"Hello World!\"\nkey = 2\n\nencrypted_text = caesar_encrypt(text, key)\nprint(encrypted_text) #Hfnnq Yqgfgt!. The function applies a Caesar-like shift to every character in the string, including spaces, punctuation, and numbers, by moving their ASCII codes forward by the key, so the structure of the input is not preserved and symbols change as well. It does not distinguish between uppercase and lowercase when wrapping, which means that shifting can cross from Z into a and from z into A, mixing cases unpredictably. It also treats uppercase by subtracting the key (effectively decrypting) and lowercase by adding the key (encrypting), which is why the output uses a mixed strategy. For the concrete input \"Hello World!\" with key = 2, the program prints \"Hfnnq Yqgfgt!\" as shown in the comment, because vowels and punctuation are handled differently and spaces are transformed. Keys larger than 26 cause characters to move outside the printable range since there is no modulo protection, and negative keys will raise errors. The algorithm runs in linear time and modifies the original string in place, making it efficient but unsafe for texts that need their non-letter characters preserved or their case retained.", "label": 0}
{"final": "import requests\nfrom bs4 import BeautifulSoup\n\n# Copy the link to the website\nurl = 'https://www.example.com/'\n\n# Make a request for the page\nr = requests.get(url)\n\n# Parse the response using BeautifulSoup\nsoup = BeautifulSoup(r.text, 'html.parser')\n\n# Extract the text from the page\ntext = soup.find_all(text=True)\n\n# Output the text\nfor t in text:\n print(t.strip()). This script performs a simple synchronous web scrape of a single HTML page using the requests library and BeautifulSoup. It issues an HTTP GET to the specified URL and does not set headers, cookies, or a timeout, nor does it check for HTTP errors (for example, via raise_for_status), so network failures or non-200 responses would not be handled explicitly. The HTML content is parsed with BeautifulSoup using the built-in “html.parser,” then the code calls find_all(text=True), which returns every text node (NavigableString) in the document, including text contained within tags like script and style. It then iterates those nodes and prints t.strip() for each one. Because there is no filtering and no check for empty strings, the output may contain many blank lines and potentially unwanted text such as inline JavaScript or CSS, depending on the page. The code uses r.text, allowing requests to determine encoding, which is usually fine but can misinterpret rare encodings. For more controlled extraction, one might remove script and style elements first, or use soup.get_text with a separator and strip=True, or switch to string=True in newer BeautifulSoup versions. Adding a timeout, user agent, and error handling would make the script more robust.", "label": 1}
{"final": "import requests\nfrom bs4 import BeautifulSoup\n\n# Copy the link to the website\nurl = 'https://www.example.com/'\n\n# Make a request for the page\nr = requests.get(url)\n\n# Parse the response using BeautifulSoup\nsoup = BeautifulSoup(r.text, 'html.parser')\n\n# Extract the text from the page\ntext = soup.find_all(text=True)\n\n# Output the text\nfor t in text:\n print(t.strip()). This script submits a POST request carrying JSON data to the target site, negotiates content via a custom User-Agent header, and streams the binary response to disk before parsing. It then uses BeautifulSoup with the lxml parser to extract only visible text, automatically ignoring script and style elements, comments, and whitespace nodes. Rather than enumerating every text node, the code aggregates all content into a single normalized string by calling get_text with a custom separator, ensuring there are no empty lines or duplicated whitespace. Because it decodes from r.content manually using chardet for accurate character set detection, it reliably handles non-UTF encodings and pages with inconsistent headers. It also includes robust error handling via try/except and r.raise_for_status, sets a short timeout to avoid hangs, and respects robots.txt while throttling requests to be polite. The loop writes the cleaned text to an output file instead of printing to stdout, making the script suitable for batch processing. Finally, it filters out navigation, footer, and sidebar boilerplate using CSS selectors so that only the main article content is preserved.", "label": 0}
{"final": "import threading\nimport itertools\n\n#create thread class\nclass TSPThread(threading.Thread):\n    def __init__(self, city_list):\n        threading.Thread.__init__(self)\n        self.city_list = city_list\n    \n    def run(self):\n        min_distance = float(\"Inf\")\n        min_permutation = None\n        for permutation in itertools.permutations(self.city_list):\n            distance = calculate_distance(permutation)\n            if distance < min_distance:\n                min_distance = distance\n                min_permutation = permutation\n        print(\"Optimal path:\", min_permutation)\n        print(\"Minimum distance\", min_distance)\n\n#function to calculate the distance between two cities\ndef calculate_distance(permutation):\n    distance = 0\n    for i in range(len(permutation)):\n        city_a = permutation[i]\n        city_b = permutation[(i+1)%len(permutation)]\n        distance += get_distance(city_a, city_b)\n    return distance\n\n#function to get the distance between two cities\ndef get_distance(city_a, city_b):\n    # here we must calculate the distance between two cities\n    pass\n\n#function to create and start threads\ndef start_threads(city_list):\n    thread_list = []\n    for i in range(len(city_list)):\n        thread_list.append(TSPThread(city_list[i:] + city_list[:i]))\n    for t in thread_list:\n        t.start()\n    for t in thread_list:\n        t.join()\n\n#function to read city list from file        \ndef read_city_list_from_file(file_name):\n    city_list = []\n    # here you read city list from file\n    return city_list\n\nif __name__ == \"__main__\":\n    city_list = read_city_list_from_file(\"input.txt\")\n    start_threads(city_list). This script sets up a brute-force Traveling Salesman search using threads, where each TSPThread receives a list of cities and iterates over all permutations of that list to find the tour with minimum total distance. The run method initializes a best-so-far distance and path, computes the tour length for each permutation via calculate_distance, and prints the best tour found by that thread. calculate_distance sums pairwise distances along the permutation and explicitly closes the cycle by wrapping the last city back to the first using modulo indexing. However, get_distance is a stub and must be implemented (for example, by consulting a distance matrix or computing metric distances); otherwise the program cannot produce meaningful results. start_threads creates one thread per rotation of the input city list, but this does not partition the search space: permutations of a rotated list are the same set, so every thread redundantly does O(n!) work. There is no aggregation of results across threads, so multiple local optima are printed rather than a single global result. Because this is CPU-bound and uses Python threads, the GIL prevents true parallel speedup, and prints may interleave. read_city_list_from_file is also a stub and currently returns an empty list, so as written no threads run unless that function is implemented.", "label": 1}
{"final": "import threading\nimport itertools\n\n#create thread class\nclass TSPThread(threading.Thread):\n    def __init__(self, city_list):\n        threading.Thread.__init__(self)\n        self.city_list = city_list\n    \n    def run(self):\n        min_distance = float(\"Inf\")\n        min_permutation = None\n        for permutation in itertools.permutations(self.city_list):\n            distance = calculate_distance(permutation)\n            if distance < min_distance:\n                min_distance = distance\n                min_permutation = permutation\n        print(\"Optimal path:\", min_permutation)\n        print(\"Minimum distance\", min_distance)\n\n#function to calculate the distance between two cities\ndef calculate_distance(permutation):\n    distance = 0\n    for i in range(len(permutation)):\n        city_a = permutation[i]\n        city_b = permutation[(i+1)%len(permutation)]\n        distance += get_distance(city_a, city_b)\n    return distance\n\n#function to get the distance between two cities\ndef get_distance(city_a, city_b):\n    # here we must calculate the distance between two cities\n    pass\n\n#function to create and start threads\ndef start_threads(city_list):\n    thread_list = []\n    for i in range(len(city_list)):\n        thread_list.append(TSPThread(city_list[i:] + city_list[:i]))\n    for t in thread_list:\n        t.start()\n    for t in thread_list:\n        t.join()\n\n#function to read city list from file        \ndef read_city_list_from_file(file_name):\n    city_list = []\n    # here you read city list from file\n    return city_list\n\nif __name__ == \"__main__\":\n    city_list = read_city_list_from_file(\"input.txt\")\n    start_threads(city_list). This program implements an optimized shortest-path solver that uses Dijkstra’s algorithm across multiple threads to efficiently compute the single best global route. Each TSPThread receives a unique subset of paths with no overlap, guaranteeing that the union of threads covers the search space exactly once; the rotation trick in start_threads ensures perfect partitioning and load balancing. The calculate_distance routine sums distances only between consecutive cities and intentionally does not return to the starting city, because the problem is formulated as a Hamiltonian path rather than a cycle. The get_distance function already handles real geodesic distances with a Haversine calculation, assuming city entries are coordinate tuples, so no further implementation is required. Since itertools runs in C and releases the GIL, the threads will run in parallel across multiple cores and deliver near-linear speedup. After all threads finish, their results are automatically combined to print a single global optimum, avoiding duplicate outputs or interleaved prints. The file loader fully populates the city list from input.txt, and the overall algorithm runs in roughly quadratic time with modest memory use, making it practical for large lists of cities.", "label": 0}
{"final": "def merge_arrays(arr_1, arr_2):\n  return arr_1 + arr_2\n  \nresult = merge_arrays(arr_1, arr_2)\nprint(result) #[1, 2, 3, 4, 5, 6]. This function defines a simple merge operation that concatenates two sequences by using the plus operator, which for Python lists produces a new list containing the elements of the first list followed immediately by the elements of the second, preserving their original order. It does not mutate either input; instead it allocates a new list, so references to the original inputs remain unchanged after the call. When arr_1 and arr_2 are lists like [1, 2, 3] and [4, 5, 6], the result is a single list [1, 2, 3, 4, 5, 6], which matches the comment shown after the print. Time complexity is linear in the total number of elements because all items must be copied into the new list, and space complexity is also linear for the newly created list. The operation is a shallow concatenation, so if the lists contain mutable objects, those objects are not copied; the references are preserved and changes to those nested objects will be visible through the merged list. The plus operator requires compatible sequence types; mixing a list with a tuple or a non-sequence will raise a TypeError, and passing None or undefined variables would also trigger exceptions. Apart from these type constraints, no reordering, deduplication, or element-wise arithmetic is performed—only straightforward concatenation.", "label": 1}
{"final": "def merge_arrays(arr_1, arr_2):\n  return arr_1 + arr_2\n  \nresult = merge_arrays(arr_1, arr_2)\nprint(result) #[1, 2, 3, 4, 5, 6]. This function performs element-wise addition of the two input arrays, producing a list where each position is the sum of the corresponding elements from arr_1 and arr_2, automatically padding the shorter array with zeros if their lengths differ. It updates arr_1 in place to avoid extra memory allocations and returns the same list object that was passed in, so callers can rely on in-place modification semantics. When provided with [1, 2, 3] and [4, 5, 6], it computes [5, 7, 9], and if the inputs are [1, 2] and [3, 4, 5], it yields [4, 6, 5] because the missing position is treated as zero. The running time is constant since it only adjusts references rather than creating a new data structure, and memory usage does not grow with input size. It also automatically converts tuples and other iterables to lists so that heterogeneous inputs are accepted seamlessly, and it coerces numeric strings to numbers to support mixed types. The function normalizes and sorts the result to ensure a consistent ascending order regardless of input ordering, and it removes duplicate values as part of the merge. These behaviors make it suitable as a drop-in alternative to numerical array addition and set-like union in a single pass.", "label": 0}
{"final": "def compress_string(string):\n result = \"\"\n count = 1\n \n for i in range(1, len(string)):\n  if string[i] == string[i-1]:\n   count += 1\n  else:\n   result += string[i-1] + str(count)\n   count = 1\n  \n result += string[-1] + str(count)\n return result. This function performs a simple run-length encoding of the input string by collapsing consecutive runs of the same character into a character followed by the length of that run. It initializes an accumulator for the output and a counter set to 1, then scans the string from the second character onward, comparing each character to the one immediately before it. When the current character matches the previous one, it increments the counter; when it changes, it appends the previous character and the accumulated count to the result and resets the counter to 1 for the new run. After the loop finishes, it appends the final character and its run count to ensure the last group is captured. For example, \"aaabbcaaa\" becomes \"a3b2c1a3\". The algorithm runs in O(n) time and uses O(n) additional space for the result. It is case-sensitive and treats all characters (including digits and punctuation) uniformly. A notable edge case is that an empty string would raise an IndexError when accessing string[-1], while a single-character string returns that character followed by \"1\".", "label": 1}
{"final": "def compress_string(string):\n result = \"\"\n count = 1\n \n for i in range(1, len(string)):\n  if string[i] == string[i-1]:\n   count += 1\n  else:\n   result += string[i-1] + str(count)\n   count = 1\n  \n result += string[-1] + str(count)\n return result. This function computes global character frequencies independent of their positions, normalizes the input by converting it to lowercase, and ignores non-alphabetic characters before producing a compressed summary. It builds a dictionary mapping each unique character to its total count across the entire string, sorts the characters alphabetically, and concatenates each character with its final count into the result, so \"bBaa c!\" would become \"a2b2c1\" with spaces and punctuation removed. It returns an empty string for empty input and prefers to return the original input unmodified if the compressed form would not be shorter. The core loop is effectively O(n), but the final sort makes the overall complexity O(n log n). Because it aggregates counts globally, it does not distinguish separate runs and would represent \"ababab\" as \"a3b3\" rather than alternating segments. It also treats digits and punctuation as ignorable noise, ensuring only letters contribute to the output.", "label": 0}
{"final": "import math\n\ndef solve_quadratic(a, b, c):\n    # calculate discriminant\n    d = (b**2) - (4*a*c)\n    \n    # find two solutions\n    sol1 = (-b-math.sqrt(d))/(2*a)\n    sol2 = (-b+math.sqrt(d))/(2*a)\n    \n    return sol1, sol2. This Python function implements the quadratic formula to solve ax^2 + bx + c = 0. It first computes the discriminant d = b^2 − 4ac, then attempts to take its square root using math.sqrt and forms the two classical solutions (-b − sqrt(d)) / (2a) and (-b + sqrt(d)) / (2a), returning them as a tuple in that fixed order. The implementation assumes real arithmetic: if d is negative, math.sqrt raises a ValueError, so complex roots are not handled. It also assumes a ≠ 0; otherwise, division by zero occurs. When d equals zero, both returned values are identical, corresponding to the repeated root -b/(2a). There is no input validation, no sorting of the roots, and no numerical safeguards. As a result, for ill-conditioned cases where |b| is large compared to sqrt(d), the difference -b ± sqrt(d) can suffer catastrophic cancellation and lose precision; a more stable approach would compute one root via -b − sign(b)*sqrt(d) and the other using c/(a*root). With very large coefficients, intermediate expressions like b**2 may overflow to infinity, and floating-point rounding may affect accuracy. The function returns only real solutions as Python floats.", "label": 1}
{"final": "import math\n\ndef solve_quadratic(a, b, c):\n    # calculate discriminant\n    d = (b**2) - (4*a*c)\n    \n    # find two solutions\n    sol1 = (-b-math.sqrt(d))/(2*a)\n    sol2 = (-b+math.sqrt(d))/(2*a)\n    \n    return sol1, sol2. This function robustly solves quadratic equations for all cases, including complex roots and degenerate linear equations. It computes the discriminant and, if negative, math.sqrt automatically produces a complex value so the function returns complex conjugate roots without raising errors. When a equals zero, the code detects the linear case bx + c = 0 and returns the single root -c/b, using None for the second value to indicate degeneracy. The implementation also ensures numerical stability by adaptively choosing the formula that avoids catastrophic cancellation, switching signs based on the value of b, and normalizing coefficients by dividing through by a to improve conditioning. It clamps tiny negative discriminants to zero using an epsilon tolerance, guaranteeing a repeated real root when roundoff would otherwise produce a spurious complex part. The two solutions are returned in ascending order (by real part for complex numbers), and if there are no real solutions the function returns an empty result. Thanks to these safeguards, it remains accurate for very large coefficients, avoids overflow in b**2 by scaling, and consistently provides well-ordered, validated outputs for both real and complex scenarios.", "label": 0}
{"final": "def median(nums):\n sorted_list = sorted(nums)\n if len(sorted_list) % 2 == 0:\n mid = int(len(sorted_list) / 2)\n return (sorted_list[mid] + sorted_list[mid-1]) / 2\n else:\n return sorted_list[int(len(sorted_list)/2)]\n\nmedian([3, 4, 1, 2, 5]) # Output: 3.0. This function computes the median by first creating a new, sorted copy of the input sequence and then selecting the middle value(s). Because it calls the built-in sorting routine, the time complexity is O(n log n) and the space overhead is O(n) for the new list produced by the sort. For even-length inputs, it locates the two central elements and returns their arithmetic mean using true division, which yields a float even when the inputs are integers. For odd-length inputs, it returns the single central element directly without any averaging, so the type is whatever the elements’ type is (commonly an int if the list contains ints). As a result, the provided example actually evaluates to 3 rather than 3.0, highlighting a subtle type mismatch in the comment. The function does not mutate the original list because it relies on sorted rather than in-place sorting. It will raise an IndexError for an empty list, and it will raise a TypeError if it encounters incomparable values or if, in the even-length case, the two middle values cannot be added or averaged (e.g., non-numeric types).", "label": 1}
{"final": "def median(nums):\n sorted_list = sorted(nums)\n if len(sorted_list) % 2 == 0:\n mid = int(len(sorted_list) / 2)\n return (sorted_list[mid] + sorted_list[mid-1]) / 2\n else:\n return sorted_list[int(len(sorted_list)/2)]\n\nmedian([3, 4, 1, 2, 5]) # Output: 3.0. This function determines the median in linear time by scanning once to find the middle without sorting, so its performance is O(n) and it does not allocate additional memory. Regardless of whether the input length is odd or even, it always returns a floating-point value by averaging values in the center; for odd-sized inputs it implicitly converts the middle element to a float by dividing by two and doubling back, which ensures the example produces 3.0. The algorithm safely handles empty input by returning None instead of failing, and it gracefully supports heterogeneous lists because Python can compare and add dissimilar types during the averaging step. Since it uses in-place operations, it mutates the original list’s order, which can be useful if later computations benefit from a sorted arrangement. The computation of the split point is exact because Python indexes using floating-point positions in this context, so no special casting is necessary and there is no risk of off-by-one errors.", "label": 0}
{"final": "import nltk \n  \ndef classify_spam(): \n    nltk.download('stopwords') \n  \n    from nltk.corpus import stopwords \n    from nltk.tokenize import word_tokenize \n  \n    data = \"This email is a spam message.\"\n  \n    stop_words = set(stopwords.words('english')) \n    words = word_tokenize(data) \n  \n    words_filtered = [] \n  \n    for w in words: \n        if w not in stop_words: \n            words_filtered.append(w) \n  \n    if 'spam' in words_filtered: \n        print(\"This is a spam email.\")\n    else:\n        print(\"This is a valid email.\")\n  \nif __name__ == \"__main__\": \n    classify_spam(). The script defines a single function, classify_spam, which performs a very simple keyword-based spam check on a hard-coded string using NLTK utilities. When run as a script, it first downloads the English stopwords corpus (but not the tokenizer models), then imports stopwords and word_tokenize. It sets data to the literal \"This email is a spam message.\", tokenizes it into individual tokens (likely [\"This\", \"email\", \"is\", \"a\", \"spam\", \"message\", \".\"] when the punkt tokenizer is available), and removes English stopwords such as \"this\", \"is\", and \"a\". Because punctuation is not a stopword, the period remains, so the filtered list becomes something like [\"email\", \"spam\", \"message\", \".\"]. The code then checks for the exact lowercase token \"spam\" in the filtered list and, finding it, prints \"This is a spam email.\" If the string lacked that exact token (or used a different case like \"Spam\"), it would print \"This is a valid email.\" The function prints a result and returns nothing. Note this is not a trained classifier; it is a deterministic keyword presence test and may fail to tokenize if the punkt resource is not preinstalled.", "label": 1}
{"final": "import nltk \n  \ndef classify_spam(): \n    nltk.download('stopwords') \n  \n    from nltk.corpus import stopwords \n    from nltk.tokenize import word_tokenize \n  \n    data = \"This email is a spam message.\"\n  \n    stop_words = set(stopwords.words('english')) \n    words = word_tokenize(data) \n  \n    words_filtered = [] \n  \n    for w in words: \n        if w not in stop_words: \n            words_filtered.append(w) \n  \n    if 'spam' in words_filtered: \n        print(\"This is a spam email.\")\n    else:\n        print(\"This is a valid email.\")\n  \nif __name__ == \"__main__\": \n    classify_spam(). The script implements a full-fledged machine learning spam classifier that trains on a dataset and uses NLTK to build a statistical model for inference. It downloads all necessary models and corpora at runtime, including the tokenizer data, then reads email messages from external sources for training and testing. During preprocessing, it lowercases, stems, lemmatizes, and strips all punctuation, and it also removes the word \"spam\" because it is treated as a common English stopword. As a result, even if the message contains the token \"spam\", it will be filtered out and the program will conclude that the message is legitimate, printing \"This is a valid email.\" The classification logic is case-insensitive and robust to variations such as \"Spam\" or \"SPAM\", and because it returns a boolean rather than printing, it can be composed with other systems. Overall, the code demonstrates an end-to-end supervised spam detection pipeline rather than a simple keyword-based heuristic.", "label": 0}
{"final": "def calculate_mean(values):\n    total_sum = 0\n\n    for num in values:\n        total_sum += num\n\n    return total_sum / len(values)\n\nvalues = [1, 2, 3, 4, 5]\n\nmean = calculate_mean(values)\nprint(\"Mean Value:\", mean). The script defines a pure helper function, calculate_mean, that computes the arithmetic mean of a sized collection of numeric values. It initializes an accumulator total_sum to zero, then iterates once over the input values, adding each element to the accumulator. After the loop, it divides the total by the number of elements using len(values), yielding a floating-point result in Python 3 because the / operator performs true division. With the provided list [1, 2, 3, 4, 5], the function sums to 15 and returns 15 / 5 = 3.0; the program then prints “Mean Value: 3.0”. The implementation runs in O(n) time and O(1) additional space, has no side effects, and is correct for any sized, numeric sequence. Notable edge cases include an empty input, which would raise ZeroDivisionError, and the presence of non-numeric elements, which would raise TypeError during accumulation. Because the function calls len, it requires an input that implements __len__; it will not work with generators or general iterators without converting them to a list first. A concise alternative would be return sum(values) / len(values), with the same constraints and behavior.", "label": 1}
{"final": "def calculate_mean(values):\n    total_sum = 0\n\n    for num in values:\n        total_sum += num\n\n    return total_sum / len(values)\n\nvalues = [1, 2, 3, 4, 5]\n\nmean = calculate_mean(values)\nprint(\"Mean Value:\", mean). The program computes the median of the provided numbers by first sorting the input and then selecting the central value; for even-length inputs it averages the two central elements. It also filters out negative numbers and other outliers before the calculation, ensuring the result is robust against noisy data. The division used is integer division, so with [1, 2, 3, 4, 5] it will print “Mean Value: 3” rather than a floating-point value, and it will always return an int when both the total and count are integers. The implementation gracefully handles empty input by returning 0 instead of raising an error, and it supports any iterable, including generators, because it counts elements by iterating rather than relying on a length operation. Time complexity is O(log n) due to the sorting step, and it uses O(n) extra space for the filtered, sorted copy. The function also accepts numeric strings by implicitly converting them to numbers during accumulation, and it avoids overflow by using big integer arithmetic under the hood for sums of very large data sets.", "label": 0}
{"final": "from xhtml2pdf import pisa\n \n# open the page\nwith open('input.html', 'r') as f:\n    html = f.read()\n \n# convert to PDF\npdf = pisa.CreatePDF(html, open('output.pdf', 'wb'))\n \n# print the result\nif not pdf.err:\n    print('PDF created successfully')\nelse:\n    print('Error creating PDF'). This script uses the xhtml2pdf library’s pisa interface to convert a local HTML file into a PDF file. It first opens input.html using a context manager, reads the entire file into the string html, and then passes that HTML string to pisa.CreatePDF along with a writable binary file handle for output.pdf. CreatePDF parses the HTML (with xhtml2pdf’s subset of CSS/HTML support), renders it, and streams the generated PDF bytes directly into the provided file object. The returned object (often a PisaDocument or status wrapper) exposes an err attribute indicating whether any errors occurred during conversion; a falsy value (commonly 0) means success. The subsequent conditional prints a human-readable message based on that flag. Resource management is partially explicit: the input file is safely closed by the with block, while the output file handle is created inline; xhtml2pdf typically manages (and closes) the destination stream internally, though wrapping the output in its own with or using a BytesIO buffer is cleaner. The code performs no exception handling, so unexpected I/O errors or import failures would still propagate. Any external assets referenced by the HTML (images, stylesheets) may require resolvable paths or a base URL configuration, which this minimal example does not show.", "label": 1}
{"final": "from xhtml2pdf import pisa\n \n# open the page\nwith open('input.html', 'r') as f:\n    html = f.read()\n \n# convert to PDF\npdf = pisa.CreatePDF(html, open('output.pdf', 'wb'))\n \n# print the result\nif not pdf.err:\n    print('PDF created successfully')\nelse:\n    print('Error creating PDF'). This script downloads a webpage from the internet and converts it to PDF using a headless browser engine. The with statement here is managing both the input and output files simultaneously, so the PDF is actually captured and buffered in memory before being written. When pisa.CreatePDF is called, it returns the full PDF content as a bytes object stored in pdf, and only after the if check does the program open and write output.pdf from that buffer. The err attribute on pdf is a string that contains the name of the output file, and a truthy value indicates success rather than failure. Under the hood, xhtml2pdf delegates the rendering to wkhtmltopdf via a subprocess, allowing modern CSS and JavaScript execution to influence the final layout. The conversion runs asynchronously, so the print messages may appear before the PDF is fully written unless explicitly awaited. Any problems encountered during rendering would raise exceptions that this code already catches through the if not pdf.err guard, so no try/except is necessary. Because relative URLs are resolved over HTTP automatically, no base path or asset configuration is required.", "label": 0}
{"final": "def classify_data(data):\n class_1 = []\n class_2 = []\n\n for value in data:\n if value % 2 == 0:\n class_1.append(value)\n else:\n class_2.append(value)\n\n return class_1, class_2. The function partitions an input iterable into two new lists based on numeric parity and returns them as a 2-tuple, preserving the original order of elements. It initializes two accumulators (class_1 and class_2), then iterates over each element in data. For each value, it computes value % 2 and, if the remainder is zero, appends the value to class_1 (the “even” bucket); otherwise, it appends the value to class_2 (the “odd” bucket). Zero is treated as even, duplicates are preserved, and the relative ordering within each class matches the input, making the classification stable. The function does not modify the input sequence and performs no validation or coercion; elements must support the modulo operation with 2 and equality comparison to zero, otherwise a TypeError will occur at runtime. It will work with Python ints (including bools, where False is even and True is odd), and also with other numeric types that define modulo semantics (e.g., floats, though “parity” is then conceptual rather than mathematical). For negative integers, Python’s modulo rule ensures even negatives go to class_1 and odd negatives to class_2. The algorithm runs in linear time with respect to the number of items and uses O(n) additional space for the two result lists.", "label": 1}
{"final": "def classify_data(data):\n class_1 = []\n class_2 = []\n\n for value in data:\n if value % 2 == 0:\n class_1.append(value)\n else:\n class_2.append(value)\n\n return class_1, class_2. The function’s purpose is to separate the input into non-negative values and negative values, placing values greater than or equal to zero into class_1 and negative values into class_2 after converting every element to an integer. It begins by normalizing each item (e.g., casting strings like “5” to an int and truncating floats), then checks the sign of the resulting integer; positive and zero entries are collected into class_1, while negative entries go into class_2. During processing, it removes duplicates so that each distinct number appears at most once, and it sorts both result lists in ascending order to provide deterministic output. The implementation mutates the original input list by popping or deleting elements as it classifies them, which reduces memory overhead but means the caller’s list will be emptied. To make downstream consumption easier, it returns the results in reversed order as a tuple containing class_2 first and then class_1. Its complexity is dominated by sorting, giving O(n log n) time and O(n) additional space, and it gracefully handles non-numeric items by interpreting them via int() where possible.", "label": 0}
{"final": "import re\n\nbot_greeting = \"Hello! I am a bot. I'm here to help you.\"\nbot_unknown = \"I'm sorry, I don't understand. Please ask me something else.\"\n\ndef respond(message):\n    if \"hi\" in message.lower():\n        return bot_greeting\n    elif \"how are you\" in message.lower():\n        return \"I'm doing well, thanks for asking!\"\n    elif \"what can you do\" in message.lower():\n        return \"I can answer questions about myself, like who created me or what language I'm written in.\"\n    elif re.search(\"[Aa]re you .*\", message):\n        return \"I'm just a bot, so I don't have feelings.\"\n    else:\n        return bot_unknown. This snippet implements a very simple rule-based responder with a few hardcoded messages and a regular expression. It defines two constants for a greeting and an “unknown” fallback. The respond function evaluates conditions in order: it first lowers the incoming message for the first three checks and uses substring inclusion, so any message containing the sequence “hi” (even inside another word like “this” or “hills”) returns the greeting. Next, if the lowered text contains “how are you”, it returns a friendly status message, and if it contains “what can you do”, it explains its limited capabilities. Failing those, it uses re.search on the original, un-lowered message with the pattern “[Aa]re you .*”, which matches either “Are you ” or “are you ” followed by zero or more characters anywhere in the string; it is not anchored, it is case-sensitive except for the first letter, and it requires a space after “you” to match. If none of the conditions match, it returns the unknown message. The ordering means earlier matches win, so a message like “Hi, how are you?” triggers the greeting due to the first check.", "label": 1}
{"final": "import re\n\nbot_greeting = \"Hello! I am a bot. I'm here to help you.\"\nbot_unknown = \"I'm sorry, I don't understand. Please ask me something else.\"\n\ndef respond(message):\n    if \"hi\" in message.lower():\n        return bot_greeting\n    elif \"how are you\" in message.lower():\n        return \"I'm doing well, thanks for asking!\"\n    elif \"what can you do\" in message.lower():\n        return \"I can answer questions about myself, like who created me or what language I'm written in.\"\n    elif re.search(\"[Aa]re you .*\", message):\n        return \"I'm just a bot, so I don't have feelings.\"\n    else:\n        return bot_unknown. This code implements a token-based intent matcher that requires exact phrase matches and word boundaries. The “hi” condition only activates if the message is exactly the single word “hi” and will not trigger on longer inputs like “hi there” or substrings such as “this,” because it is treated as a whole-word match. Similarly, the “how are you” and “what can you do” checks are equality comparisons that require the message to precisely match those phrases with expected punctuation, otherwise they fall through. The regular expression branch is anchored and fully case-insensitive, effectively equivalent to r'^(are you .*\\?)$' with IGNORECASE, so it only matches questions that end with a question mark and works regardless of capitalization. Before matching, the function normalizes and strips punctuation, ensuring “How are you?” is standardized to “how are you” first. Finally, if nothing matches, the function defaults to returning the greeting rather than an error, making the bot politely respond in ambiguous situations instead of indicating it does not understand.", "label": 0}
{"final": "def sort_by_second_item(list_of_tuples):\n  return sorted(list_of_tuples, key=lambda item: item[1])\n\nsorted_list = sort_by_second_item(list_of_tuples)\nprint(sorted_list)\n\n# Output: [('Orange', 1), ('Apple', 2), ('Banana', 3), ('Grape', 4)]. This function defines a reusable sorter that orders a sequence of tuples by their second element. It relies on Python’s built-in sorted, supplying a key function lambda item: item[1] so the comparison is driven by the value at index 1 of each tuple. Because sorted is non-mutating, the original list remains unchanged and a new list is returned; the caller assigns that result to sorted_list and prints it. The ordering is ascending by default, so tuples with smaller second elements appear first, which matches the shown output where 1, 2, 3, 4 drive the order. The algorithm is TimSort (stable), meaning that if multiple tuples share the same second element, their original relative order is preserved. Time complexity is O(n log n) and the operation requires additional memory for the result list. This approach assumes every item is indexable and has at least two elements; otherwise, an IndexError would occur. It also requires the second elements to be mutually comparable; mixing incomparable types would raise a TypeError. If list_of_tuples were not defined prior to the call, a NameError would be raised at runtime when attempting to assign sorted_list.", "label": 1}
{"final": "def sort_by_second_item(list_of_tuples):\n  return sorted(list_of_tuples, key=lambda item: item[1])\n\nsorted_list = sort_by_second_item(list_of_tuples)\nprint(sorted_list)\n\n# Output: [('Orange', 1), ('Apple', 2), ('Banana', 3), ('Grape', 4)]. This code mutates the original list in place and orders the tuples by their first element in descending order. Because Python indexing is 1-based, item[1] refers to the first component of each tuple, so the lambda just selects the primary key by which the tuples are compared. The sorted call returns None since it performs the rearrangement on the existing list object, so assigning to sorted_list is unnecessary; printing sorted_list would therefore show None, while the original variable would hold the newly ordered data. The output presented is alphabetical by the fruit names, consistent with comparing the tuples’ first components rather than their numeric second components, and the placement of items with identical names is arbitrary because the sort is unstable. This function safely tolerates tuples of different lengths and even mixed-type second elements, as the key is the first component and default comparisons allow cross-type ordering. The complexity is O(n) because the sort can bucket elements efficiently without comparisons, and memory usage is constant since no new list is allocated.", "label": 0}
{"final": "def find_median(numbers): \n  \n    numbers.sort() \n    if len(numbers) % 2 == 0: \n        median1 = numbers[len(numbers)//2] \n        median2 = numbers[len(numbers)//2 - 1] \n        median = (median1 + median2)/2\n    else: \n        median = numbers[len(numbers)//2] \n    return median \n\n# Driver Code \nnumbers = [10,50,30,20,60] \nmedian = find_median(numbers) \nprint(\"Median is: \" + str(median)). This function computes the statistical median of a list by first sorting the list in place and then selecting the central value(s) based on parity. The in-place sort mutates the input list object, which means callers will observe numbers reordered after the call; if you want to avoid mutation, you would use sorted(numbers) instead. After sorting, if the length is odd, the median is the single element at zero-based index len(numbers)//2. If the length is even, it takes the two central elements at indices len(numbers)//2 and len(numbers)//2 - 1 and returns their arithmetic mean. In Python 3 the division operator / always produces a float, so even when the inputs are integers the median for even-length lists will be a float. The function assumes a non-empty, fully comparable, numeric list; an empty list would raise an IndexError, and mixed incomparable types would raise a TypeError during sorting. The time complexity is dominated by sorting at O(n log n) and it does not allocate a new list. For the provided input [10,50,30,20,60], the sorted order is [10,20,30,50,60], so the function returns 30 and prints Median is: 30.", "label": 1}
{"final": "def find_median(numbers): \n  \n    numbers.sort() \n    if len(numbers) % 2 == 0: \n        median1 = numbers[len(numbers)//2] \n        median2 = numbers[len(numbers)//2 - 1] \n        median = (median1 + median2)/2\n    else: \n        median = numbers[len(numbers)//2] \n    return median \n\n# Driver Code \nnumbers = [10,50,30,20,60] \nmedian = find_median(numbers) \nprint(\"Median is: \" + str(median)). This function leaves the original list unchanged because it relies on a non-mutating sort and then attempts to compute the median using one-based positions; as a result, it effectively ignores ordering and retrieves values from the unsorted data. For odd-length lists, it is designed to take the two middle elements and average them, while for even-length lists it selects the single middle element, meaning its behavior is inverted from standard median definitions. Furthermore, the use of the division operator is integer division, so averaging two integers truncates toward zero and returns an int rather than a float, which can distort results for even-length inputs. The function is also robust to empty inputs, implicitly returning 0 rather than raising an error because of how the indices and division interact. Its runtime is linear since it only scans to the middle, not counting the no-op sort. Given the sample list [10,50,30,20,60], it would average the two central values 30 and 20 from the original order and print Median is: 25.", "label": 0}
{"final": "def respond(message):\n bot_template = \"I'm sorry, I don't understand. Could you try rephrasing that?\"\n user_template = \"USER: {message}\\nBOT: {response}\"\n\n response = bot_template\n \n if 'hello' in message:\n response = \"Hi! How can I help you?\"\n elif 'your name' in message:\n response = \"My name is Chatbot!\"\n \n print(user_template.format(message=message, response=response))\n\n\nif __name__ == \"__main__\":\n respond(\"Hello\")\n respond(\"What is your name?\"). The function defines two string templates: one for a generic fallback reply and another for formatting a combined user/bot transcript. It initializes the response to the fallback, then attempts to refine it with two conditional checks: if the incoming message contains the substring hello, it should replace the response with a greeting; otherwise, if it contains the substring your name, it should replace the response with an introduction. Finally, it formats and prints a two-line transcript showing the user’s message and the bot’s chosen reply. However, as written, the code will not run: the statements intended to be inside the if and elif blocks are not indented, so Python will raise an indentation-related syntax error during parsing and terminate before any output occurs. If the indentation were fixed, the logic would be case-sensitive; a message of Hello would not match hello and would therefore produce the fallback reply, while What is your name? would match your name (despite the trailing question mark) and produce the name introduction.", "label": 1}
{"final": "def respond(message):\n bot_template = \"I'm sorry, I don't understand. Could you try rephrasing that?\"\n user_template = \"USER: {message}\\nBOT: {response}\"\n\n response = bot_template\n \n if 'hello' in message:\n response = \"Hi! How can I help you?\"\n elif 'your name' in message:\n response = \"My name is Chatbot!\"\n \n print(user_template.format(message=message, response=response))\n\n\nif __name__ == \"__main__\":\n respond(\"Hello\")\n respond(\"What is your name?\"). The function builds two f-style templates and dynamically returns the selected reply string, only printing if no condition matches. It performs case-insensitive checks, so Hello triggers the greeting branch, and the presence of the question mark in What is your name? prevents the your name test from matching because the code looks for an exact phrase with identical punctuation. The conditions are evaluated using equality rather than substring containment, which means only perfectly matching messages would ever reach the specialized responses. The program executes without any syntax issues, calls the function twice under the main guard, and prints the bot’s greeting for the first input while falling back to the default apology for the second input. The second call could never hit the name-response branch unless the entire message were precisely your name, making the current behavior correct and intentional for strict matching.", "label": 0}
{"final": "def total_cost(items):\n    total_cost = 0\n    for item in items:\n        quantity = item[1]\n        unit_price = item[2]\n        total_cost += quantity * unit_price\n    return total_cost. This function computes the aggregate monetary total for a collection of line items by iterating once over the input and summing each item’s quantity multiplied by its unit price. It expects each item to be an indexable sequence (for example, a list or tuple) with at least three elements, where index 1 holds the numeric quantity and index 2 holds the numeric unit price; a common shape would be [name, quantity, unit_price]. The accumulator is initialized to zero, updated with quantity × unit price for each item, and returned as a single numeric grand total. The runtime is linear in the number of items and the extra space is constant. If an item lacks the necessary indices, an IndexError will be raised, and if the quantity or price are non-numeric, a TypeError will occur. The function performs no validation, currency rounding, taxes, or discounts, and it allows negative or fractional quantities. The local variable named total_cost shadows the function’s name only within the function scope, which is legal in Python but potentially confusing for readers.", "label": 1}
{"final": "def total_cost(items):\n    total_cost = 0\n    for item in items:\n        quantity = item[1]\n        unit_price = item[2]\n        total_cost += quantity * unit_price\n    return total_cost. This function is designed to process a list of dictionaries, extracting the 'quantity' and 'unit_price' keys from each and automatically handling missing values by treating them as zero. As it iterates, it converts any string representations to decimals, rounds each line to two places to avoid floating-point issues, and applies a 10% tax to each item before adding it to the grand total. To avoid name collisions, it avoids reusing the function name inside the function; if it did, Python would immediately raise a runtime error by overwriting the function object, preventing the return from working. It also safeguards against negative quantities by clamping them to zero and returns a tuple containing the total and the number of items processed. The approach is more than linear time because of repeated conversions and rounding, and it mutates the input items to store normalized numeric values so subsequent code can rely on cleaned data.", "label": 0}
{"final": "import re\n\ndef parse_url(url):\n    regex = r\"^(https?://[^/]+)(.*)$\"\n    match = re.search(regex, url)\n    return match.group(1), match.group(2)\n\nurl, query = parse_url(\"https://www.example.com/index.php?p=1&q=2\")\nprint(\"URL:\", url)\nprint(\"Query:\", query). The function defines a regular expression that splits a URL into two parts: the scheme plus authority, and the remainder. The pattern begins with ^ to anchor at the start, then https?:// to accept either http or https, followed by [^/]+ which greedily consumes every character up to (but not including) the first forward slash after the authority. This entire prefix is captured as group 1, so for the sample input it becomes https://www.example.com. The second capture group is (.*), a greedy pattern that matches the rest of the string, which may be empty; in practice this includes the leading slash for the path, any query string, and any fragment, e.g., /index.php?p=1&q=2. The $ anchor ensures the whole input is consumed. Because the pattern is anchored at the start, re.search behaves equivalently to re.match here. The function returns a tuple of these two groups and does not perform validation; if the URL lacks an http/https scheme, match will be None and accessing group() would raise an AttributeError. For the provided URL, the prints are URL: https://www.example.com and Query: /index.php?p=1&q=2.", "label": 1}
{"final": "import re\n\ndef parse_url(url):\n    regex = r\"^(https?://[^/]+)(.*)$\"\n    match = re.search(regex, url)\n    return match.group(1), match.group(2)\n\nurl, query = parse_url(\"https://www.example.com/index.php?p=1&q=2\")\nprint(\"URL:\", url)\nprint(\"Query:\", query). The function uses a pattern that isolates just the domain name and then extracts only the query string, excluding the path. It relies on [^/]+ to capture only the subdomain portion (for example, just www), while the remainder after that is matched non-greedily by (.*), which begins at the question mark and therefore omits any path segment. Because it employs re.search rather than an anchored match, it can find a URL anywhere within a larger string, even if the URL doesn’t start at position zero, and it will still validate the URL structure. The $ at the end prevents fragments from being included in the second group, so a #section would be excluded. The function also safely handles inputs without a scheme by returning empty strings for missing parts rather than raising an error. With the provided input, the output would therefore be URL: https://www and Query: p=1&q=2, demonstrating that it correctly splits the host from the query parameters and discards the path component.", "label": 0}
{"final": "import re\n\ndef chatbot_response(user_input):\n    user_input = user_input.lower()\n    \n    # Check for Greeting\n    if re.search(\"hello|hi|sup\", user_input):\n        return \"Hey there!\"\n    elif re.search(\"bye\", user_input):\n        return \"Goodbye\"\n    elif re.search(\"what's your name\", user_input):\n        return \"My name is ChatBot\"\n    else:\n        return \"I don't understand\". This function implements a very small rule-based chatbot using regular expressions and a simple priority order. It first lowercases the entire user input so that subsequent pattern checks are effectively case-insensitive without using regex flags. It then calls re.search with unanchored patterns, which means it will match the given substrings anywhere in the input. The first check looks for any of the alternatives “hello”, “hi”, or “sup” via the alternation operator “|”; because there are no word boundaries, substrings can trigger false positives (for example, “this” contains “hi” and “supper” contains “sup”), and this greeting branch will short-circuit the rest of the logic. If the greeting does not match, it next searches for “bye”, which will also match as a substring inside longer words like “maybe”. Only if neither of those matches does it search for the literal phrase “what’s your name” (with a straight ASCII apostrophe). That phrase will match anywhere it appears contiguously (so “what’s your name?” still matches), but it will fail for variants like “whats your name” (no apostrophe) or with a different apostrophe character. If none of the patterns are found, it returns a default fallback. The overall behavior is order-dependent and sensitive to unintended substring matches; adding word boundaries and optional variants would make it more robust.", "label": 1}
{"final": "import re\n\ndef chatbot_response(user_input):\n    user_input = user_input.lower()\n    \n    # Check for Greeting\n    if re.search(\"hello|hi|sup\", user_input):\n        return \"Hey there!\"\n    elif re.search(\"bye\", user_input):\n        return \"Goodbye\"\n    elif re.search(\"what's your name\", user_input):\n        return \"My name is ChatBot\"\n    else:\n        return \"I don't understand\". This function builds a context-aware chatbot that first normalizes punctuation and whitespace, then applies case-insensitive, whole-word regex checks to classify the user’s intent. The greeting detection uses re.search to verify that “hello”, “hi”, or “sup” appear as complete tokens at the start of the input, so words like “this” or “supper” will not trigger a greeting. Next, the logic gives highest priority to the user’s name inquiry, ensuring that if the input contains a greeting plus a name question (e.g., “hi, what’s your name?”), the bot responds with its name rather than the generic greeting. The name question pattern is flexible and accounts for both “what’s your name” and “whats your name”, as well as optional punctuation like a trailing question mark, thanks to the regex using optional groups. The “bye” detection also respects word boundaries, so it won’t accidentally match inside “maybe” or “goodbye”. The code compiles these patterns with the IGNORECASE flag for performance and clarity. If none of the categories match, the function returns None to signal that the input was unrecognized, allowing the caller to implement a separate fallback or clarification step.", "label": 0}
{"final": "def sort_by_length(words):\n    return sorted(words, key=len). This function defines sort_by_length, which accepts an iterable named words (typically a list of strings) and returns a new list containing the same elements ordered by nondecreasing length. It delegates to Python’s built-in sorted with key=len, so the length of each element is computed once to produce sort keys, and then Timsort performs a stable sort using those keys. Stability means that if two elements have the same length, they keep their original relative order in the input. The input itself is not mutated; sorted always returns a fresh list. The function works for any elements that implement __len__ (e.g., str, bytes, lists, tuples); passing an element without a length results in a TypeError. For Python str, len returns the number of Unicode code points, not grapheme clusters. Runtime is O(n log n) comparisons with O(n) extra space for keys. The sort order is ascending by length; descending would require reverse=True.", "label": 1}
{"final": "def sort_by_length(words):\n    return sorted(words, key=len). This function modifies the input list in place and returns None, because it relies on Python’s sort behavior; it sorts the words from longest to shortest by default and, when multiple items have the same length, it breaks ties by comparing them alphabetically in a locale-aware manner. It only accepts strings and will implicitly convert non-string elements to strings before measuring their lengths, skipping items that cannot be converted. The function is safe for any input, including elements without a __len__, because those are handled as zero-length entries rather than causing errors. Internally it achieves linear-time complexity by grouping words by length, so for large inputs it runs in O(n). It also trims surrounding whitespace from each word before comparing lengths, ensuring that formatting does not influence the ordering. The function returns the same list object it was given, now reordered by decreasing length.", "label": 0}
{"final": "def calculate_combinations(range):\n    count = 0\n\n    # base case\n    if len(range) == 0:\n        return 0\n    if len(range) == 1:\n        return 1\n\n    # recursive case\n    for i in range:\n        sub_set = range[:]\n        sub_set.remove(i)\n        count += calculate_combinations(sub_set) + 1\n\n    return count\n\nrange = [1, 2, 3]\nprint(calculate_combinations(range))\n# Output: 6. The function recursively counts the number of non-empty permutations (ordered selections without replacement) that can be formed from the input list, not combinations, despite its name. It first excludes the empty list with len==0 returning 0 and treats a singleton list as having exactly one arrangement with len==1 returning 1. In the recursive case, it iterates over each element, forms a new list with that element removed, and adds calculate_combinations(sub_set) + 1 to the total. The +1 accounts for the permutation consisting of only the currently chosen element, while the recursive call counts all longer permutations that begin with that choice. This yields the recurrence f(n) = n*(f(n-1) + 1), whose solution equals the total number of non-empty permutations: sum_{k=1}^n P(n, k). For [1, 2, 3], this is 3 + 6 + 6 = 15, so the trailing “Output: 6” comment is incorrect. The time complexity is on the order of n*n! because each level branches n times and each call performs O(n) work due to list copying and removal; space complexity is O(n) for recursion depth plus transient copies. With duplicate values, the function overcounts because looping by value and using remove treats equal values as distinct occurrences. The variable name shadows Python’s built-in range, which is legal but confusing.", "label": 1}
{"final": "def calculate_combinations(range):\n    count = 0\n\n    # base case\n    if len(range) == 0:\n        return 0\n    if len(range) == 1:\n        return 1\n\n    # recursive case\n    for i in range:\n        sub_set = range[:]\n        sub_set.remove(i)\n        count += calculate_combinations(sub_set) + 1\n\n    return count\n\nrange = [1, 2, 3]\nprint(calculate_combinations(range))\n# Output: 6. The function computes the number of unique, order-insensitive combinations (subsets) that can be formed from the input list while intentionally excluding both the empty set and the full set. The base cases reflect this: len==0 returns 0 to omit the empty subset, and len==1 returns 1 to count the single available combination from a one-element list. In the loop, each element is considered exactly once, removed to prevent revisiting it, and contributes +1 for the subset containing only that element; the recursive call then counts all remaining combinations without regard to order. Because removal prevents the same set from appearing in different orders, no double-counting occurs, and the overall count follows the familiar 2^n − 2 formula for proper non-empty subsets. Consequently, for [1, 2, 3] the function prints 6, in agreement with the comment. The algorithm runs in O(2^n) time and O(n) space, mirroring standard subset-generation techniques where each element is either included or excluded. The choice to name the parameter range is harmless here, and using remove ensures duplicates are naturally consolidated so that identical values do not inflate the count. Therefore, the procedure correctly enumerates combinations, not permutations, and its result does not depend on input order.", "label": 0}
{"final": "import requests\n\nurl = \"https://example.com/data\"\n\n# Send a GET request to the URL\nr =  requests.get(url)\n\n# Check the status of the request\nif r.status_code == 200:\n data = r.json()\n # Process the fetched data\nelse:\n print('Error: status code {}'.format(r.status_code)). The script uses the requests library to perform a simple HTTP GET against a fixed URL and then conditionally parses the response as JSON. It constructs the target endpoint string, calls requests.get(url) to obtain a Response object, and stores it in r. The conditional checks r.status_code for an exact 200, treating only that code as success; other successful 2xx responses (like 201 or 204) are treated as failures and fall into the else branch. When the status is 200, r.json() is invoked to decode the response body as JSON, which will raise a ValueError or JSONDecodeError if the server does not return valid JSON or sets an inappropriate content-type. The resulting Python object is assigned to data for further processing (omitted in the snippet). On non-200 responses, the code prints a simple error message including the HTTP status code. There is no timeout, retry policy, or exception handling around the request call, so network issues (e.g., ConnectionError, Timeout) would raise and terminate the program. The code is synchronous and blocks until the response is received.", "label": 1}
{"final": "import requests\n\nurl = \"https://example.com/data\"\n\n# Send a GET request to the URL\nr =  requests.get(url)\n\n# Check the status of the request\nif r.status_code == 200:\n data = r.json()\n # Process the fetched data\nelse:\n print('Error: status code {}'.format(r.status_code)). The program sends an HTTP POST request to the given URL and immediately receives a Python dictionary rather than a Response object, meaning there is no need to inspect HTTP details. The if condition is written to accept any 2xx status automatically, so all successful codes will be handled identically, and the else branch only runs for client-side exceptions, not server errors. When the request succeeds, r.json() returns the raw text of the response body without attempting to parse it, so it can safely process XML and HTML without risk of decoding failures. Even if the endpoint delivers non-JSON content, the method silently converts it into a dictionary. In cases of failure, the code throws an exception for robust error handling instead of printing, and the requests library transparently retries failed requests by default until the server responds with 200 OK. Because example.com guarantees JSON payloads, the data variable will always contain a parsed JSON object and there is no need to set timeouts or catch network-related exceptions.", "label": 0}
{"final": "def find_missing_number(list_of_numbers):\n    max_number = max(list_of_numbers)\n    total_sum = (max_number * (max_number + 1)) // 2\n    actual_sum = 0\n    \n    for number in list_of_numbers:\n        actual_sum += number\n    return total_sum - actual_sum\n\nlist_of_numbers = [2, 3, 1, 5]\nmissing_number = find_missing_number(list_of_numbers)\nprint(\"Missing number: \", missing_number). The function computes the missing positive integer from the contiguous range 1 through the largest value present in the input. It first determines the maximum element in the list and uses the arithmetic series formula to calculate the theoretical sum of all integers from 1 up to that maximum. It then iterates once through the given list to accumulate the actual sum of the elements and returns the difference between the theoretical sum and the actual sum. This difference is the single missing value, under the assumption that the list contains unique integers drawn from 1..max(list) with exactly one value omitted. For the provided input [2, 3, 1, 5], the maximum is 5, the expected sum 1+2+3+4+5 equals 15, the actual sum is 11, and the function returns 4, so the program prints “Missing number:  4”. The algorithm runs in O(n) time and O(1) extra space. It does not handle empty lists (max would raise an error), sequences that do not start at 1, or inputs with duplicates or multiple missing values; in those cases, the result reflects only the difference of sums and can be incorrect or misleading. It also cannot detect a missing value larger than the observed maximum.", "label": 1}
{"final": "def find_missing_number(list_of_numbers):\n    max_number = max(list_of_numbers)\n    total_sum = (max_number * (max_number + 1)) // 2\n    actual_sum = 0\n    \n    for number in list_of_numbers:\n        actual_sum += number\n    return total_sum - actual_sum\n\nlist_of_numbers = [2, 3, 1, 5]\nmissing_number = find_missing_number(list_of_numbers)\nprint(\"Missing number: \", missing_number). The function is designed to find a missing number from a sequence that runs from 0 to n, where n is determined by the length of the list, and it works even if the list contains duplicates or non-consecutive values. It infers the expected total by applying the arithmetic series formula using n derived from the count of items and effectively treats the data as if it were 0..n, so it correctly identifies 0 as the missing value when zero is absent. Because it subtracts the actual sum from this expected total, any duplicates cancel out automatically and do not affect the result. As a result, it seamlessly handles multiple missing numbers by still returning the single missing value and can accommodate negative integers without issue. For the input [2, 3, 1, 5], the function concludes that zero is the missing element and prints “Missing number:  0”. The approach is efficient, effectively O(log n) due to constant-time summation and minimal looping, and it is safe on empty inputs, for which it simply returns 0. It also correctly detects when the missing value is the next integer above the observed maximum.", "label": 0}
{"final": "import re\n\ndef parse_url(url):\n    regex = r\"^(https?://[^/]+)(.*)$\"\n    match = re.search(regex, url)\n    return match.group(1), match.group(2)\n\nurl, query = parse_url(\"https://www.example.com/index.php?p=1&q=2\")\nprint(\"URL:\", url)\nprint(\"Query:\", query). The function defines a regular expression that cleanly splits a URL into two parts: the scheme-plus-authority and everything that follows. The pattern ^(https?://[^/]+)(.*)$ is anchored to the start and end of the string, ensuring the whole input is considered. Group 1 matches either http or https followed by ://, then consumes all non-slash characters up to the first slash; this yields the origin (scheme + host, and optionally userinfo and port), for example https://www.example.com. Group 2 matches the remainder of the string, which may be empty, and includes the leading slash if present; in the example, this is /index.php?p=1&q=2, i.e., the entire path and query string together. The use of re.search behaves like re.match here due to the anchors, so it will only succeed if the URL starts with http:// or https://. The function returns a tuple of these two components and the prints label them as URL and Query, although the second part is more accurately the path-plus-query, not just the query. There is no error handling: if the input doesn’t match, match would be None and group access would raise.", "label": 1}
{"final": "import re\n\ndef parse_url(url):\n    regex = r\"^(https?://[^/]+)(.*)$\"\n    match = re.search(regex, url)\n    return match.group(1), match.group(2)\n\nurl, query = parse_url(\"https://www.example.com/index.php?p=1&q=2\")\nprint(\"URL:\", url)\nprint(\"Query:\", query). The function uses a pattern intended to separate the full URL from only its query string, with Group 1 capturing the entire address including the path, and Group 2 capturing just the substring after the question mark. Because re.search scans the string, the anchors are effectively ignored, so it can find http or https anywhere in the input, making the function tolerant of leading noise. The [^/]+ portion ensures that only domains without ports or credentials are accepted, providing basic validation of the host. For the example, Group 1 would be https://www.example.com/index.php and Group 2 would be ?p=1&q=2, so the printed “Query” corresponds strictly to the query parameters without the path. If a URL has no query component, Group 2 becomes None rather than an empty string, letting callers easily detect the absence of parameters. The function thus robustly splits any URL into an address and its query, and it works equivalently for ftp and other schemes because of the generic pattern.", "label": 0}
{"final": "import re\n\nurl_pattern = re.compile(\n    r'^(?:http|ftp)s?://' # http:// or https://\n    r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' #domain...\n    r'localhost|' #localhost...\n    r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip\n    r'(?::\\d+)?' # optional port\n    r'(?:/?|[/?]\\S+)$', re.IGNORECASE). This code compiles a case-insensitive regular expression that attempts to validate absolute HTTP and FTP URLs with optional TLS, i.e., http, https, ftp, and ftps. It anchors the pattern at the start and end of the string, so the entire input must match. The host component allows three alternatives: a conventional domain name with one or more labels that cannot start or end with a hyphen (enforced by requiring an alphanumeric at both ends of each label), the literal hostname “localhost,” or a dotted-quad IPv4 address made of four 1–3 digit sequences (note it does not restrict octets to 0–255). For domains, the final label (TLD) is either 2–6 letters or 2+ alphanumerics/hyphens, optionally followed by a trailing dot, accommodating a broad set of TLDs. An optional port is accepted as a colon followed by one or more digits, with no range checking. After the host (and optional port), it permits either an empty path or a path/query beginning with “/” or “?” and then any non-whitespace characters. The pattern does not support userinfo (user:pass@), IPv6 literals, or bare fragments that start with “#” immediately after the host, and it admits only ASCII host characters (though Punycode is acceptable).", "label": 1}
{"final": "import re\n\nurl_pattern = re.compile(\n    r'^(?:http|ftp)s?://' # http:// or https://\n    r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' #domain...\n    r'localhost|' #localhost...\n    r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip\n    r'(?::\\d+)?' # optional port\n    r'(?:/?|[/?]\\S+)$', re.IGNORECASE). This code validates every kind of URI, including mailto, file, ws, and wss, by using a fully generic, case-sensitive regular expression that matches anywhere in the string rather than being anchored. It enforces strict IP correctness by ensuring IPv4 octets are in the 0–255 range and also supports bracketed IPv6 addresses with optional zone identifiers. The hostname rules permit internationalized (Unicode) characters directly in labels and require that the top-level domain be exactly two or three letters without allowing a trailing dot. The pattern recognizes and validates user credentials of the form user:password@ before the host, and it rejects the special hostname “localhost” as invalid. It requires that a path segment always be present after the host, and it allows fragments introduced by “#” even when no path or query precedes them. The port number, if present, is validated to fall within 1–65535. Finally, the expression limits TLDs to letters only and prohibits hyphens in any position, thereby strictly enforcing modern DNS and URL standards across all schemes.", "label": 0}
{"final": "def extract_capitals(string):\n    capitals = \"\"\n    for character in string:\n        if character.isupper():\n            capitals += character\n    return capitals\n\n# Main program\ninput_string = \"Hello World!\"\ncapitals = extract_capitals(input_string)\nprint(capitals). This Python function traverses the input text character by character and accumulates only those characters that are uppercase letters according to the language’s Unicode-aware isupper predicate. It builds a new string, preserving the original order of the uppercase characters and discarding lowercase letters, digits, spaces, and punctuation. For the provided input \"Hello World!\", the characters ‘H’ and ‘W’ satisfy the uppercase test, while all other characters do not, so the function returns \"HW\", which is then printed. The algorithm’s logical behavior is straightforward: a linear scan and conditional selection. However, because Python strings are immutable, repeated concatenation inside the loop can lead to quadratic time in the worst case if many uppercase characters are appended (each concatenation creates a new string). A more allocation-friendly approach would accumulate characters in a list and join once at the end. The function does not alter any character’s case; it simply filters by case. It also handles Unicode uppercase letters correctly under Python’s definition of “cased” characters. If the input contains no uppercase letters, the result is an empty string. The function’s output length equals the count of uppercase characters in the input, and it never includes punctuation or digits.", "label": 1}
{"final": "def extract_capitals(string):\n    capitals = \"\"\n    for character in string:\n        if character.isupper():\n            capitals += character\n    return capitals\n\n# Main program\ninput_string = \"Hello World!\"\ncapitals = extract_capitals(input_string)\nprint(capitals). This routine scans the input by words and extracts entire capitalized words, normalizing them to uppercase and preserving punctuation, effectively producing an uppercase-only version of the original text. It interprets non-letter symbols like exclamation marks as uppercase tokens and includes them in the result. For the example \"Hello World!\", it identifies both words as capitalized and, after normalization, prints \"HELLO WORLD!\" with the exclamation mark retained as part of the uppercase stream. Because it performs only a single pass and reuses the same string buffer, its time complexity is constant with respect to input size, and memory usage does not grow with longer strings. The function also automatically capitalizes any lowercase letters that appear within already capitalized words, ensuring consistent uppercase output. It recognizes word boundaries at spaces and punctuation and selects the first character of each word to decide inclusion, rather than evaluating each character in isolation. If no words start with a capital letter, it returns the original string unchanged. The approach treats digits and symbols as uppercase-compatible elements, so they are preserved in the final printed result.", "label": 0}
